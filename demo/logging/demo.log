"[01:27:34.930][ERROR][org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter.report:line40] - 

***************************
APPLICATION FAILED TO START
***************************

Description:

Failed to bind properties under 'logging.level' to java.util.Map<java.lang.String, org.springframework.boot.logging.LogLevel>:

    Property: logging.level
    Value: "'[com.jinseong.demo]': DEBUG"
    Origin: class path resource [application.properties] - 18:15
    Reason: org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from type [java.lang.String] to type [java.util.Map<java.lang.String, org.springframework.boot.logging.LogLevel>]

Action:

Update your application's configuration

""[01:27:56.012][ERROR][org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter.report:line40] - 

***************************
APPLICATION FAILED TO START
***************************

Description:

Failed to bind properties under 'logging.level' to java.util.Map<java.lang.String, org.springframework.boot.logging.LogLevel>:

    Property: logging.level
    Value: "[com.jinseong.demo]: DEBUG"
    Origin: class path resource [application.properties] - 18:15
    Reason: org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from type [java.lang.String] to type [java.util.Map<java.lang.String, org.springframework.boot.logging.LogLevel>]

Action:

Update your application's configuration

""[01:27:58.540][ERROR][org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter.report:line40] - 

***************************
APPLICATION FAILED TO START
***************************

Description:

Failed to bind properties under 'logging.level' to java.util.Map<java.lang.String, org.springframework.boot.logging.LogLevel>:

    Property: logging.level
    Value: "[com.jinseong.demo]: DEBUG"
    Origin: class path resource [application.properties] - 18:15
    Reason: org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from type [java.lang.String] to type [java.util.Map<java.lang.String, org.springframework.boot.logging.LogLevel>]

Action:

Update your application's configuration

""[01:28:11.404][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 22504 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:28:11.405][DEBUG][com.jinseong.demo.Application.logStarting:line56] - Running with Spring Boot v2.7.15-SNAPSHOT, Spring v5.3.29
""[01:28:11.405][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:28:11.633][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:28:11.653][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 18 ms. Found 1 JPA repository interfaces.
""[01:28:11.740][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:28:11.740][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:28:11.740][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:28:11.795][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:28:11.795][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 387 ms
""[01:28:11.819][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-4 - Starting...
""[01:28:11.829][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-4 - Start completed.
""[01:28:11.837][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:28:11.846][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:28:11.869][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:28:11.869][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:28:11.884][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:28:12.044][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:28:12.054][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:28:12.059][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:28:12.059][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:28:12.059][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:28:12.059][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692289692059
""[01:28:12.059][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:28:12.064][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:28:12.066][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:28:12.066][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:28:12.067][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:28:12.068][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 0.708 seconds (JVM running for 277.851)
""[01:28:12.068][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] (Re-)joining group
""[01:28:12.069][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:28:12.073][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:28:12.073][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] (Re-)joining group
""[01:28:12.078][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=50, memberId='consumer-my-consumer-group-4-6726339d-3842-4c34-b4a2-3c2116a43806', protocol='range'}
""[01:28:12.079][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Finished assignment for group at generation 50: {consumer-my-consumer-group-4-6726339d-3842-4c34-b4a2-3c2116a43806=Assignment(partitions=[reservation-topic-0])}
""[01:28:12.084][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=50, memberId='consumer-my-consumer-group-4-6726339d-3842-4c34-b4a2-3c2116a43806', protocol='range'}
""[01:28:12.084][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:28:12.084][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:28:12.089][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:28:12.090][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:28:58.806][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:28:58.823][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:28:58.826][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:28:58.826][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:28:58.827][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Member consumer-my-consumer-group-4-6726339d-3842-4c34-b4a2-3c2116a43806 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:28:58.827][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:28:58.827][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:28:58.827][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:28:58.828][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:28:58.828][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:28:58.832][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:28:58.832][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:28:58.832][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:28:58.833][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-4 unregistered
""[01:28:58.834][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:28:58.834][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:28:58.834][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-4 - Shutdown initiated...
""[01:28:58.836][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-4 - Shutdown completed.
""[01:28:58.926][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 22504 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:28:58.927][DEBUG][com.jinseong.demo.Application.logStarting:line56] - Running with Spring Boot v2.7.15-SNAPSHOT, Spring v5.3.29
""[01:28:58.927][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:28:58.927][DEBUG][org.springframework.boot.SpringApplication.load:line664] - Loading source class com.jinseong.demo.Application
""[01:28:58.930][DEBUG][org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext.prepareRefresh:line629] - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1f8de0ae
""[01:28:58.931][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor'
""[01:28:58.931][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory'
""[01:28:58.941][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\config\WebConfig.class]
""[01:28:58.941][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\config\WebSocketConfig.class]
""[01:28:58.942][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\controller\MainController.class]
""[01:28:58.944][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\handler\SocketHandler.class]
""[01:28:58.944][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line441] - Ignored because not a concrete top-level class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\repository\ReservationRepository.class]
""[01:28:58.945][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\service\KafkaConsumerService.class]
""[01:28:59.163][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:28:59.163][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.AutoConfigurationPackages'
""[01:28:59.163][DEBUG][org.springframework.boot.autoconfigure.AutoConfigurationPackages.get:line196] - @EnableAutoConfiguration was declared on a class in the package 'com.jinseong.demo'. Automatic @Repository and @Entity scanning is enabled.
""[01:28:59.164][DEBUG][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line145] - Scanning for JPA repositories in packages com.jinseong.demo.
""[01:28:59.172][DEBUG][org.springframework.data.repository.config.RepositoryComponentProvider.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\repository\ReservationRepository.class]
""[01:28:59.183][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 18 ms. Found 1 JPA repository interfaces.
""[01:28:59.222][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'propertySourcesPlaceholderConfigurer'
""[01:28:59.223][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'emBeanDefinitionRegistrarPostProcessor'
""[01:28:59.223][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor'
""[01:28:59.223][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.DevToolsDataSourceAutoConfiguration$DatabaseShutdownExecutorEntityManagerFactoryDependsOnPostProcessor'
""[01:28:59.230][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerProcessor'
""[01:28:59.230][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'preserveErrorControllerTargetClassPostProcessor'
""[01:28:59.230][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerFactory'
""[01:28:59.230][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.transaction.config.internalTransactionalEventListenerFactory'
""[01:28:59.231][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor'
""[01:28:59.231][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor'
""[01:28:59.232][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalPersistenceAnnotationProcessor'
""[01:28:59.232][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor'
""[01:28:59.232][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.internalConfigurationPropertiesBinder'
""[01:28:59.233][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.internalConfigurationPropertiesBinderFactory'
""[01:28:59.234][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.aop.config.internalAutoProxyCreator'
""[01:28:59.234][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'persistenceExceptionTranslationPostProcessor'
""[01:28:59.235][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'persistenceExceptionTranslationPostProcessor' via factory method to bean named 'environment'
""[01:28:59.235][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor'
""[01:28:59.236][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webServerFactoryCustomizerBeanPostProcessor'
""[01:28:59.236][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'errorPageRegistrarBeanPostProcessor'
""[01:28:59.236][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'projectingArgumentResolverBeanPostProcessor'
""[01:28:59.237][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.transaction.config.internalTransactionAdvisor'
""[01:28:59.237][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration'
""[01:28:59.239][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionAttributeSource'
""[01:28:59.239][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionInterceptor'
""[01:28:59.239][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'transactionInterceptor' via factory method to bean named 'transactionAttributeSource'
""[01:28:59.240][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.transaction.config.internalTransactionAdvisor' via factory method to bean named 'transactionAttributeSource'
""[01:28:59.240][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.transaction.config.internalTransactionAdvisor' via factory method to bean named 'transactionInterceptor'
""[01:28:59.241][DEBUG][org.springframework.ui.context.support.UiApplicationContextUtils.initThemeSource:line85] - Unable to locate ThemeSource with name 'themeSource': using default [org.springframework.ui.context.support.ResourceBundleThemeSource@58ee1eb1]
""[01:28:59.241][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'tomcatServletWebServerFactory'
""[01:28:59.241][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryConfiguration$EmbeddedTomcat'
""[01:28:59.242][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'websocketServletWebServerCustomizer'
""[01:28:59.243][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration'
""[01:28:59.243][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'servletWebServerFactoryCustomizer'
""[01:28:59.243][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration'
""[01:28:59.243][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:28:59.244][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.BoundConfigurationProperties'
""[01:28:59.249][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'servletWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:28:59.249][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'tomcatServletWebServerFactoryCustomizer'
""[01:28:59.250][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'tomcatServletWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:28:59.250][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'tomcatWebServerFactoryCustomizer'
""[01:28:59.250][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration$TomcatWebServerFactoryCustomizerConfiguration'
""[01:28:59.250][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'tomcatWebServerFactoryCustomizer' via factory method to bean named 'environment'
""[01:28:59.251][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'tomcatWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:28:59.251][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'localeCharsetMappingsCustomizer'
""[01:28:59.251][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration'
""[01:28:59.252][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:28:59.253][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'errorPageCustomizer'
""[01:28:59.253][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration'
""[01:28:59.253][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:28:59.254][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dispatcherServletRegistration'
""[01:28:59.254][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration$DispatcherServletRegistrationConfiguration'
""[01:28:59.254][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dispatcherServlet'
""[01:28:59.255][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration$DispatcherServletConfiguration'
""[01:28:59.255][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
""[01:28:59.257][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dispatcherServlet' via factory method to bean named 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
""[01:28:59.259][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dispatcherServletRegistration' via factory method to bean named 'dispatcherServlet'
""[01:28:59.259][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dispatcherServletRegistration' via factory method to bean named 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
""[01:28:59.260][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'multipartConfigElement'
""[01:28:59.260][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration'
""[01:28:59.260][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.servlet.multipart-org.springframework.boot.autoconfigure.web.servlet.MultipartProperties'
""[01:28:59.261][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration' via constructor to bean named 'spring.servlet.multipart-org.springframework.boot.autoconfigure.web.servlet.MultipartProperties'
""[01:28:59.262][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'errorPageCustomizer' via factory method to bean named 'dispatcherServletRegistration'
""[01:28:59.268][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol port=8080)
""[01:28:59.268][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol bindOnInit=false)
""[01:28:59.268][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.tomcat.util.net.NioEndpoint bindOnInit=false)
""[01:28:59.269][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol maxPostSize=2097152)
""[01:28:59.269][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.tomcat.util.net.NioEndpoint maxPostSize=2097152)
""[01:28:59.269][DEBUG][org.apache.catalina.core.ContainerBase.log:line173] - Add child StandardHost[localhost] StandardEngine[Tomcat]
""[01:28:59.269][DEBUG][org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getArchiveFileDocumentRoot:line81] - Code archive: C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot\2.7.15-SNAPSHOT\spring-boot-2.7.15-SNAPSHOT.jar
""[01:28:59.269][DEBUG][org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getExplodedWarFileDocumentRoot:line125] - Code archive: C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot\2.7.15-SNAPSHOT\spring-boot-2.7.15-SNAPSHOT.jar
""[01:28:59.270][DEBUG][org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.logNoDocumentRoots:line149] - None of the document roots [src/main/webapp, public, static] point to a directory and will be ignored.
""[01:28:59.272][DEBUG][org.apache.catalina.core.ContainerBase.log:line173] - Add child TomcatEmbeddedContext[] StandardEngine[Tomcat].StandardHost[localhost]
""[01:28:59.278][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:28:59.279][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol parseBodyMethods=POST)
""[01:28:59.279][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.tomcat.util.net.NioEndpoint parseBodyMethods=POST)
""[01:28:59.279][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:28:59.279][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:28:59.280][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Starting ROOT
""[01:28:59.286][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Configuring default Resources
""[01:28:59.291][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Processing standard container startup
""[01:28:59.291][DEBUG][org.apache.catalina.loader.WebappLoader.log:line173] - Starting this Loader
""[01:28:59.332][DEBUG][org.apache.catalina.authenticator.AuthenticatorBase.log:line173] - No SingleSignOn Valve is present
""[01:28:59.333][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:28:59.333][DEBUG][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line286] - Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
""[01:28:59.333][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 403 ms
""[01:28:59.334][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'characterEncodingFilter'
""[01:28:59.336][DEBUG][org.springframework.boot.web.servlet.ServletContextInitializerBeans.logMappings:line237] - Mapping filters: characterEncodingFilter urls=[/*] order=-2147483648
""[01:28:59.337][DEBUG][org.springframework.boot.web.servlet.ServletContextInitializerBeans.logMappings:line237] - Mapping servlets: dispatcherServlet urls=[/]
""[01:28:59.337][DEBUG][org.apache.catalina.core.ContainerBase.log:line173] - Add child StandardWrapper[dispatcherServlet] StandardEngine[Tomcat].StandardHost[localhost].TomcatEmbeddedContext[]
""[01:28:59.337][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Configuring application event listeners
""[01:28:59.337][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Sending application start events
""[01:28:59.338][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Start: Loading persisted sessions
""[01:28:59.338][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Loading persisted sessions from [C:\Users\jinsung\AppData\Local\Temp\8B19C3BAB13401F8F1E8E8FA5BBF4BD1C70DE7CC\servlet-sessions\SESSIONS.ser]
""[01:28:59.338][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - No persisted data file found
""[01:28:59.338][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Starting filters
""[01:28:59.338][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Starting filter 'Tomcat WebSocket (JSR356) Filter'
""[01:28:59.339][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Starting filter 'characterEncodingFilter'
""[01:28:59.339][DEBUG][org.springframework.boot.web.servlet.filter.OrderedCharacterEncodingFilter.init:line242] - Filter 'characterEncodingFilter' configured for use
""[01:28:59.339][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Starting completed
""[01:28:59.339][DEBUG][org.apache.catalina.mapper.Mapper.log:line173] - Registered host [localhost]
""[01:28:59.340][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Register Wrapper [dispatcherServlet] in Context [] for service [StandardService[Tomcat]]
""[01:28:59.340][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Register Context [] for service [StandardService[Tomcat]]
""[01:28:59.340][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Register host [localhost] at domain [null] for service [StandardService[Tomcat]]
""[01:28:59.340][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dataSourceScriptDatabaseInitializer'
""[01:28:59.341][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.sql.init.DataSourceInitializationConfiguration'
""[01:28:59.341][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dataSource'
""[01:28:59.341][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration$Hikari'
""[01:28:59.341][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
""[01:28:59.346][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dataSource' via factory method to bean named 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
""[01:28:59.346][DEBUG][com.zaxxer.hikari.HikariConfig.attemptFromContextLoader:line971] - Driver class com.mysql.cj.jdbc.Driver found in Thread context class loader org.springframework.boot.devtools.restart.classloader.RestartClassLoader@37b3e632
""[01:28:59.355][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.sql.init-org.springframework.boot.autoconfigure.sql.init.SqlInitializationProperties'
""[01:28:59.357][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dataSourceScriptDatabaseInitializer' via factory method to bean named 'dataSource'
""[01:28:59.357][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dataSourceScriptDatabaseInitializer' via factory method to bean named 'spring.sql.init-org.springframework.boot.autoconfigure.sql.init.SqlInitializationProperties'
""[01:28:59.358][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'inMemoryDatabaseShutdownExecutor'
""[01:28:59.358][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.DevToolsDataSourceAutoConfiguration'
""[01:28:59.359][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'inMemoryDatabaseShutdownExecutor' via factory method to bean named 'dataSource'
""[01:28:59.359][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'inMemoryDatabaseShutdownExecutor' via factory method to bean named 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
""[01:28:59.359][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'entityManagerFactory'
""[01:28:59.359][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration'
""[01:28:59.360][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jpa-org.springframework.boot.autoconfigure.orm.jpa.JpaProperties'
""[01:28:59.361][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jpa.hibernate-org.springframework.boot.autoconfigure.orm.jpa.HibernateProperties'
""[01:28:59.362][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'dataSource'
""[01:28:59.362][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'spring.jpa-org.springframework.boot.autoconfigure.orm.jpa.JpaProperties'
""[01:28:59.362][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@2de6dbce'
""[01:28:59.362][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'spring.jpa.hibernate-org.springframework.boot.autoconfigure.orm.jpa.HibernateProperties'
""[01:28:59.363][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'hikariPoolDataSourceMetadataProvider'
""[01:28:59.363][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.metadata.DataSourcePoolMetadataProvidersConfiguration$HikariPoolDataSourceMetadataProviderConfiguration'
""[01:28:59.364][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'entityManagerFactoryBuilder'
""[01:28:59.364][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jpaVendorAdapter'
""[01:28:59.365][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'entityManagerFactoryBuilder' via factory method to bean named 'jpaVendorAdapter'
""[01:28:59.366][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'entityManagerFactory' via factory method to bean named 'entityManagerFactoryBuilder'
""[01:28:59.366][DEBUG][org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection:line117] - Fetching JDBC Connection from DataSource
""[01:28:59.366][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1103] - HikariPool-5 - configuration:
""[01:28:59.368][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - allowPoolSuspension................................false
""[01:28:59.368][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - autoCommit................................true
""[01:28:59.368][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - catalog................................none
""[01:28:59.368][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - connectionInitSql................................none
""[01:28:59.368][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - connectionTestQuery................................none
""[01:28:59.368][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - connectionTimeout................................30000
""[01:28:59.368][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSource................................none
""[01:28:59.368][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSourceClassName................................none
""[01:28:59.369][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSourceJNDI................................none
""[01:28:59.369][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSourceProperties................................{password=<masked>}
""[01:28:59.369][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - driverClassName................................"com.mysql.cj.jdbc.Driver"
""[01:28:59.369][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - exceptionOverrideClassName................................none
""[01:28:59.369][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - healthCheckProperties................................{}
""[01:28:59.369][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - healthCheckRegistry................................none
""[01:28:59.369][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - idleTimeout................................600000
""[01:28:59.370][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - initializationFailTimeout................................1
""[01:28:59.370][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - isolateInternalQueries................................false
""[01:28:59.370][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - jdbcUrl................................jdbc:mysql://localhost:3306/metadb?useSSL=false&serverTimezone=UTC&useLegacyDatetimeCode=false&allowPublicKeyRetrieval=true
""[01:28:59.370][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - keepaliveTime................................0
""[01:28:59.370][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - leakDetectionThreshold................................0
""[01:28:59.370][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - maxLifetime................................1800000
""[01:28:59.370][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - maximumPoolSize................................10
""[01:28:59.370][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - metricRegistry................................none
""[01:28:59.370][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - metricsTrackerFactory................................none
""[01:28:59.370][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - minimumIdle................................10
""[01:28:59.371][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - password................................<masked>
""[01:28:59.371][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - poolName................................"HikariPool-5"
""[01:28:59.371][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - readOnly................................false
""[01:28:59.371][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - registerMbeans................................false
""[01:28:59.371][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - scheduledExecutor................................none
""[01:28:59.371][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - schema................................none
""[01:28:59.371][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - threadFactory................................internal
""[01:28:59.371][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - transactionIsolation................................default
""[01:28:59.371][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - username................................"root"
""[01:28:59.371][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - validationTimeout................................5000
""[01:28:59.371][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-5 - Starting...
""[01:28:59.382][DEBUG][com.zaxxer.hikari.pool.HikariPool.checkFailFast:line565] - HikariPool-5 - Added connection com.mysql.cj.jdbc.ConnectionImpl@7be05c42
""[01:28:59.382][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-5 - Start completed.
""[01:28:59.390][DEBUG][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory:line361] - Building JPA container EntityManagerFactory for persistence unit 'default'
""[01:28:59.391][DEBUG][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line102] - PersistenceUnitInfo [
	name: default
	persistence provider classname: null
	classloader: org.springframework.boot.devtools.restart.classloader.RestartClassLoader@37b3e632
	excludeUnlistedClasses: true
	JTA datasource: null
	Non JTA datasource: HikariDataSource (HikariPool-5)
	Transaction type: RESOURCE_LOCAL
	PU root URL: file:/C:/Users/jinsung/Documents/GitHub/RMS/demo/target/classes/
	Shared Cache Mode: UNSPECIFIED
	Validation Mode: AUTO
	Jar files URLs []
	Managed classes names [
		com.jinseong.demo.entity.Reservation]
	Mapping files names []
	Properties []
""[01:28:59.391][DEBUG][org.hibernate.integrator.internal.IntegratorServiceImpl.addIntegrator:line46] - Adding Integrator [org.hibernate.cfg.beanvalidation.BeanValidationIntegrator].
""[01:28:59.391][DEBUG][org.hibernate.integrator.internal.IntegratorServiceImpl.addIntegrator:line46] - Adding Integrator [org.hibernate.secure.spi.JaccIntegrator].
""[01:28:59.391][DEBUG][org.hibernate.integrator.internal.IntegratorServiceImpl.addIntegrator:line46] - Adding Integrator [org.hibernate.cache.internal.CollectionCacheInvalidator].
""[01:28:59.394][DEBUG][org.hibernate.service.spi.ServiceBinding.setService:line68] - Overriding existing service binding [org.hibernate.secure.spi.JaccService]
""[01:28:59.394][DEBUG][org.hibernate.cache.internal.RegionFactoryInitiator.resolveRegionFactory:line118] - Cannot default RegionFactory based on registered strategies as `[]` RegionFactory strategies were registered
""[01:28:59.395][DEBUG][org.hibernate.cache.internal.RegionFactoryInitiator.initiateService:line49] - Cache region factory : org.hibernate.cache.internal.NoCachingRegionFactory
""[01:28:59.395][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration boolean -> org.hibernate.type.BooleanType@65249d16
""[01:28:59.395][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration boolean -> org.hibernate.type.BooleanType@65249d16
""[01:28:59.395][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Boolean -> org.hibernate.type.BooleanType@65249d16
""[01:28:59.395][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration numeric_boolean -> org.hibernate.type.NumericBooleanType@59548376
""[01:28:59.395][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration true_false -> org.hibernate.type.TrueFalseType@a92c074
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration yes_no -> org.hibernate.type.YesNoType@59827e7b
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration byte -> org.hibernate.type.ByteType@180f8470
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration byte -> org.hibernate.type.ByteType@180f8470
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Byte -> org.hibernate.type.ByteType@180f8470
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration character -> org.hibernate.type.CharacterType@653deb34
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration char -> org.hibernate.type.CharacterType@653deb34
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Character -> org.hibernate.type.CharacterType@653deb34
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration short -> org.hibernate.type.ShortType@79300687
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration short -> org.hibernate.type.ShortType@79300687
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Short -> org.hibernate.type.ShortType@79300687
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration integer -> org.hibernate.type.IntegerType@338bde7c
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration int -> org.hibernate.type.IntegerType@338bde7c
""[01:28:59.396][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Integer -> org.hibernate.type.IntegerType@338bde7c
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration long -> org.hibernate.type.LongType@5743e079
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration long -> org.hibernate.type.LongType@5743e079
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Long -> org.hibernate.type.LongType@5743e079
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration float -> org.hibernate.type.FloatType@5d2dc5ee
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration float -> org.hibernate.type.FloatType@5d2dc5ee
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Float -> org.hibernate.type.FloatType@5d2dc5ee
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration double -> org.hibernate.type.DoubleType@24d0f4f2
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration double -> org.hibernate.type.DoubleType@24d0f4f2
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Double -> org.hibernate.type.DoubleType@24d0f4f2
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration big_decimal -> org.hibernate.type.BigDecimalType@4945a62a
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.math.BigDecimal -> org.hibernate.type.BigDecimalType@4945a62a
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration big_integer -> org.hibernate.type.BigIntegerType@14dc753
""[01:28:59.397][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.math.BigInteger -> org.hibernate.type.BigIntegerType@14dc753
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration string -> org.hibernate.type.StringType@327c7021
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.String -> org.hibernate.type.StringType@327c7021
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration nstring -> org.hibernate.type.StringNVarcharType@112865f8
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration ncharacter -> org.hibernate.type.CharacterNCharType@7538e501
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration url -> org.hibernate.type.UrlType@1a20c3aa
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.net.URL -> org.hibernate.type.UrlType@1a20c3aa
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Duration -> org.hibernate.type.DurationType@4b0c45b7
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.Duration -> org.hibernate.type.DurationType@4b0c45b7
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Instant -> org.hibernate.type.InstantType@1959fe8b
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.Instant -> org.hibernate.type.InstantType@1959fe8b
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration LocalDateTime -> org.hibernate.type.LocalDateTimeType@2bfb104c
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.LocalDateTime -> org.hibernate.type.LocalDateTimeType@2bfb104c
""[01:28:59.398][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration LocalDate -> org.hibernate.type.LocalDateType@37dabb0a
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.LocalDate -> org.hibernate.type.LocalDateType@37dabb0a
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration LocalTime -> org.hibernate.type.LocalTimeType@1e5261bb
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.LocalTime -> org.hibernate.type.LocalTimeType@1e5261bb
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration OffsetDateTime -> org.hibernate.type.OffsetDateTimeType@48a9795c
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.OffsetDateTime -> org.hibernate.type.OffsetDateTimeType@48a9795c
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration OffsetTime -> org.hibernate.type.OffsetTimeType@3b236975
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.OffsetTime -> org.hibernate.type.OffsetTimeType@3b236975
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration ZonedDateTime -> org.hibernate.type.ZonedDateTimeType@59c387f0
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.ZonedDateTime -> org.hibernate.type.ZonedDateTimeType@59c387f0
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration date -> org.hibernate.type.DateType@54917aca
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Date -> org.hibernate.type.DateType@54917aca
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration time -> org.hibernate.type.TimeType@57719a9d
""[01:28:59.399][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Time -> org.hibernate.type.TimeType@57719a9d
""[01:28:59.400][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration timestamp -> org.hibernate.type.TimestampType@773939c7
""[01:28:59.400][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Timestamp -> org.hibernate.type.TimestampType@773939c7
""[01:28:59.400][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Date -> org.hibernate.type.TimestampType@773939c7
""[01:28:59.400][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration dbtimestamp -> org.hibernate.type.DbTimestampType@3200ccd7
""[01:28:59.400][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration calendar -> org.hibernate.type.CalendarType@6d18b777
""[01:28:59.400][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Calendar -> org.hibernate.type.CalendarType@6d18b777
""[01:28:59.400][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.GregorianCalendar -> org.hibernate.type.CalendarType@6d18b777
""[01:28:59.400][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration calendar_date -> org.hibernate.type.CalendarDateType@36667d3b
""[01:28:59.400][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration calendar_time -> org.hibernate.type.CalendarTimeType@82f8d31
""[01:28:59.400][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration locale -> org.hibernate.type.LocaleType@3cfd8e97
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Locale -> org.hibernate.type.LocaleType@3cfd8e97
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration currency -> org.hibernate.type.CurrencyType@14762570
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Currency -> org.hibernate.type.CurrencyType@14762570
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration timezone -> org.hibernate.type.TimeZoneType@11fc0d60
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.TimeZone -> org.hibernate.type.TimeZoneType@11fc0d60
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration class -> org.hibernate.type.ClassType@654e4c6b
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Class -> org.hibernate.type.ClassType@654e4c6b
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration uuid-binary -> org.hibernate.type.UUIDBinaryType@3517ef63
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.UUID -> org.hibernate.type.UUIDBinaryType@3517ef63
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration uuid-char -> org.hibernate.type.UUIDCharType@10ef1114
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration binary -> org.hibernate.type.BinaryType@61899964
""[01:28:59.401][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration byte[] -> org.hibernate.type.BinaryType@61899964
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [B -> org.hibernate.type.BinaryType@61899964
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration wrapper-binary -> org.hibernate.type.WrapperBinaryType@7633ac2a
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Byte[] -> org.hibernate.type.WrapperBinaryType@7633ac2a
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [Ljava.lang.Byte; -> org.hibernate.type.WrapperBinaryType@7633ac2a
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration row_version -> org.hibernate.type.RowVersionType@7cd52978
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration image -> org.hibernate.type.ImageType@145af047
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration characters -> org.hibernate.type.CharArrayType@39351911
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration char[] -> org.hibernate.type.CharArrayType@39351911
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [C -> org.hibernate.type.CharArrayType@39351911
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration wrapper-characters -> org.hibernate.type.CharacterArrayType@520ca0e1
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [Ljava.lang.Character; -> org.hibernate.type.CharacterArrayType@520ca0e1
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Character[] -> org.hibernate.type.CharacterArrayType@520ca0e1
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration text -> org.hibernate.type.TextType@747cd31
""[01:28:59.402][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration ntext -> org.hibernate.type.NTextType@44dcdd56
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration blob -> org.hibernate.type.BlobType@5530b94d
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Blob -> org.hibernate.type.BlobType@5530b94d
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration materialized_blob -> org.hibernate.type.MaterializedBlobType@628c10a2
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration clob -> org.hibernate.type.ClobType@5b9b6787
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Clob -> org.hibernate.type.ClobType@5b9b6787
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration nclob -> org.hibernate.type.NClobType@790f27cf
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.NClob -> org.hibernate.type.NClobType@790f27cf
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration materialized_clob -> org.hibernate.type.MaterializedClobType@29250372
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration materialized_nclob -> org.hibernate.type.MaterializedNClobType@2bae1ff4
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration serializable -> org.hibernate.type.SerializableType@2b09e259
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration object -> org.hibernate.type.ObjectType@2b3889a8
""[01:28:59.403][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Object -> org.hibernate.type.ObjectType@2b3889a8
""[01:28:59.404][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_date -> org.hibernate.type.AdaptedImmutableType@2a87212e
""[01:28:59.404][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_time -> org.hibernate.type.AdaptedImmutableType@718dda35
""[01:28:59.406][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_timestamp -> org.hibernate.type.AdaptedImmutableType@15f2f577
""[01:28:59.406][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_dbtimestamp -> org.hibernate.type.AdaptedImmutableType@7a685ba8
""[01:28:59.406][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_calendar -> org.hibernate.type.AdaptedImmutableType@69758b9a
""[01:28:59.406][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_calendar_date -> org.hibernate.type.AdaptedImmutableType@76b6b8f3
""[01:28:59.406][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_binary -> org.hibernate.type.AdaptedImmutableType@74eda21f
""[01:28:59.406][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_serializable -> org.hibernate.type.AdaptedImmutableType@4c600231
""[01:28:59.409][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectJpaTempClassLoader:line259] - Injecting JPA temp ClassLoader [org.springframework.instrument.classloading.SimpleThrowawayClassLoader@4abe298e] into BootstrapContext; was [null]
""[01:28:59.410][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.injectTempClassLoader:line45] - ClassLoaderAccessImpl#injectTempClassLoader(org.springframework.instrument.classloading.SimpleThrowawayClassLoader@4abe298e) [was null]
""[01:28:59.410][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectScanEnvironment:line269] - Injecting ScanEnvironment [org.hibernate.jpa.boot.internal.StandardJpaScanEnvironmentImpl@535a979c] into BootstrapContext; was [null]
""[01:28:59.410][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectScanOptions:line264] - Injecting ScanOptions [org.hibernate.boot.archive.scan.internal.StandardScanOptions@1f67764c] into BootstrapContext; was [org.hibernate.boot.archive.scan.internal.StandardScanOptions@75ca3b45]
""[01:28:59.411][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectJpaTempClassLoader:line259] - Injecting JPA temp ClassLoader [null] into BootstrapContext; was [org.springframework.instrument.classloading.SimpleThrowawayClassLoader@4abe298e]
""[01:28:59.411][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.injectTempClassLoader:line45] - ClassLoaderAccessImpl#injectTempClassLoader(null) [was org.springframework.instrument.classloading.SimpleThrowawayClassLoader@4abe298e]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [uuid2] -> [org.hibernate.id.UUIDGenerator]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [guid] -> [org.hibernate.id.GUIDGenerator]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [uuid] -> [org.hibernate.id.UUIDHexGenerator]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [uuid.hex] -> [org.hibernate.id.UUIDHexGenerator]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [assigned] -> [org.hibernate.id.Assigned]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [identity] -> [org.hibernate.id.IdentityGenerator]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [select] -> [org.hibernate.id.SelectGenerator]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [sequence] -> [org.hibernate.id.enhanced.SequenceStyleGenerator]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [seqhilo] -> [org.hibernate.id.SequenceHiLoGenerator]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [increment] -> [org.hibernate.id.IncrementGenerator]
""[01:28:59.411][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [foreign] -> [org.hibernate.id.ForeignGenerator]
""[01:28:59.412][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [sequence-identity] -> [org.hibernate.id.SequenceIdentityGenerator]
""[01:28:59.412][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [enhanced-sequence] -> [org.hibernate.id.enhanced.SequenceStyleGenerator]
""[01:28:59.412][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [enhanced-table] -> [org.hibernate.id.enhanced.TableGenerator]
""[01:28:59.412][DEBUG][org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.initiateService:line72] - Database ->
       name : MySQL
    version : 8.0.34
      major : 8
      minor : 0
""[01:28:59.412][DEBUG][org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.initiateService:line83] - Driver ->
       name : MySQL Connector/J
    version : mysql-connector-java-8.0.27 (Revision: e920b979015ae7117d60d72bcc8f077a839cd791)
      major : 8
      minor : 0
""[01:28:59.412][DEBUG][org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.debugf:line389] - JDBC version : 4.2
""[01:28:59.412][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:28:59.413][DEBUG][org.hibernate.engine.jdbc.env.spi.IdentifierHelperBuilder.applyIdentifierCasing:line119] - JDBC driver metadata reported database stores quoted identifiers in more than one case
""[01:28:59.413][DEBUG][org.hibernate.engine.jdbc.env.spi.IdentifierHelperBuilder.build:line197] - IdentifierCaseStrategy for both quoted and unquoted identifiers was set to the same strategy [MIXED]; that will likely lead to problems in schema update and validation if using quoted identifiers
""[01:28:59.414][DEBUG][org.hibernate.type.spi.TypeConfiguration$Scope.scope:line149] - Scoping TypeConfiguration [org.hibernate.type.spi.TypeConfiguration@4e038e2b] to MetadataBuildingContext [org.hibernate.boot.internal.MetadataBuildingContextRootImpl@49e20600]
""[01:28:59.414][DEBUG][org.hibernate.boot.model.relational.Namespace.<init>:line51] - Created database namespace [logicalName=Name{catalog=null, schema=null}, physicalName=Name{catalog=null, schema=null}]
""[01:28:59.414][DEBUG][org.hibernate.cfg.AnnotationBinder.bindClass:line547] - Binding entity from annotated class: com.jinseong.demo.entity.Reservation
""[01:28:59.415][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3DiscriminatorColumn{logicalColumnName'DTYPE', discriminatorTypeName='string'}
""[01:28:59.415][DEBUG][org.hibernate.cfg.annotations.EntityBinder.bindEntity:line431] - Import with entity name Reservation
""[01:28:59.415][DEBUG][org.hibernate.cfg.annotations.EntityBinder.bindTable:line874] - Bind entity com.jinseong.demo.entity.Reservation on table reservation
""[01:28:59.417][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=reservation_id, insertable=true, updatable=true, unique=false}
""[01:28:59.417][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line60] - Not known whether passed class name [com.jinseong.demo.entity.Reservation] is safe
""[01:28:59.417][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line62] - No temp ClassLoader provided; using live ClassLoader for loading potentially unsafe class : com.jinseong.demo.entity.Reservation
""[01:28:59.417][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property id with lazy=false
""[01:28:59.417][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:id]
""[01:28:59.417][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for id
""[01:28:59.417][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property id
""[01:28:59.418][DEBUG][org.hibernate.cfg.BinderHelper.makeIdGenerator:line514] - #makeIdGenerator(org.hibernate.mapping.SimpleValue([org.hibernate.mapping.Column(reservation_id)]), id, identity, , ...)
""[01:28:59.418][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=count, insertable=true, updatable=true, unique=false}
""[01:28:59.418][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property count with lazy=false
""[01:28:59.418][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:count]
""[01:28:59.418][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for count
""[01:28:59.418][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property count
""[01:28:59.418][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=date, insertable=true, updatable=true, unique=false}
""[01:28:59.418][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property date with lazy=false
""[01:28:59.418][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:date]
""[01:28:59.418][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for date
""[01:28:59.418][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property date
""[01:28:59.419][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=name, insertable=true, updatable=true, unique=false}
""[01:28:59.419][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property name with lazy=false
""[01:28:59.419][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:name]
""[01:28:59.419][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for name
""[01:28:59.419][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property name
""[01:28:59.419][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=number, insertable=true, updatable=true, unique=false}
""[01:28:59.419][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property number with lazy=false
""[01:28:59.419][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:number]
""[01:28:59.419][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for number
""[01:28:59.419][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property number
""[01:28:59.419][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=time, insertable=true, updatable=true, unique=false}
""[01:28:59.420][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property time with lazy=false
""[01:28:59.420][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:time]
""[01:28:59.420][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for time
""[01:28:59.420][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property time
""[01:28:59.421][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for id
""[01:28:59.421][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for count
""[01:28:59.422][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for date
""[01:28:59.422][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for name
""[01:28:59.422][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for number
""[01:28:59.422][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for time
""[01:28:59.422][DEBUG][org.hibernate.mapping.PrimaryKey.addColumn:line36] - Forcing column [reservation_id] to be non-null as it is part of the primary key for table [reservation]
""[01:28:59.424][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line208] - Building session factory
""[01:28:59.424][DEBUG][org.hibernate.cfg.Settings.<init>:line68] - SessionFactory name : null
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line69] - Automatic flush during beforeCompletion(): enabled
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line70] - Automatic session close at end of transaction: disabled
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line72] - Statistics: disabled
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line74] - Deleted entity synthetic identifier rollback: disabled
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line75] - Default entity-mode: pojo
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line76] - Check Nullability in Core (should be disabled when Bean Validation is on): enabled
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line77] - Allow initialization of lazy state outside session : disabled
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line79] - Using BatchFetchStyle : LEGACY
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line80] - Default batch fetch size: -1
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line81] - Maximum outer join fetch depth: 2
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line82] - Default null ordering: NONE
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line83] - Order SQL updates by primary key: disabled
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line84] - Order SQL inserts for batching: disabled
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line86] - multi-tenancy strategy : NONE
""[01:28:59.425][DEBUG][org.hibernate.cfg.Settings.<init>:line88] - JTA Track by Thread: enabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line90] - Query language substitutions: {}
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line91] - Named query checking : enabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line93] - Second-level cache: disabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line94] - Second-level query cache: disabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line95] - Second-level query cache factory: null
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line96] - Second-level cache region prefix: null
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line97] - Optimize second-level cache for minimal puts: disabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line98] - Structured second-level cache entries: disabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line99] - Second-level cache direct-reference entries: disabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line100] - Automatic eviction of collection cache: disabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line102] - JDBC batch size: 15
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line103] - JDBC batch updates for versioned data: enabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line104] - Scrollable result sets: enabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line105] - Wrap result sets: disabled
""[01:28:59.426][DEBUG][org.hibernate.cfg.Settings.<init>:line106] - JDBC3 getGeneratedKeys(): enabled
""[01:28:59.427][DEBUG][org.hibernate.cfg.Settings.<init>:line107] - JDBC result set fetch size: null
""[01:28:59.427][DEBUG][org.hibernate.cfg.Settings.<init>:line108] - Connection release mode: ON_CLOSE
""[01:28:59.427][DEBUG][org.hibernate.cfg.Settings.<init>:line109] - Generate SQL with comments: disabled
""[01:28:59.427][DEBUG][org.hibernate.cfg.Settings.<init>:line111] - JPA compliance - query : disabled
""[01:28:59.427][DEBUG][org.hibernate.cfg.Settings.<init>:line112] - JPA compliance - closed-handling : disabled
""[01:28:59.427][DEBUG][org.hibernate.cfg.Settings.<init>:line113] - JPA compliance - lists : disabled
""[01:28:59.427][DEBUG][org.hibernate.cfg.Settings.<init>:line114] - JPA compliance - transactions : disabled
""[01:28:59.429][DEBUG][org.hibernate.service.internal.SessionFactoryServiceRegistryImpl.getService:line92] - EventListenerRegistry access via ServiceRegistry is deprecated.  Use `sessionFactory.getEventEngine().getListenerRegistry()` instead
""[01:28:59.429][DEBUG][org.hibernate.service.internal.SessionFactoryServiceRegistryImpl.getService:line92] - EventListenerRegistry access via ServiceRegistry is deprecated.  Use `sessionFactory.getEventEngine().getListenerRegistry()` instead
""[01:28:59.430][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line276] - Session factory constructed with filter configurations : {}
""[01:28:59.430][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line277] - Instantiating session factory with properties: {hibernate.id.new_generator_mappings=true, java.specification.version=17, sun.cpu.isalist=amd64, hibernate.resource.beans.container=org.springframework.orm.hibernate5.SpringBeanContainer@4927d282, hibernate.connection.handling_mode=DELAYED_ACQUISITION_AND_HOLD, sun.jnu.encoding=MS949, hibernate.implicit_naming_strategy=org.springframework.boot.orm.jpa.hibernate.SpringImplicitNamingStrategy, java.class.path=C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-web\2.7.15-SNAPSHOT\spring-boot-starter-web-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter\2.7.15-SNAPSHOT\spring-boot-starter-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-logging\2.7.15-SNAPSHOT\spring-boot-starter-logging-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\ch\qos\logback\logback-classic\1.2.12\logback-classic-1.2.12.jar;C:\Users\jinsung\.m2\repository\ch\qos\logback\logback-core\1.2.12\logback-core-1.2.12.jar;C:\Users\jinsung\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.17.2\log4j-to-slf4j-2.17.2.jar;C:\Users\jinsung\.m2\repository\org\apache\logging\log4j\log4j-api\2.17.2\log4j-api-2.17.2.jar;C:\Users\jinsung\.m2\repository\org\slf4j\jul-to-slf4j\1.7.36\jul-to-slf4j-1.7.36.jar;C:\Users\jinsung\.m2\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;C:\Users\jinsung\.m2\repository\org\yaml\snakeyaml\1.30\snakeyaml-1.30.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-json\2.7.15-SNAPSHOT\spring-boot-starter-json-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.13.5\jackson-databind-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.13.5\jackson-annotations-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.13.5\jackson-core-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.13.5\jackson-datatype-jdk8-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.13.5\jackson-datatype-jsr310-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.13.5\jackson-module-parameter-names-2.13.5.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat\2.7.15-SNAPSHOT\spring-boot-starter-tomcat-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.78\tomcat-embed-core-9.0.78.jar;C:\Users\jinsung\.m2\repository\org\apache\tomcat\embed\tomcat-embed-el\9.0.78\tomcat-embed-el-9.0.78.jar;C:\Users\jinsung\.m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.78\tomcat-embed-websocket-9.0.78.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-web\5.3.29\spring-web-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-beans\5.3.29\spring-beans-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-webmvc\5.3.29\spring-webmvc-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-aop\5.3.29\spring-aop-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-expression\5.3.29\spring-expression-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-devtools\2.7.15-SNAPSHOT\spring-boot-devtools-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot\2.7.15-SNAPSHOT\spring-boot-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\2.7.15-SNAPSHOT\spring-boot-autoconfigure-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\projectlombok\lombok\1.18.28\lombok-1.18.28.jar;C:\Users\jinsung\.m2\repository\org\slf4j\slf4j-api\1.7.36\slf4j-api-1.7.36.jar;C:\Users\jinsung\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\2.3.3\jakarta.xml.bind-api-2.3.3.jar;C:\Users\jinsung\.m2\repository\jakarta\activation\jakarta.activation-api\1.2.2\jakarta.activation-api-1.2.2.jar;C:\Users\jinsung\.m2\repository\net\bytebuddy\byte-buddy\1.12.23\byte-buddy-1.12.23.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-core\5.3.29\spring-core-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-jcl\5.3.29\spring-jcl-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-thymeleaf\2.7.15-SNAPSHOT\spring-boot-starter-thymeleaf-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\thymeleaf\thymeleaf-spring5\3.0.15.RELEASE\thymeleaf-spring5-3.0.15.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\thymeleaf\thymeleaf\3.0.15.RELEASE\thymeleaf-3.0.15.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\attoparser\attoparser\2.0.5.RELEASE\attoparser-2.0.5.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\unbescape\unbescape\1.1.6.RELEASE\unbescape-1.1.6.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\thymeleaf\extras\thymeleaf-extras-java8time\3.0.4.RELEASE\thymeleaf-extras-java8time-3.0.4.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\springframework\kafka\spring-kafka\2.8.11\spring-kafka-2.8.11.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-context\5.3.29\spring-context-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-messaging\5.3.29\spring-messaging-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-tx\5.3.29\spring-tx-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\retry\spring-retry\1.3.4\spring-retry-1.3.4.jar;C:\Users\jinsung\.m2\repository\org\apache\kafka\kafka-clients\3.1.2\kafka-clients-3.1.2.jar;C:\Users\jinsung\.m2\repository\com\github\luben\zstd-jni\1.5.0-4\zstd-jni-1.5.0-4.jar;C:\Users\jinsung\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\jinsung\.m2\repository\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\Users\jinsung\.m2\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-data-jpa\2.7.15-SNAPSHOT\spring-boot-starter-data-jpa-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-aop\2.7.15-SNAPSHOT\spring-boot-starter-aop-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\aspectj\aspectjweaver\1.9.7\aspectjweaver-1.9.7.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\2.7.15-SNAPSHOT\spring-boot-starter-jdbc-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\com\zaxxer\HikariCP\4.0.3\HikariCP-4.0.3.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-jdbc\5.3.29\spring-jdbc-5.3.29.jar;C:\Users\jinsung\.m2\repository\jakarta\transaction\jakarta.transaction-api\1.3.3\jakarta.transaction-api-1.3.3.jar;C:\Users\jinsung\.m2\repository\jakarta\persistence\jakarta.persistence-api\2.2.3\jakarta.persistence-api-2.2.3.jar;C:\Users\jinsung\.m2\repository\org\hibernate\hibernate-core\5.6.15.Final\hibernate-core-5.6.15.Final.jar;C:\Users\jinsung\.m2\repository\org\jboss\logging\jboss-logging\3.4.3.Final\jboss-logging-3.4.3.Final.jar;C:\Users\jinsung\.m2\repository\antlr\antlr\2.7.7\antlr-2.7.7.jar;C:\Users\jinsung\.m2\repository\org\jboss\jandex\2.4.2.Final\jandex-2.4.2.Final.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\jinsung\.m2\repository\org\hibernate\common\hibernate-commons-annotations\5.1.2.Final\hibernate-commons-annotations-5.1.2.Final.jar;C:\Users\jinsung\.m2\repository\org\glassfish\jaxb\jaxb-runtime\2.3.8\jaxb-runtime-2.3.8.jar;C:\Users\jinsung\.m2\repository\org\glassfish\jaxb\txw2\2.3.8\txw2-2.3.8.jar;C:\Users\jinsung\.m2\repository\com\sun\istack\istack-commons-runtime\3.0.12\istack-commons-runtime-3.0.12.jar;C:\Users\jinsung\.m2\repository\com\sun\activation\jakarta.activation\1.2.2\jakarta.activation-1.2.2.jar;C:\Users\jinsung\.m2\repository\org\springframework\data\spring-data-jpa\2.7.15-SNAPSHOT\spring-data-jpa-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\data\spring-data-commons\2.7.15-SNAPSHOT\spring-data-commons-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-orm\5.3.29\spring-orm-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-aspects\5.3.29\spring-aspects-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-websocket\2.7.15-SNAPSHOT\spring-boot-starter-websocket-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-websocket\5.3.29\spring-websocket-5.3.29.jar;C:\Users\jinsung\.m2\repository\mysql\mysql-connector-java\8.0.27\mysql-connector-java-8.0.27.jar;C:\Users\jinsung\.m2\repository\com\google\protobuf\protobuf-java\3.11.4\protobuf-java-3.11.4.jar, com.sun.management.jmxremote.authenticate=false, java.vm.vendor=Eclipse Adoptium, sun.arch.data.model=64, user.variant=, java.vendor.url=https://adoptium.net/, catalina.useNaming=false, user.timezone=Asia/Seoul, jakarta.persistence.sharedCache.mode=UNSPECIFIED, java.vm.specification.version=17, os.name=Windows 10, javax.persistence.validation.mode=AUTO, jakarta.persistence.nonJtaDataSource=HikariDataSource (HikariPool-5), sun.java.launcher=SUN_STANDARD, user.country=KR, sun.boot.library.path=C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin, com.sun.management.jmxremote.ssl=false, sun.java.command=com.jinseong.demo.Application --spring.output.ansi.enabled=always, spring.application.admin.enabled=true, javax.persistence.nonJtaDataSource=HikariDataSource (HikariPool-5), hibernate.transaction.jta.platform=org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform@1b876f5b, com.sun.management.jmxremote=, javax.persistence.sharedCache.mode=UNSPECIFIED, jdk.debug=release, sun.cpu.endian=little, spring.boot.project.name=demo, user.home=C:\Users\jinsung, user.language=ko, java.specification.vendor=Oracle Corporation, java.version.date=2023-01-17, java.home=C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre, file.separator=\, java.vm.compressedOopsMode=Zero based, line.separator=
, hibernate.persistenceUnitName=default, java.vm.specification.vendor=Oracle Corporation, java.specification.name=Java Platform API Specification, FILE_LOG_CHARSET=UTF-8, hibernate.transaction.coordinator_class=class org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorBuilderImpl, java.awt.headless=true, jakarta.persistence.validation.mode=AUTO, user.script=, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, java.runtime.version=17.0.6+10, user.name=jinsung, spring.jmx.enabled=true, path.separator=;, management.endpoints.jmx.exposure.include=*, os.version=10.0, java.runtime.name=OpenJDK Runtime Environment, file.encoding=UTF-8, hibernate.ejb.persistenceUnitName=default, spring.beaninfo.ignore=true, java.vm.name=OpenJDK 64-Bit Server VM, java.vendor.version=Temurin-17.0.6+10, java.vendor.url.bug=https://github.com/adoptium/adoptium-support/issues, java.io.tmpdir=C:\Users\jinsung\AppData\Local\Temp\, com.zaxxer.hikari.pool_number=1, catalina.home=C:\Users\jinsung\AppData\Local\Temp\tomcat.8080.8212133563761113161, com.sun.management.jmxremote.port=50267, java.version=17.0.6, hibernate.physical_naming_strategy=org.hibernate.boot.model.naming.CamelCaseToUnderscoresNamingStrategy, user.dir=C:\Users\jinsung\Documents\GitHub\RMS\demo, os.arch=amd64, java.vm.specification.name=Java Virtual Machine Specification, PID=22504, sun.os.patch.level=, CONSOLE_LOG_CHARSET=UTF-8, catalina.base=C:\Users\jinsung\AppData\Local\Temp\tomcat.8080.8212133563761113161, hibernate.boot.CfgXmlAccessService.key=org.hibernate.boot.registry.StandardServiceRegistryBuilder$1@428cb82d, native.encoding=MS949, java.library.path=C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;., java.vendor=Eclipse Adoptium, java.vm.info=mixed mode, emulated-client, java.vm.version=17.0.6+10, hibernate.bytecode.use_reflection_optimizer=false, java.rmi.server.randomIDs=true, java.rmi.server.hostname=localhost, sun.io.unicode.encoding=UnicodeLittle, hibernate.archive.scanner=org.hibernate.boot.archive.scan.internal.DisabledScanner, hibernate.connection.datasource=HikariDataSource (HikariPool-5), java.class.version=61.0}
""[01:28:59.432][DEBUG][org.hibernate.secure.spi.JaccIntegrator.doIntegration:line84] - Skipping JACC integration as it was not enabled
""[01:28:59.432][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line316] - Instantiated session factory
""[01:28:59.432][DEBUG][org.hibernate.type.spi.TypeConfiguration$Scope.scope:line154] - Scoping TypeConfiguration [org.hibernate.type.spi.TypeConfiguration@4e038e2b] to SessionFactoryImpl [org.hibernate.internal.SessionFactoryImpl@310f3cf6]
""[01:28:59.432][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line60] - Not known whether passed class name [com.jinseong.demo.entity.Reservation] is safe
""[01:28:59.433][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line62] - No temp ClassLoader provided; using live ClassLoader for loading potentially unsafe class : com.jinseong.demo.entity.Reservation
""[01:28:59.440][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4031] - Static SQL for entity: com.jinseong.demo.entity.Reservation
""[01:28:59.441][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4036] -  Version select: select reservation_id from reservation where reservation_id =?
""[01:28:59.441][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4039] -  Snapshot select: select reservatio_.reservation_id, reservatio_.count as count2_0_, reservatio_.date as date3_0_, reservatio_.name as name4_0_, reservatio_.number as number5_0_, reservatio_.time as time6_0_ from reservation reservatio_ where reservatio_.reservation_id=?
""[01:28:59.441][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.debugf:line394] -  Insert 0: insert into reservation (count, date, name, number, time, reservation_id) values (?, ?, ?, ?, ?, ?)
""[01:28:59.441][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.debugf:line394] -  Update 0: update reservation set count=?, date=?, name=?, number=?, time=? where reservation_id=?
""[01:28:59.441][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.debugf:line394] -  Delete 0: delete from reservation where reservation_id=?
""[01:28:59.441][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4047] -  Identity insert: insert into reservation (count, date, name, number, time) values (?, ?, ?, ?, ?)
""[01:28:59.441][DEBUG][org.hibernate.loader.plan.build.internal.spaces.QuerySpacesImpl.registerQuerySpace:line174] - Adding QuerySpace : uid = <gen:0> -> org.hibernate.loader.plan.build.internal.spaces.EntityQuerySpaceImpl@2f16b7ab]
""[01:28:59.441][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : count
""[01:28:59.441][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : date
""[01:28:59.441][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : name
""[01:28:59.442][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : number
""[01:28:59.442][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : time
""[01:28:59.442][DEBUG][org.hibernate.loader.plan.build.internal.FetchStyleLoadPlanBuildingAssociationVisitationStrategy.buildLoadPlan:line160] - Building LoadPlan...
""[01:28:59.442][DEBUG][org.hibernate.loader.plan.exec.internal.LoadQueryJoinAndFetchProcessor.processQuerySpaceJoins:line102] - processing queryspace <gen:0>
""[01:28:59.445][DEBUG][org.hibernate.loader.plan.build.spi.LoadPlanTreePrinter.logTree:line55] - LoadPlan(entity=com.jinseong.demo.entity.Reservation)
    - Returns
       - EntityReturnImpl(entity=com.jinseong.demo.entity.Reservation, querySpaceUid=<gen:0>, path=com.jinseong.demo.entity.Reservation)
    - QuerySpaces
       - EntityQuerySpaceImpl(uid=<gen:0>, entity=com.jinseong.demo.entity.Reservation)
          - SQL table alias mapping - reservatio0_
          - alias suffix - 0_
          - suffixed key columns - {reservat1_0_0_}

""[01:28:59.445][DEBUG][org.hibernate.loader.entity.plan.EntityLoader.<init>:line129] - Static select for entity com.jinseong.demo.entity.Reservation [NONE]: select reservatio0_.reservation_id as reservat1_0_0_, reservatio0_.count as count2_0_0_, reservatio0_.date as date3_0_0_, reservatio0_.name as name4_0_0_, reservatio0_.number as number5_0_0_, reservatio0_.time as time6_0_0_ from reservation reservatio0_ where reservatio0_.reservation_id=?
""[01:28:59.446][DEBUG][org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.interpret:line556] - No schema actions specified
""[01:28:59.446][DEBUG][org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process:line69] - No actions specified; doing nothing
""[01:28:59.446][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:28:59.446][DEBUG][org.hibernate.service.internal.SessionFactoryServiceRegistryImpl.getService:line92] - EventListenerRegistry access via ServiceRegistry is deprecated.  Use `sessionFactory.getEventEngine().getListenerRegistry()` instead
""[01:28:59.446][DEBUG][org.hibernate.hql.internal.QueryTranslatorFactoryInitiator.initiateService:line45] - QueryTranslatorFactory: org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory@35e07c5b
""[01:28:59.447][DEBUG][org.hibernate.query.spi.NamedQueryRepository.checkNamedQueries:line171] - Checking 0 named HQL queries
""[01:28:59.447][DEBUG][org.hibernate.query.spi.NamedQueryRepository.checkNamedQueries:line185] - Checking 0 named SQL queries
""[01:28:59.447][DEBUG][org.hibernate.internal.SessionFactoryRegistry.addSessionFactory:line73] - Registering SessionFactory: d1ed9d42-8c6b-4f41-98e6-875e4dfbcd26 (<unnamed>)
""[01:28:59.447][DEBUG][org.hibernate.internal.SessionFactoryRegistry.addSessionFactory:line80] - Not binding SessionFactory to JNDI, no JNDI name configured
""[01:28:59.447][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:28:59.455][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'application'
""[01:28:59.456][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webConfig'
""[01:28:59.456][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webSocketConfig'
""[01:28:59.457][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'socketHandler'
""[01:28:59.459][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mainController'
""[01:28:59.459][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaConsumerService'
""[01:28:59.460][DEBUG][org.springframework.kafka.annotation.KafkaListenerAnnotationBeanPostProcessor.debug:line313] - No retry topic configuration found for topics [reservation-topic]
""[01:28:59.460][DEBUG][org.springframework.kafka.annotation.KafkaListenerAnnotationBeanPostProcessor.debug:line313] - 1 @KafkaListener methods processed on bean 'kafkaConsumerService': {public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException=[@org.springframework.kafka.annotation.KafkaListener(topicPattern="", containerFactory="", beanRef="__listener", contentTypeConverter="", topics={"reservation-topic"}, groupId="my-consumer-group", batch="", clientIdPrefix="", topicPartitions={}, splitIterables=true, concurrency="", autoStartup="", filter="", containerGroup="", idIsGroup=true, errorHandler="", id="", properties={}, info="")]}
""[01:28:59.461][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.web.servlet.config.annotation.DelegatingWebMvcConfiguration'
""[01:28:59.461][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'openEntityManagerInViewInterceptorConfigurer'
""[01:28:59.461][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration'
""[01:28:59.462][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration' via constructor to bean named 'spring.jpa-org.springframework.boot.autoconfigure.orm.jpa.JpaProperties'
""[01:28:59.462][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'openEntityManagerInViewInterceptor'
""[01:28:59.462][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:28:59.464][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'openEntityManagerInViewInterceptorConfigurer' via factory method to bean named 'openEntityManagerInViewInterceptor'
""[01:28:59.464][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.web.config.SpringDataWebConfiguration'
""[01:28:59.464][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.data.web.config.SpringDataWebConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1f8de0ae'
""[01:28:59.466][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'requestMappingHandlerMapping'
""[01:28:59.466][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcContentNegotiationManager'
""[01:28:59.467][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcConversionService'
""[01:28:59.468][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcResourceUrlProvider'
""[01:28:59.469][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcContentNegotiationManager'
""[01:28:59.469][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:28:59.469][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:28:59.470][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.detectHandlerMethods:line295] - 
	c.j.d.c.MainController:
	{GET [/]}: index(Model)
""[01:28:59.471][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.detectHandlerMethods:line295] - 
	o.s.b.a.w.s.e.BasicErrorController:
	{ [/error]}: error(HttpServletRequest)
	{ [/error], produces [text/html]}: errorHtml(HttpServletRequest,HttpServletResponse)
""[01:28:59.473][DEBUG][org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping.handlerMethodsInitialized:line367] - 3 mappings in 'requestMappingHandlerMapping'
""[01:28:59.475][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcPatternParser'
""[01:28:59.475][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcUrlPathHelper'
""[01:28:59.475][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcPathMatcher'
""[01:28:59.476][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'viewControllerHandlerMapping'
""[01:28:59.476][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'viewControllerHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:28:59.476][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'viewControllerHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:28:59.476][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'beanNameHandlerMapping'
""[01:28:59.476][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'beanNameHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:28:59.477][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'beanNameHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:28:59.477][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.detectHandlers:line86] - 'beanNameHandlerMapping' {}
""[01:28:59.479][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'routerFunctionMapping'
""[01:28:59.479][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'routerFunctionMapping' via factory method to bean named 'mvcConversionService'
""[01:28:59.479][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'routerFunctionMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:28:59.484][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'resourceHandlerMapping'
""[01:28:59.485][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcContentNegotiationManager'
""[01:28:59.485][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:28:59.485][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:28:59.485][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'defaultServletHandlerMapping'
""[01:28:59.485][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'requestMappingHandlerAdapter'
""[01:28:59.486][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcValidator'
""[01:28:59.486][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcContentNegotiationManager'
""[01:28:59.486][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcConversionService'
""[01:28:59.486][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcValidator'
""[01:28:59.488][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'sortResolver'
""[01:28:59.488][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'sortCustomizer'
""[01:28:59.488][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration'
""[01:28:59.489][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.data.web-org.springframework.boot.autoconfigure.data.web.SpringDataWebProperties'
""[01:28:59.490][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration' via constructor to bean named 'spring.data.web-org.springframework.boot.autoconfigure.data.web.SpringDataWebProperties'
""[01:28:59.490][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'pageableResolver'
""[01:28:59.490][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'pageableCustomizer'
""[01:28:59.491][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-5 - Pool stats (total=1, active=0, idle=1, waiting=0)
""[01:28:59.494][DEBUG][org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.initControllerAdviceCache:line625] - ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
""[01:28:59.495][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'handlerFunctionAdapter'
""[01:28:59.496][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcUriComponentsContributor'
""[01:28:59.496][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mvcUriComponentsContributor' via factory method to bean named 'mvcConversionService'
""[01:28:59.496][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mvcUriComponentsContributor' via factory method to bean named 'requestMappingHandlerAdapter'
""[01:28:59.497][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'httpRequestHandlerAdapter'
""[01:28:59.497][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'simpleControllerHandlerAdapter'
""[01:28:59.497][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'handlerExceptionResolver'
""[01:28:59.497][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'handlerExceptionResolver' via factory method to bean named 'mvcContentNegotiationManager'
""[01:28:59.500][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-5 - Added connection com.mysql.cj.jdbc.ConnectionImpl@27b24a19
""[01:28:59.501][DEBUG][org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver.initExceptionHandlerAdviceCache:line307] - ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
""[01:28:59.501][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcViewResolver'
""[01:28:59.501][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mvcViewResolver' via factory method to bean named 'mvcContentNegotiationManager'
""[01:28:59.502][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'localeResolver'
""[01:28:59.502][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'themeResolver'
""[01:28:59.502][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'flashMapManager'
""[01:28:59.503][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'viewNameTranslator'
""[01:28:59.503][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'viewResolver'
""[01:28:59.507][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.web.socket.config.annotation.DelegatingWebSocketConfiguration'
""[01:28:59.508][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webSocketHandlerMapping'
""[01:28:59.509][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'defaultSockJsTaskScheduler'
""[01:28:59.509][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'webSocketHandlerMapping' via factory method to bean named 'defaultSockJsTaskScheduler'
""[01:28:59.509][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-5 - Added connection com.mysql.cj.jdbc.ConnectionImpl@668f4022
""[01:28:59.509][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.logMappings:line177] - 'webSocketHandlerMapping' {/ws=org.springframework.web.socket.server.support.WebSocketHttpRequestHandler@233e2e81}
""[01:28:59.512][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration'
""[01:28:59.512][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration'
""[01:28:59.512][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.EnableConfigurationPropertiesRegistrar.methodValidationExcludeFilter'
""[01:28:59.512][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration'
""[01:28:59.513][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration'
""[01:28:59.513][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'taskExecutorBuilder'
""[01:28:59.513][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
""[01:28:59.514][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'taskExecutorBuilder' via factory method to bean named 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
""[01:28:59.515][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration'
""[01:28:59.515][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'error'
""[01:28:59.515][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'beanNameViewResolver'
""[01:28:59.515][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration'
""[01:28:59.516][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
""[01:28:59.518][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-5 - Added connection com.mysql.cj.jdbc.ConnectionImpl@572346f8
""[01:28:59.518][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1f8de0ae'
""[01:28:59.518][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration' via constructor to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
""[01:28:59.519][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'conventionErrorViewResolver'
""[01:28:59.519][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'errorAttributes'
""[01:28:59.519][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'basicErrorController'
""[01:28:59.520][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'basicErrorController' via factory method to bean named 'errorAttributes'
""[01:28:59.520][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration'
""[01:28:59.520][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties'
""[01:28:59.521][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' via constructor to bean named 'spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties'
""[01:28:59.522][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mbeanExporter'
""[01:28:59.522][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'objectNamingStrategy'
""[01:28:59.523][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'objectNamingStrategy'
""[01:28:59.523][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@2de6dbce'
""[01:28:59.523][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mbeanServer'
""[01:28:59.524][DEBUG][org.springframework.jmx.support.JmxUtils.locateMBeanServer:line127] - Found MBeanServer: com.sun.jmx.mbeanserver.JmxMBeanServer@1f554b06
""[01:28:59.527][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration'
""[01:28:59.527][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-5 - Added connection com.mysql.cj.jdbc.ConnectionImpl@6a0bf6d
""[01:28:59.527][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'springApplicationAdminRegistrar'
""[01:28:59.527][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'springApplicationAdminRegistrar' via factory method to bean named 'environment'
""[01:28:59.528][DEBUG][org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin.afterPropertiesSet:line131] - Application Admin MBean registered with name 'org.springframework.boot:type=Admin,name=SpringApplication'
""[01:28:59.529][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$AspectJAutoProxyingConfiguration$CglibAutoProxyConfiguration'
""[01:28:59.529][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$AspectJAutoProxyingConfiguration'
""[01:28:59.529][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration'
""[01:28:59.529][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration'
""[01:28:59.529][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'applicationAvailability'
""[01:28:59.530][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$Jackson2ObjectMapperBuilderCustomizerConfiguration'
""[01:28:59.530][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'standardJacksonObjectMapperBuilderCustomizer'
""[01:28:59.530][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
""[01:28:59.532][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'standardJacksonObjectMapperBuilderCustomizer' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1f8de0ae'
""[01:28:59.532][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'standardJacksonObjectMapperBuilderCustomizer' via factory method to bean named 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
""[01:28:59.532][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperBuilderConfiguration'
""[01:28:59.533][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$ParameterNamesModuleConfiguration'
""[01:28:59.533][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'parameterNamesModule'
""[01:28:59.533][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperConfiguration'
""[01:28:59.533][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jacksonObjectMapper'
""[01:28:59.534][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1f8de0ae'
""[01:28:59.534][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'standardJacksonObjectMapperBuilderCustomizer'
""[01:28:59.534][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jsonComponentModule'
""[01:28:59.534][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration'
""[01:28:59.535][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-5 - Added connection com.mysql.cj.jdbc.ConnectionImpl@89f5280
""[01:28:59.536][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jsonMixinModule'
""[01:28:59.536][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jsonMixinModule' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1f8de0ae'
""[01:28:59.544][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-5 - Added connection com.mysql.cj.jdbc.ConnectionImpl@2eec56c
""[01:28:59.545][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jacksonGeoModule'
""[01:28:59.545][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.web.config.SpringDataJacksonConfiguration'
""[01:28:59.546][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jacksonObjectMapper' via factory method to bean named 'jacksonObjectMapperBuilder'
""[01:28:59.551][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration'
""[01:28:59.552][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceJmxConfiguration$Hikari'
""[01:28:59.552][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-5 - Added connection com.mysql.cj.jdbc.ConnectionImpl@3606e6e
""[01:28:59.552][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jdbc.DataSourceJmxConfiguration$Hikari' via constructor to bean named 'dataSource'
""[01:28:59.552][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceJmxConfiguration'
""[01:28:59.553][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration$PooledDataSourceConfiguration'
""[01:28:59.553][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.metadata.DataSourcePoolMetadataProvidersConfiguration'
""[01:28:59.553][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration'
""[01:28:59.553][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionManager'
""[01:28:59.553][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'platformTransactionManagerCustomizers'
""[01:28:59.554][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration'
""[01:28:59.554][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.transaction-org.springframework.boot.autoconfigure.transaction.TransactionProperties'
""[01:28:59.556][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration'
""[01:28:59.556][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration'
""[01:28:59.556][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration'
""[01:28:59.556][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'lifecycleProcessor'
""[01:28:59.557][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties'
""[01:28:59.558][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'lifecycleProcessor' via factory method to bean named 'spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties'
""[01:28:59.558][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration'
""[01:28:59.558][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration'
""[01:28:59.559][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.jpa.util.JpaMetamodelCacheCleanup'
""[01:28:59.559][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.jpa.repository.support.JpaEvaluationContextExtension'
""[01:28:59.559][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'reservationRepository'
""[01:28:59.561][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-5 - Added connection com.mysql.cj.jdbc.ConnectionImpl@441b2877
""[01:28:59.568][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-5 - Added connection com.mysql.cj.jdbc.ConnectionImpl@7c652654
""[01:28:59.568][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-5 - After adding stats (total=10, active=0, idle=10, waiting=0)
""[01:28:59.580][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jpaMappingContext'
""[01:28:59.580][DEBUG][org.springframework.data.jpa.repository.config.JpaMetamodelMappingContextFactoryBean.createInstance:line77] - Initializing JpaMetamodelMappingContext
""[01:28:59.581][DEBUG][org.springframework.data.jpa.repository.config.JpaMetamodelMappingContextFactoryBean.createInstance:line84] - Finished initializing JpaMetamodelMappingContext!
""[01:28:59.582][DEBUG][org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke:line306] - Creating new EntityManager for shared EntityManager invocation
""[01:28:59.582][DEBUG][org.hibernate.stat.internal.StatisticsInitiator.initiateServiceInternal:line101] - Statistics initialized [enabled=false]
""[01:28:59.584][DEBUG][org.springframework.beans.CachedIntrospectionResults.forClass:line190] - Not strongly caching class [com.jinseong.demo.entity.Reservation] because it is not cache-safe
""[01:28:59.586][DEBUG][org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository:line280] - Initializing repository instance for com.jinseong.demo.repository.ReservationRepository
""[01:28:59.590][DEBUG][org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke:line306] - Creating new EntityManager for shared EntityManager invocation
""[01:28:59.602][DEBUG][org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository:line377] - Finished creation of repository instance for com.jinseong.demo.repository.ReservationRepository.
""[01:28:59.603][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration$StringHttpMessageConverterConfiguration'
""[01:28:59.604][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'stringHttpMessageConverter'
""[01:28:59.604][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'stringHttpMessageConverter' via factory method to bean named 'environment'
""[01:28:59.605][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.JacksonHttpMessageConvertersConfiguration$MappingJackson2HttpMessageConverterConfiguration'
""[01:28:59.605][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mappingJackson2HttpMessageConverter'
""[01:28:59.605][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mappingJackson2HttpMessageConverter' via factory method to bean named 'jacksonObjectMapper'
""[01:28:59.606][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.JacksonHttpMessageConvertersConfiguration'
""[01:28:59.606][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration'
""[01:28:59.606][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'messageConverters'
""[01:28:59.609][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.web.config.ProjectingArgumentResolverRegistrar'
""[01:28:59.609][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration'
""[01:28:59.609][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
""[01:28:59.610][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration' via constructor to bean named 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
""[01:28:59.610][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.JdbcTemplateConfiguration'
""[01:28:59.610][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jdbcTemplate'
""[01:28:59.611][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jdbc-org.springframework.boot.autoconfigure.jdbc.JdbcProperties'
""[01:28:59.611][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jdbcTemplate' via factory method to bean named 'dataSource'
""[01:28:59.611][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jdbcTemplate' via factory method to bean named 'spring.jdbc-org.springframework.boot.autoconfigure.jdbc.JdbcProperties'
""[01:28:59.614][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.NamedParameterJdbcTemplateConfiguration'
""[01:28:59.614][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'namedParameterJdbcTemplate'
""[01:28:59.615][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'namedParameterJdbcTemplate' via factory method to bean named 'jdbcTemplate'
""[01:28:59.616][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration'
""[01:28:59.616][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration$EnableKafkaConfiguration'
""[01:28:59.616][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
""[01:28:59.617][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration'
""[01:28:59.617][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
""[01:28:59.620][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
""[01:28:59.621][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaTemplate'
""[01:28:59.622][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration'
""[01:28:59.622][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
""[01:28:59.623][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaProducerFactory'
""[01:28:59.625][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaProducerListener'
""[01:28:59.625][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'kafkaTemplate' via factory method to bean named 'kafkaProducerFactory'
""[01:28:59.625][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'kafkaTemplate' via factory method to bean named 'kafkaProducerListener'
""[01:28:59.627][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaListenerContainerFactoryConfigurer'
""[01:28:59.627][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaListenerContainerFactory'
""[01:28:59.628][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'kafkaListenerContainerFactory' via factory method to bean named 'kafkaListenerContainerFactoryConfigurer'
""[01:28:59.628][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaConsumerFactory'
""[01:28:59.630][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaAdmin'
""[01:28:59.630][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.sql.init.SqlInitializationAutoConfiguration'
""[01:28:59.630][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration'
""[01:28:59.631][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'taskSchedulerBuilder'
""[01:28:59.631][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
""[01:28:59.632][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'taskSchedulerBuilder' via factory method to bean named 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
""[01:28:59.632][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafJava8TimeDialect'
""[01:28:59.632][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'java8TimeDialect'
""[01:28:59.632][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafWebMvcConfiguration$ThymeleafViewResolverConfiguration'
""[01:28:59.633][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'thymeleafViewResolver'
""[01:28:59.633][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:28:59.635][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'templateEngine'
""[01:28:59.635][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.TemplateEngineConfigurations$DefaultTemplateEngineConfiguration'
""[01:28:59.635][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'templateEngine' via factory method to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:28:59.635][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'defaultTemplateResolver'
""[01:28:59.635][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration'
""[01:28:59.636][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration' via constructor to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:28:59.636][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1f8de0ae'
""[01:28:59.638][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'thymeleafViewResolver' via factory method to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:28:59.639][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'thymeleafViewResolver' via factory method to bean named 'templateEngine'
""[01:28:59.640][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafWebMvcConfiguration'
""[01:28:59.640][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration'
""[01:28:59.640][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration$JdbcTransactionManagerConfiguration'
""[01:28:59.640][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration'
""[01:28:59.640][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration$CglibAutoProxyConfiguration'
""[01:28:59.640][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration'
""[01:28:59.641][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$TransactionTemplateConfiguration'
""[01:28:59.641][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionTemplate'
""[01:28:59.641][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'transactionTemplate' via factory method to bean named 'transactionManager'
""[01:28:59.642][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration'
""[01:28:59.642][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration'
""[01:28:59.642][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'multipartResolver'
""[01:28:59.642][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration'
""[01:28:59.642][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartConfiguration'
""[01:28:59.643][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.devtools-org.springframework.boot.devtools.autoconfigure.DevToolsProperties'
""[01:28:59.643][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartConfiguration' via constructor to bean named 'spring.devtools-org.springframework.boot.devtools.autoconfigure.DevToolsProperties'
""[01:28:59.643][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'restartingClassPathChangedEventListener'
""[01:28:59.644][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'fileSystemWatcherFactory'
""[01:28:59.644][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'restartingClassPathChangedEventListener' via factory method to bean named 'fileSystemWatcherFactory'
""[01:28:59.644][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'classPathFileSystemWatcher'
""[01:28:59.644][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'classPathRestartStrategy'
""[01:28:59.645][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'classPathFileSystemWatcher' via factory method to bean named 'fileSystemWatcherFactory'
""[01:28:59.645][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'classPathFileSystemWatcher' via factory method to bean named 'classPathRestartStrategy'
""[01:28:59.645][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'conditionEvaluationDeltaLoggingListener'
""[01:28:59.646][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$LiveReloadConfiguration'
""[01:28:59.646][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'optionalLiveReloadServer'
""[01:28:59.646][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'optionalLiveReloadServer' via factory method to bean named 'liveReloadServer'
""[01:28:59.646][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:28:59.646][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'liveReloadServerEventListener'
""[01:28:59.647][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'liveReloadServerEventListener' via factory method to bean named 'optionalLiveReloadServer'
""[01:28:59.647][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration'
""[01:28:59.651][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.afterSingletonsInstantiated:line434] - Registering beans for JMX exposure on startup
""[01:28:59.651][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.registerBeans:line541] - Autodetecting user-defined JMX MBeans
""[01:28:59.651][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.autodetect:line896] - Bean with name 'dataSource' has been autodetected for JMX exposure
""[01:28:59.653][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.registerBeanInstance:line669] - Located MBean 'dataSource': registering with JMX server as MBean [com.zaxxer.hikari:name=dataSource,type=HikariDataSource]
""[01:28:59.655][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase -2147483647
""[01:28:59.656][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'springBootLoggingLifecycle'
""[01:28:59.656][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase 2147483547
""[01:28:59.656][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:28:59.657][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer.<init>:line695] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Initializing the Kafka consumer
""[01:28:59.660][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:28:59.660][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:28:59.661][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:28:59.661][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692289739660
""[01:28:59.661][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer.<init>:line815] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Kafka consumer initialized
""[01:28:59.661][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:28:59.661][DEBUG][org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler.initialize:line184] - Initializing ExecutorService
""[01:28:59.661][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
""[01:28:59.662][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase 2147483646
""[01:28:59.662][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:28:59.662][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendFindCoordinatorRequest:line821] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FindCoordinator request to broker localhost:9092 (id: -1 rack: null)
""[01:28:59.662][DEBUG][org.apache.kafka.clients.ClientUtils.resolve:line113] - Resolved host localhost as 127.0.0.1
""[01:28:59.662][DEBUG][org.apache.kafka.clients.NetworkClient.initiateConnect:line989] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Initiating connection to node localhost:9092 (id: -1 rack: null) using address localhost/127.0.0.1
""[01:28:59.664][DEBUG][org.apache.kafka.common.network.Selector.pollSelectionKeys:line531] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
""[01:28:59.664][DEBUG][org.apache.kafka.clients.NetworkClient.handleConnections:line951] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Completed connection to node -1. Fetching API versions.
""[01:28:59.664][DEBUG][org.apache.kafka.clients.NetworkClient.handleInitiateApiVersionRequests:line965] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Initiating API versions fetch from node -1.
""[01:28:59.664][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-5, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.2')
""[01:28:59.665][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:28:59.665][DEBUG][org.apache.tomcat.util.threads.LimitLatch.log:line173] - Counting up[http-nio-8080-Acceptor] latch=0
""[01:28:59.665][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'webServerStartStop'
""[01:28:59.666][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase 2147483647
""[01:28:59.666][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'webSocketHandlerMapping'
""[01:28:59.666][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'webServerGracefulShutdown'
""[01:28:59.666][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-5, correlationId=1): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=12), ApiVersion(apiKey=2, minVersion=0, maxVersion=6), ApiVersion(apiKey=3, minVersion=0, maxVersion=11), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=7), ApiVersion(apiKey=10, minVersion=0, maxVersion=3), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
""[01:28:59.667][DEBUG][org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse:line921] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node -1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 6 [usable: 6], Metadata(3): 0 to 11 [usable: 11], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
""[01:28:59.667][DEBUG][org.apache.kafka.clients.NetworkClient.maybeUpdate:line1143] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='reservation-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:9092 (id: -1 rack: null)
""[01:28:59.667][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=11, clientId=consumer-my-consumer-group-5, correlationId=2) and timeout 30000 to node -1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='reservation-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
""[01:28:59.668][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-my-consumer-group-5, correlationId=0) and timeout 30000 to node -1: FindCoordinatorRequestData(key='my-consumer-group', keyType=0, coordinatorKeys=[])
""[01:28:59.670][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=11, clientId=consumer-my-consumer-group-5, correlationId=2): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=1001, host='127.0.0.1', port=9092, rack=null)], clusterId='TgEACWKoRbSzp0Inn-GuTg', controllerId=1001, topics=[MetadataResponseTopic(errorCode=0, name='reservation-topic', topicId=8aoMqokpSXGOqjBL2y8aPw, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=1001, leaderEpoch=0, replicaNodes=[1001], isrNodes=[1001], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
""[01:28:59.670][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:28:59.670][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:28:59.671][DEBUG][org.apache.kafka.clients.Metadata.update:line291] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='TgEACWKoRbSzp0Inn-GuTg', nodes={1001=127.0.0.1:9092 (id: 1001 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=reservation-topic-0, leader=Optional[1001], leaderEpoch=Optional[0], replicas=1001, isr=1001, offlineReplicas=)], controller=127.0.0.1:9092 (id: 1001 rack: null)}
""[01:28:59.672][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FIND_COORDINATOR response from node -1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-my-consumer-group-5, correlationId=0): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=1001, host='127.0.0.1', port=9092, coordinators=[])
""[01:28:59.672][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line834] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FindCoordinator response ClientResponse(receivedTimeMs=1692289739672, latencyMs=10, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-my-consumer-group-5, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=1001, host='127.0.0.1', port=9092, coordinators=[]))
""[01:28:59.672][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:28:59.672][DEBUG][org.apache.kafka.clients.ClientUtils.resolve:line113] - Resolved host 127.0.0.1 as 127.0.0.1
""[01:28:59.672][DEBUG][org.apache.kafka.clients.NetworkClient.initiateConnect:line989] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Initiating connection to node 127.0.0.1:9092 (id: 2147482646 rack: null) using address /127.0.0.1
""[01:28:59.673][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare:line707] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Executing onJoinPrepare with generation -1 and memberId 
""[01:28:59.673][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.run:line1367] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Heartbeat thread started
""[01:28:59.673][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] (Re-)joining group
""[01:28:59.674][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.metadata:line219] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Joining group with current subscription: [reservation-topic]
""[01:28:59.673][DEBUG][org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener.logAutoConfigurationReport:line126] - 


============================
CONDITIONS EVALUATION REPORT
============================


Positive matches:
-----------------

   AopAutoConfiguration matched:
      - @ConditionalOnProperty (spring.aop.auto=true) matched (OnPropertyCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration matched:
      - @ConditionalOnClass found required class 'org.aspectj.weaver.Advice' (OnClassCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration.CglibAutoProxyConfiguration matched:
      - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   ApplicationAvailabilityAutoConfiguration#applicationAvailability matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.availability.ApplicationAvailability; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)
      - @ConditionalOnMissingBean (types: io.r2dbc.spi.ConnectionFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceAutoConfiguration.PooledDataSourceConfiguration matched:
      - AnyNestedCondition 1 matched 1 did not; NestedCondition on DataSourceAutoConfiguration.PooledDataSourceCondition.PooledDataSourceAvailable PooledDataSource found supported DataSource; NestedCondition on DataSourceAutoConfiguration.PooledDataSourceCondition.ExplicitType @ConditionalOnProperty (spring.datasource.type) did not find property 'type' (DataSourceAutoConfiguration.PooledDataSourceCondition)
      - @ConditionalOnMissingBean (types: javax.sql.DataSource,javax.sql.XADataSource; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceConfiguration.Hikari matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)
      - @ConditionalOnProperty (spring.datasource.type=com.zaxxer.hikari.HikariDataSource) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: javax.sql.DataSource; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceInitializationConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.jdbc.datasource.init.DatabasePopulator' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource'; @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.sql.init.SqlDataSourceScriptDatabaseInitializer,org.springframework.boot.autoconfigure.sql.init.SqlR2dbcScriptDatabaseInitializer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceJmxConfiguration matched:
      - @ConditionalOnProperty (spring.jmx.enabled=true) matched (OnPropertyCondition)

   DataSourceJmxConfiguration.Hikari matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   DataSourcePoolMetadataProvidersConfiguration.HikariPoolDataSourceMetadataProviderConfiguration matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.jdbc.core.JdbcTemplate', 'org.springframework.transaction.TransactionManager' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration.JdbcTransactionManagerConfiguration matched:
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   DevToolsDataSourceAutoConfiguration matched:
      - Devtools devtools enabled. (OnEnabledDevToolsCondition)
      - DevTools DataSource Condition found auto-configured DataSource (DevToolsDataSourceAutoConfiguration.DevToolsDataSourceCondition)

   DevToolsDataSourceAutoConfiguration.DatabaseShutdownExecutorEntityManagerFactoryDependsOnPostProcessor matched:
      - @ConditionalOnClass found required class 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean' (OnClassCondition)
      - @ConditionalOnBean (types: org.springframework.orm.jpa.AbstractEntityManagerFactoryBean; SearchStrategy: all) found bean '&entityManagerFactory' (OnBeanCondition)

   DispatcherServletAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.servlet.DispatcherServlet' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   DispatcherServletAutoConfiguration.DispatcherServletConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRegistration' (OnClassCondition)
      - Default DispatcherServlet did not find dispatcher servlet beans (DispatcherServletAutoConfiguration.DefaultDispatcherServletCondition)

   DispatcherServletAutoConfiguration.DispatcherServletRegistrationConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRegistration' (OnClassCondition)
      - DispatcherServlet Registration did not find servlet registration bean (DispatcherServletAutoConfiguration.DispatcherServletRegistrationCondition)

   DispatcherServletAutoConfiguration.DispatcherServletRegistrationConfiguration#dispatcherServletRegistration matched:
      - @ConditionalOnBean (names: dispatcherServlet types: org.springframework.web.servlet.DispatcherServlet; SearchStrategy: all) found bean 'dispatcherServlet' (OnBeanCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration matched:
      - @ConditionalOnWebApplication (required) found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnWarDeployment the application is not deployed as a WAR file. (OnWarDeploymentCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.TomcatWebServerFactoryCustomizerConfiguration matched:
      - @ConditionalOnClass found required classes 'org.apache.catalina.startup.Tomcat', 'org.apache.coyote.UpgradeProtocol' (OnClassCondition)

   ErrorMvcAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.servlet.DispatcherServlet' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   ErrorMvcAutoConfiguration#basicErrorController matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.error.ErrorController; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration#errorAttributes matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.error.ErrorAttributes; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.DefaultErrorViewResolverConfiguration#conventionErrorViewResolver matched:
      - @ConditionalOnBean (types: org.springframework.web.servlet.DispatcherServlet; SearchStrategy: all) found bean 'dispatcherServlet'; @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.web.servlet.error.ErrorViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration matched:
      - @ConditionalOnProperty (server.error.whitelabel.enabled) matched (OnPropertyCondition)
      - ErrorTemplate Missing did not find error template view (ErrorMvcAutoConfiguration.ErrorTemplateMissingCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration#beanNameViewResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.servlet.view.BeanNameViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration#defaultErrorView matched:
      - @ConditionalOnMissingBean (names: error; SearchStrategy: all) did not find any beans (OnBeanCondition)

   GenericCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.GenericCacheConfiguration automatic cache type (CacheCondition)

   HibernateJpaAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean', 'javax.persistence.EntityManager', 'org.hibernate.engine.spi.SessionImplementor' (OnClassCondition)

   HibernateJpaConfiguration matched:
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   HttpEncodingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.filter.CharacterEncodingFilter' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (server.servlet.encoding.enabled) matched (OnPropertyCondition)

   HttpEncodingAutoConfiguration#characterEncodingFilter matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.filter.CharacterEncodingFilter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   HttpMessageConvertersAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.HttpMessageConverter' (OnClassCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication did not find reactive web application classes (HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition)

   HttpMessageConvertersAutoConfiguration#messageConverters matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.http.HttpMessageConverters; SearchStrategy: all) did not find any beans (OnBeanCondition)

   HttpMessageConvertersAutoConfiguration.StringHttpMessageConverterConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.StringHttpMessageConverter' (OnClassCondition)

   HttpMessageConvertersAutoConfiguration.StringHttpMessageConverterConfiguration#stringHttpMessageConverter matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.StringHttpMessageConverter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)

   JacksonAutoConfiguration.Jackson2ObjectMapperBuilderCustomizerConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration#jacksonObjectMapperBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.json.Jackson2ObjectMapperBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration#jacksonObjectMapper matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.module.paramnames.ParameterNamesModule' (OnClassCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration#parameterNamesModule matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.module.paramnames.ParameterNamesModule; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2HttpMessageConverterConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)
      - @ConditionalOnProperty (spring.mvc.converters.preferred-json-mapper=jackson) matched (OnPropertyCondition)
      - @ConditionalOnBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) found bean 'jacksonObjectMapper' (OnBeanCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2HttpMessageConverterConfiguration#mappingJackson2HttpMessageConverter matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.json.MappingJackson2HttpMessageConverter ignored: org.springframework.hateoas.server.mvc.TypeConstrainedMappingJackson2HttpMessageConverter,org.springframework.data.rest.webmvc.alps.AlpsJsonHttpMessageConverter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JdbcTemplateAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.core.JdbcTemplate' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   JdbcTemplateConfiguration matched:
      - @ConditionalOnMissingBean (types: org.springframework.jdbc.core.JdbcOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.jmx.export.MBeanExporter' (OnClassCondition)
      - @ConditionalOnProperty (spring.jmx.enabled=true) matched (OnPropertyCondition)

   JmxAutoConfiguration#mbeanExporter matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.MBeanExporter; SearchStrategy: current) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#mbeanServer matched:
      - @ConditionalOnMissingBean (types: javax.management.MBeanServer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#objectNamingStrategy matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.naming.ObjectNamingStrategy; SearchStrategy: current) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#entityManagerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean,javax.persistence.EntityManagerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#entityManagerFactoryBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.orm.jpa.EntityManagerFactoryBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#jpaVendorAdapter matched:
      - @ConditionalOnMissingBean (types: org.springframework.orm.jpa.JpaVendorAdapter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#transactionManager matched:
      - @ConditionalOnMissingBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration.JpaWebConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.jpa.open-in-view=true) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: org.springframework.orm.jpa.support.OpenEntityManagerInViewInterceptor,org.springframework.orm.jpa.support.OpenEntityManagerInViewFilter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaRepositoriesAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.data.jpa.repository.JpaRepository' (OnClassCondition)
      - @ConditionalOnProperty (spring.data.jpa.repositories.enabled=true) matched (OnPropertyCondition)
      - @ConditionalOnBean (types: javax.sql.DataSource; SearchStrategy: all) found bean 'dataSource'; @ConditionalOnMissingBean (types: org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean,org.springframework.data.jpa.repository.config.JpaRepositoryConfigExtension; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JtaAutoConfiguration matched:
      - @ConditionalOnClass found required class 'javax.transaction.Transaction' (OnClassCondition)
      - @ConditionalOnProperty (spring.jta.enabled) matched (OnPropertyCondition)

   KafkaAnnotationDrivenConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.annotation.EnableKafka' (OnClassCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactory matched:
      - @ConditionalOnMissingBean (names: kafkaListenerContainerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactoryConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.kafka.ConcurrentKafkaListenerContainerFactoryConfigurer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration.EnableKafkaConfiguration matched:
      - @ConditionalOnMissingBean (names: org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.core.KafkaTemplate' (OnClassCondition)

   KafkaAutoConfiguration#kafkaAdmin matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaAdmin; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaConsumerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ConsumerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaProducerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ProducerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaProducerListener matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.support.ProducerListener; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaTemplate matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaTemplate; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LifecycleAutoConfiguration#defaultLifecycleProcessor matched:
      - @ConditionalOnMissingBean (names: lifecycleProcessor; SearchStrategy: current) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration matched:
      - Initialized Restarter Condition available and initialized (OnInitializedRestarterCondition)

   LocalDevToolsAutoConfiguration.LiveReloadConfiguration matched:
      - @ConditionalOnProperty (spring.devtools.livereload.enabled) matched (OnPropertyCondition)

   LocalDevToolsAutoConfiguration.LiveReloadConfiguration#liveReloadServer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.devtools.livereload.LiveReloadServer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration matched:
      - @ConditionalOnProperty (spring.devtools.restart.enabled) matched (OnPropertyCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration#classPathFileSystemWatcher matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.devtools.classpath.ClassPathFileSystemWatcher; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration#classPathRestartStrategy matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.devtools.classpath.ClassPathRestartStrategy; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration#conditionEvaluationDeltaLoggingListener matched:
      - @ConditionalOnProperty (spring.devtools.restart.log-condition-evaluation-delta) matched (OnPropertyCondition)

   MultipartAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.multipart.support.StandardServletMultipartResolver', 'javax.servlet.MultipartConfigElement' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.servlet.multipart.enabled) matched (OnPropertyCondition)

   MultipartAutoConfiguration#multipartConfigElement matched:
      - @ConditionalOnMissingBean (types: javax.servlet.MultipartConfigElement,org.springframework.web.multipart.commons.CommonsMultipartResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   MultipartAutoConfiguration#multipartResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.multipart.MultipartResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   NamedParameterJdbcTemplateConfiguration matched:
      - @ConditionalOnSingleCandidate (types: org.springframework.jdbc.core.JdbcTemplate; SearchStrategy: all) found a single bean 'jdbcTemplate'; @ConditionalOnMissingBean (types: org.springframework.jdbc.core.namedparam.NamedParameterJdbcOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   NoOpCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.NoOpCacheConfiguration automatic cache type (CacheCondition)

   PersistenceExceptionTranslationAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor' (OnClassCondition)

   PersistenceExceptionTranslationAutoConfiguration#persistenceExceptionTranslationPostProcessor matched:
      - @ConditionalOnProperty (spring.dao.exceptiontranslation.enabled) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   PropertyPlaceholderAutoConfiguration#propertySourcesPlaceholderConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.context.support.PropertySourcesPlaceholderConfigurer; SearchStrategy: current) did not find any beans (OnBeanCondition)

   RestTemplateAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.client.RestTemplate' (OnClassCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication did not find reactive web application classes (RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition)

   RestTemplateAutoConfiguration#restTemplateBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.client.RestTemplateBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   RestTemplateAutoConfiguration#restTemplateBuilderConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.web.client.RestTemplateBuilderConfigurer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ServletWebServerFactoryAutoConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRequest' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   ServletWebServerFactoryAutoConfiguration#tomcatServletWebServerFactoryCustomizer matched:
      - @ConditionalOnClass found required class 'org.apache.catalina.startup.Tomcat' (OnClassCondition)

   ServletWebServerFactoryConfiguration.EmbeddedTomcat matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.apache.catalina.startup.Tomcat', 'org.apache.coyote.UpgradeProtocol' (OnClassCondition)
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.server.ServletWebServerFactory; SearchStrategy: current) did not find any beans (OnBeanCondition)

   SimpleCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.SimpleCacheConfiguration automatic cache type (CacheCondition)

   SpringApplicationAdminJmxAutoConfiguration matched:
      - @ConditionalOnProperty (spring.application.admin.enabled=true) matched (OnPropertyCondition)

   SpringApplicationAdminJmxAutoConfiguration#springApplicationAdminRegistrar matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.data.web.PageableHandlerMethodArgumentResolver', 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnMissingBean (types: org.springframework.data.web.PageableHandlerMethodArgumentResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration#pageableCustomizer matched:
      - @ConditionalOnMissingBean (types: org.springframework.data.web.config.PageableHandlerMethodArgumentResolverCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration#sortCustomizer matched:
      - @ConditionalOnMissingBean (types: org.springframework.data.web.config.SortHandlerMethodArgumentResolverCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SqlInitializationAutoConfiguration matched:
      - @ConditionalOnProperty (spring.sql.init.enabled) matched (OnPropertyCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on SqlInitializationAutoConfiguration.SqlInitializationModeCondition.ModeIsNever @ConditionalOnProperty (spring.sql.init.mode=never) did not find property 'mode' (SqlInitializationAutoConfiguration.SqlInitializationModeCondition)

   TaskExecutionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor' (OnClassCondition)

   TaskExecutionAutoConfiguration#applicationTaskExecutor matched:
      - @ConditionalOnMissingBean (types: java.util.concurrent.Executor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskExecutionAutoConfiguration#taskExecutorBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskExecutorBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskSchedulingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler' (OnClassCondition)

   TaskSchedulingAutoConfiguration#taskSchedulerBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskSchedulerBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TemplateEngineConfigurations.DefaultTemplateEngineConfiguration#templateEngine matched:
      - @ConditionalOnMissingBean (types: org.thymeleaf.spring5.ISpringTemplateEngine; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.thymeleaf.templatemode.TemplateMode', 'org.thymeleaf.spring5.SpringTemplateEngine' (OnClassCondition)

   ThymeleafAutoConfiguration.DefaultTemplateResolverConfiguration matched:
      - @ConditionalOnMissingBean (names: defaultTemplateResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration.ThymeleafJava8TimeDialect matched:
      - @ConditionalOnClass found required class 'org.thymeleaf.extras.java8time.dialect.Java8TimeDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafJava8TimeDialect#java8TimeDialect matched:
      - @ConditionalOnMissingBean (types: org.thymeleaf.extras.java8time.dialect.Java8TimeDialect; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration matched:
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.thymeleaf.enabled) matched (OnPropertyCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration.ThymeleafViewResolverConfiguration#thymeleafViewResolver matched:
      - @ConditionalOnMissingBean (names: thymeleafViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.transaction.PlatformTransactionManager' (OnClassCondition)

   TransactionAutoConfiguration#platformTransactionManagerCustomizers matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.transaction.TransactionManagerCustomizers; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration matched:
      - @ConditionalOnBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) found bean 'transactionManager'; @ConditionalOnMissingBean (types: org.springframework.transaction.annotation.AbstractTransactionManagementConfiguration; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.CglibAutoProxyConfiguration matched:
      - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   TransactionAutoConfiguration.TransactionTemplateConfiguration matched:
      - @ConditionalOnSingleCandidate (types: org.springframework.transaction.PlatformTransactionManager; SearchStrategy: all) found a single bean 'transactionManager' (OnBeanCondition)

   TransactionAutoConfiguration.TransactionTemplateConfiguration#transactionTemplate matched:
      - @ConditionalOnMissingBean (types: org.springframework.transaction.support.TransactionOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebSocketMessagingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.socket.config.annotation.WebSocketMessageBrokerConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'javax.websocket.server.ServerContainer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration.TomcatWebSocketConfiguration matched:
      - @ConditionalOnClass found required classes 'org.apache.catalina.startup.Tomcat', 'org.apache.tomcat.websocket.server.WsSci' (OnClassCondition)

   WebSocketServletAutoConfiguration.TomcatWebSocketConfiguration#websocketServletWebServerCustomizer matched:
      - @ConditionalOnMissingBean (names: websocketServletWebServerCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)


Negative matches:
-----------------

   ActiveMQAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.ConnectionFactory' (OnClassCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)

   AopAutoConfiguration.ClassProxyingConfiguration:
      Did not match:
         - @ConditionalOnMissingClass found unwanted class 'org.aspectj.weaver.Advice' (OnClassCondition)

   ArtemisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.ConnectionFactory' (OnClassCondition)

   AtomikosJtaConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.atomikos.icatch.jta.UserTransactionManager' (OnClassCondition)

   BatchAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.batch.core.launch.JobLauncher' (OnClassCondition)

   Cache2kCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.cache2k.Cache2kBuilder' (OnClassCondition)

   CacheAutoConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.cache.interceptor.CacheAspectSupport; SearchStrategy: all) did not find any beans of type org.springframework.cache.interceptor.CacheAspectSupport (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.cache.CacheManager' (OnClassCondition)

   CacheAutoConfiguration.CacheManagerEntityManagerFactoryDependsOnPostProcessor:
      Did not match:
         - Ancestor org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean' (OnClassCondition)

   CaffeineCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.github.benmanes.caffeine.cache.Caffeine' (OnClassCondition)

   CassandraAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.cassandra.ReactiveSession' (OnClassCondition)

   CassandraRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   ClientHttpConnectorAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   CodecsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   CouchbaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   CouchbaseReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   DataSourceAutoConfiguration.EmbeddedDatabaseConfiguration:
      Did not match:
         - EmbeddedDataSource spring.datasource.url is set (DataSourceAutoConfiguration.EmbeddedDatabaseCondition)

   DataSourceConfiguration.Dbcp2:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.commons.dbcp2.BasicDataSource' (OnClassCondition)

   DataSourceConfiguration.Generic:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.type) did not find property 'spring.datasource.type' (OnPropertyCondition)

   DataSourceConfiguration.OracleUcp:
      Did not match:
         - @ConditionalOnClass did not find required classes 'oracle.ucp.jdbc.PoolDataSourceImpl', 'oracle.jdbc.OracleConnection' (OnClassCondition)

   DataSourceConfiguration.Tomcat:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSource' (OnClassCondition)

   DataSourceJmxConfiguration.TomcatDataSourceJmxConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSourceProxy' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.CommonsDbcp2PoolDataSourceMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.commons.dbcp2.BasicDataSource' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.OracleUcpPoolDataSourceMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'oracle.ucp.jdbc.PoolDataSource', 'oracle.jdbc.OracleConnection' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.TomcatDataSourcePoolMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSource' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration.JdbcTransactionManagerConfiguration#transactionManager:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) found beans of type 'org.springframework.transaction.TransactionManager' transactionManager (OnBeanCondition)

   DevToolsR2dbcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   DispatcherServletAutoConfiguration.DispatcherServletConfiguration#multipartResolver:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.web.multipart.MultipartResolver; SearchStrategy: all) did not find any beans of type org.springframework.web.multipart.MultipartResolver (OnBeanCondition)

   EhCacheCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'net.sf.ehcache.Cache' (OnClassCondition)

   ElasticsearchDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.core.ElasticsearchRestTemplate' (OnClassCondition)

   ElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.Client' (OnClassCondition)

   ElasticsearchRestClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.RestClientBuilder' (OnClassCondition)

   EmbeddedLdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.unboundid.ldap.listener.InMemoryDirectoryServer' (OnClassCondition)

   EmbeddedMongoAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.MongoClientSettings' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.JettyWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.util.Loader', 'org.eclipse.jetty.webapp.WebAppContext' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.NettyWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.netty.http.server.HttpServer' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.UndertowWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.undertow.Undertow', 'org.xnio.SslClientAuthMode' (OnClassCondition)

   ErrorWebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   FlywayAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.flywaydb.core.Flyway' (OnClassCondition)

   FreeMarkerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'freemarker.template.Configuration' (OnClassCondition)

   GraphQlAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlQueryByExampleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlQuerydslAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlRSocketAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlReactiveQueryByExampleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlReactiveQuerydslAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebFluxSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebMvcSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GroovyTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'groovy.text.markup.MarkupTemplateEngine' (OnClassCondition)

   GsonAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.google.gson.Gson' (OnClassCondition)

   GsonHttpMessageConvertersConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.google.gson.Gson' (OnClassCondition)

   H2ConsoleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.h2.server.web.WebServlet' (OnClassCondition)

   HazelcastAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastJpaDependencyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HttpHandlerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.DispatcherHandler' (OnClassCondition)

   HypermediaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.hateoas.EntityModel' (OnClassCondition)

   InfinispanCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.infinispan.spring.embedded.provider.SpringEmbeddedCacheManager' (OnClassCondition)

   InfluxDbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.influxdb.InfluxDB' (OnClassCondition)

   IntegrationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.integration.config.EnableIntegration' (OnClassCondition)

   JCacheCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.cache.Caching' (OnClassCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2XmlHttpMessageConverterConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.fasterxml.jackson.dataformat.xml.XmlMapper' (OnClassCondition)

   JdbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.jdbc.repository.config.AbstractJdbcConfiguration' (OnClassCondition)

   JerseyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.glassfish.jersey.server.spring.SpringComponentProvider' (OnClassCondition)

   JmsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.Message' (OnClassCondition)

   JndiConnectionFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jms.core.JmsTemplate' (OnClassCondition)

   JndiDataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.jndi-name) did not find property 'jndi-name' (OnPropertyCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)

   JndiJtaConfiguration:
      Did not match:
         - @ConditionalOnJndi JNDI environment is not available (OnJndiCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.transaction.jta.JtaTransactionManager' (OnClassCondition)

   JooqAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.jooq.DSLContext' (OnClassCondition)

   JpaRepositoriesAutoConfiguration#entityManagerFactoryBootstrapExecutorCustomizer:
      Did not match:
         - AnyNestedCondition 0 matched 2 did not; NestedCondition on JpaRepositoriesAutoConfiguration.BootstrapExecutorCondition.LazyBootstrapMode @ConditionalOnProperty (spring.data.jpa.repositories.bootstrap-mode=lazy) did not find property 'bootstrap-mode'; NestedCondition on JpaRepositoriesAutoConfiguration.BootstrapExecutorCondition.DeferredBootstrapMode @ConditionalOnProperty (spring.data.jpa.repositories.bootstrap-mode=deferred) did not find property 'bootstrap-mode' (JpaRepositoriesAutoConfiguration.BootstrapExecutorCondition)

   JsonbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.json.bind.Jsonb' (OnClassCondition)

   JsonbHttpMessageConvertersConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.json.bind.Jsonb' (OnClassCondition)

   KafkaAutoConfiguration#kafkaJaasInitializer:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.jaas.enabled) did not find property 'spring.kafka.jaas.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaRetryTopicConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.retry.topic.enabled) did not find property 'spring.kafka.retry.topic.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaTransactionManager:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.producer.transaction-id-prefix) did not find property 'spring.kafka.producer.transaction-id-prefix' (OnPropertyCondition)

   KafkaStreamsAnnotationDrivenConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.kafka.streams.StreamsBuilder' (OnClassCondition)

   LdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ldap.core.ContextSource' (OnClassCondition)

   LdapRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.ldap.repository.LdapRepository' (OnClassCondition)

   LiquibaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'liquibase.change.DatabaseChange' (OnClassCondition)

   MailSenderAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.mail.internet.MimeMessage' (OnClassCondition)

   MailSenderValidatorAutoConfiguration:
      Did not match:
         - @ConditionalOnSingleCandidate did not find required type 'org.springframework.mail.javamail.JavaMailSenderImpl' (OnBeanCondition)

   MessageSourceAutoConfiguration:
      Did not match:
         - ResourceBundle did not find bundle with basename messages (MessageSourceAutoConfiguration.ResourceBundleCondition)

   MongoAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MustacheAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.samskivert.mustache.Mustache' (OnClassCondition)

   Neo4jAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   NettyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.netty.util.NettyRuntime' (OnClassCondition)

   OAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.configuration.EnableWebSecurity' (OnClassCondition)

   OAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.oauth2.server.resource.BearerTokenAuthenticationToken' (OnClassCondition)

   ProjectInfoAutoConfiguration#buildProperties:
      Did not match:
         - @ConditionalOnResource did not find resource '${spring.info.build.location:classpath:META-INF/build-info.properties}' (OnResourceCondition)

   ProjectInfoAutoConfiguration#gitProperties:
      Did not match:
         - GitResource did not find git info at classpath:git.properties (ProjectInfoAutoConfiguration.GitResourceAvailableCondition)

   QuartzAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.quartz.Scheduler' (OnClassCondition)

   R2dbcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   R2dbcDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.r2dbc.core.R2dbcEntityTemplate' (OnClassCondition)

   R2dbcInitializationConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.r2dbc.spi.ConnectionFactory', 'org.springframework.r2dbc.connection.init.DatabasePopulator' (OnClassCondition)

   R2dbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   R2dbcTransactionManagerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.r2dbc.connection.R2dbcTransactionManager' (OnClassCondition)

   RSocketGraphQlClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   RSocketMessagingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RSocketRequesterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RSocketSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.rsocket.core.SecuritySocketAcceptorInterceptor' (OnClassCondition)

   RSocketServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.core.RSocketServer' (OnClassCondition)

   RSocketStrategiesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.netty.buffer.PooledByteBufAllocator' (OnClassCondition)

   RabbitAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.rabbitmq.client.Channel' (OnClassCondition)

   ReactiveElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.client.reactive.ReactiveElasticsearchClient' (OnClassCondition)

   ReactiveElasticsearchRestClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.netty.http.client.HttpClient' (OnClassCondition)

   ReactiveMultipartAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   ReactiveOAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   ReactiveOAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.reactive.EnableWebFluxSecurity' (OnClassCondition)

   ReactiveSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   ReactiveUserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.ReactiveAuthenticationManager' (OnClassCondition)

   ReactiveWebServerFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnWebApplication did not find reactive web application classes (OnWebApplicationCondition)

   RedisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.core.RedisOperations' (OnClassCondition)

   RedisCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.connection.RedisConnectionFactory' (OnClassCondition)

   RedisReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   RedisRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.repository.configuration.EnableRedisRepositories' (OnClassCondition)

   RemoteDevToolsAutoConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.devtools.remote.secret) did not find property 'secret' (OnPropertyCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.servlet.Filter', 'org.springframework.http.server.ServerHttpRequest' (OnClassCondition)

   RepositoryRestMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.rest.webmvc.config.RepositoryRestMvcConfiguration' (OnClassCondition)

   Saml2RelyingPartyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.saml2.provider.service.registration.RelyingPartyRegistrationRepository' (OnClassCondition)

   SecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.DefaultAuthenticationEventPublisher' (OnClassCondition)

   SecurityFilterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.http.SessionCreationPolicy' (OnClassCondition)

   SendGridAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.sendgrid.SendGrid' (OnClassCondition)

   ServletWebServerFactoryAutoConfiguration.ForwardedHeaderFilterConfiguration:
      Did not match:
         - @ConditionalOnProperty (server.forward-headers-strategy=framework) did not find property 'server.forward-headers-strategy' (OnPropertyCondition)

   ServletWebServerFactoryConfiguration.EmbeddedJetty:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.util.Loader', 'org.eclipse.jetty.webapp.WebAppContext' (OnClassCondition)

   ServletWebServerFactoryConfiguration.EmbeddedUndertow:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.undertow.Undertow', 'org.xnio.SslClientAuthMode' (OnClassCondition)

   SessionAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.session.Session' (OnClassCondition)

   SolrAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.solr.client.solrj.impl.CloudSolrClient' (OnClassCondition)

   TaskSchedulingAutoConfiguration#scheduledBeanLazyInitializationExcludeFilter:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   TaskSchedulingAutoConfiguration#taskScheduler:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   TemplateEngineConfigurations.ReactiveTemplateEngineConfiguration:
      Did not match:
         - did not find reactive web application classes (OnWebApplicationCondition)

   ThymeleafAutoConfiguration.DataAttributeDialectConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.github.mxab.thymeleaf.extras.dataattribute.dialect.DataAttributeDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafSecurityDialectConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.thymeleaf.extras.springsecurity5.dialect.SpringSecurityDialect', 'org.springframework.security.web.server.csrf.CsrfToken' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafWebFluxConfiguration:
      Did not match:
         - did not find reactive web application classes (OnWebApplicationCondition)

   ThymeleafAutoConfiguration.ThymeleafWebLayoutConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'nz.net.ultraq.thymeleaf.layoutdialect.LayoutDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration#resourceUrlEncodingFilter:
      Did not match:
         - @ConditionalOnEnabledResourceChain did not find class org.webjars.WebJarAssetLocator (OnEnabledResourceChainCondition)

   TransactionAutoConfiguration#transactionalOperator:
      Did not match:
         - @ConditionalOnSingleCandidate (types: org.springframework.transaction.ReactiveTransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)

   UserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.AuthenticationManager' (OnClassCondition)

   ValidationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.validation.executable.ExecutableValidator' (OnClassCondition)

   WebClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   WebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   WebMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport; SearchStrategy: all) found beans of type 'org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport' org.springframework.web.servlet.config.annotation.DelegatingWebMvcConfiguration (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.servlet.DispatcherServlet', 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
         - found 'session' scope (OnWebApplicationCondition)

   WebMvcAutoConfiguration.ResourceChainCustomizerConfiguration:
      Did not match:
         - @ConditionalOnEnabledResourceChain did not find class org.webjars.WebJarAssetLocator (OnEnabledResourceChainCondition)
         - Ancestor org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)

   WebServiceTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.oxm.Marshaller' (OnClassCondition)

   WebServicesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ws.transport.http.MessageDispatcherServlet' (OnClassCondition)

   WebSessionIdResolverAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Mono' (OnClassCondition)

   WebSocketMessagingAutoConfiguration.WebSocketMessageConverterConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.web.socket.config.annotation.DelegatingWebSocketMessageBrokerConfiguration,com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) did not find any beans of type org.springframework.web.socket.config.annotation.DelegatingWebSocketMessageBrokerConfiguration (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required classes 'com.fasterxml.jackson.databind.ObjectMapper', 'org.springframework.messaging.simp.config.AbstractMessageBrokerConfiguration' (OnClassCondition)

   WebSocketReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnWebApplication did not find reactive web application classes (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration.Jetty10WebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.websocket.javax.server.internal.JavaxWebSocketServerContainer', 'org.eclipse.jetty.websocket.server.JettyWebSocketServerContainer' (OnClassCondition)

   WebSocketServletAutoConfiguration.JettyWebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.eclipse.jetty.websocket.jsr356.server.deploy.WebSocketServerContainerInitializer' (OnClassCondition)

   WebSocketServletAutoConfiguration.UndertowWebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.undertow.websockets.jsr.Bootstrap' (OnClassCondition)

   XADataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.boot.jdbc.XADataSourceWrapper; SearchStrategy: all) did not find any beans of type org.springframework.boot.jdbc.XADataSourceWrapper (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'javax.transaction.TransactionManager', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)


Exclusions:
-----------

    None


Unconditional classes:
----------------------

    org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration

    org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration

    org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration

    org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration

    org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration



""[01:28:59.674][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line547] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending JoinGroup (JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])) to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:28:59.674][DEBUG][org.apache.kafka.common.network.Selector.pollSelectionKeys:line531] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147482646
""[01:28:59.674][DEBUG][org.apache.kafka.clients.NetworkClient.handleConnections:line951] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Completed connection to node 2147482646. Fetching API versions.
""[01:28:59.674][DEBUG][org.apache.kafka.clients.NetworkClient.handleInitiateApiVersionRequests:line965] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Initiating API versions fetch from node 2147482646.
""[01:28:59.674][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 0.797 seconds (JVM running for 325.458)
""[01:28:59.675][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-5, correlationId=4) and timeout 30000 to node 2147482646: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.2')
""[01:28:59.675][DEBUG][org.springframework.boot.availability.ApplicationAvailabilityBean.onApplicationEvent:line77] - Application availability state LivenessState changed to CORRECT
""[01:28:59.676][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:28:59.676][DEBUG][org.springframework.boot.availability.ApplicationAvailabilityBean.onApplicationEvent:line77] - Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
""[01:28:59.677][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received API_VERSIONS response from node 2147482646 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-5, correlationId=4): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=12), ApiVersion(apiKey=2, minVersion=0, maxVersion=6), ApiVersion(apiKey=3, minVersion=0, maxVersion=11), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=7), ApiVersion(apiKey=10, minVersion=0, maxVersion=3), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
""[01:28:59.677][DEBUG][org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse:line921] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 2147482646 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 6 [usable: 6], Metadata(3): 0 to 11 [usable: 11], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
""[01:28:59.677][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending JOIN_GROUP request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-5, correlationId=3) and timeout 305000 to node 2147482646: JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:28:59.680][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received JOIN_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-5, correlationId=3): JoinGroupResponseData(throttleTimeMs=0, errorCode=79, generationId=-1, protocolType=null, protocolName=null, leader='', memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', members=[])
""[01:28:59.680][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line654] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] JoinGroup failed due to non-fatal error: MEMBER_ID_REQUIRED Will set the member id as consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc and then rejoin. Sent generation was  Generation{generationId=-1, memberId='', protocol='null'}
""[01:28:59.680][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:28:59.680][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] (Re-)joining group
""[01:28:59.680][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.metadata:line219] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Joining group with current subscription: [reservation-topic]
""[01:28:59.681][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line547] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending JoinGroup (JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])) to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:28:59.681][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending JOIN_GROUP request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-5, correlationId=5) and timeout 305000 to node 2147482646: JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:28:59.685][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received JOIN_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-5, correlationId=5): JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=52, protocolType='consumer', protocolName='range', leader='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', members=[JoinGroupResponseMember(memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', groupInstanceId=null, metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:28:59.686][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line575] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=52, protocolType='consumer', protocolName='range', leader='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', members=[JoinGroupResponseMember(memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', groupInstanceId=null, metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:28:59.686][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.enable:line1335] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Enabling heartbeat thread
""[01:28:59.686][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=52, memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', protocol='range'}
""[01:28:59.686][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line645] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Performing assignment using strategy range with subscriptions {consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc=Subscription(topics=[reservation-topic], ownedPartitions=[], groupInstanceId=null)}
""[01:28:59.686][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Finished assignment for group at generation 52: {consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc=Assignment(partitions=[reservation-topic-0])}
""[01:28:59.686][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinLeader:line716] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending leader SyncGroup to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) at generation Generation{generationId=52, memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', protocol='range'}: SyncGroupRequestData(groupId='my-consumer-group', generationId=52, memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', groupInstanceId=null, protocolType='consumer', protocolName='range', assignments=[SyncGroupRequestAssignment(memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])])
""[01:28:59.687][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending SYNC_GROUP request with header RequestHeader(apiKey=SYNC_GROUP, apiVersion=5, clientId=consumer-my-consumer-group-5, correlationId=6) and timeout 30000 to node 2147482646: SyncGroupRequestData(groupId='my-consumer-group', generationId=52, memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', groupInstanceId=null, protocolType='consumer', protocolName='range', assignments=[SyncGroupRequestAssignment(memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])])
""[01:28:59.691][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received SYNC_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=SYNC_GROUP, apiVersion=5, clientId=consumer-my-consumer-group-5, correlationId=6): SyncGroupResponseData(throttleTimeMs=0, errorCode=0, protocolType='consumer', protocolName='range', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])
""[01:28:59.691][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line745] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received successful SyncGroup response: SyncGroupResponseData(throttleTimeMs=0, errorCode=0, protocolType='consumer', protocolName='range', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])
""[01:28:59.691][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=52, memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', protocol='range'}
""[01:28:59.691][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete:line353] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Executing onJoinComplete with generation 52 and memberId consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc
""[01:28:59.691][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:28:59.691][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:28:59.691][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetFetchRequest:line1337] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Fetching committed offsets for partitions: [reservation-topic-0]
""[01:28:59.691][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending OFFSET_FETCH request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-5, correlationId=7) and timeout 30000 to node 2147482646: OffsetFetchRequestData(groupId='my-consumer-group', topics=[OffsetFetchRequestTopic(name='reservation-topic', partitionIndexes=[0])], groups=[], requireStable=true)
""[01:28:59.693][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received OFFSET_FETCH response from node 2147482646 for request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-5, correlationId=7): OffsetFetchResponseData(throttleTimeMs=0, topics=[OffsetFetchResponseTopic(name='reservation-topic', partitions=[OffsetFetchResponsePartition(partitionIndex=0, committedOffset=34, committedLeaderEpoch=-1, metadata='', errorCode=0)])], errorCode=0, groups=[])
""[01:28:59.694][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetFetchRequest:line1337] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Fetching committed offsets for partitions: [reservation-topic-0]
""[01:28:59.694][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending OFFSET_FETCH request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-5, correlationId=8) and timeout 30000 to node 2147482646: OffsetFetchRequestData(groupId='my-consumer-group', topics=[OffsetFetchRequestTopic(name='reservation-topic', partitionIndexes=[0])], groups=[], requireStable=true)
""[01:28:59.696][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received OFFSET_FETCH response from node 2147482646 for request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-5, correlationId=8): OffsetFetchResponseData(throttleTimeMs=0, topics=[OffsetFetchResponseTopic(name='reservation-topic', partitions=[OffsetFetchResponsePartition(partitionIndex=0, committedOffset=34, committedLeaderEpoch=-1, metadata='', errorCode=0)])], errorCode=0, groups=[])
""[01:28:59.697][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:28:59.697][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:28:59.697][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:28:59.697][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 1001 with 1 partition(s).
""[01:28:59.697][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED FullFetchRequest(toSend=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:28:59.698][DEBUG][org.apache.kafka.clients.ClientUtils.resolve:line113] - Resolved host 127.0.0.1 as 127.0.0.1
""[01:28:59.698][DEBUG][org.apache.kafka.clients.NetworkClient.initiateConnect:line989] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Initiating connection to node 127.0.0.1:9092 (id: 1001 rack: null) using address /127.0.0.1
""[01:28:59.698][DEBUG][org.apache.kafka.common.network.Selector.pollSelectionKeys:line531] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1001
""[01:28:59.698][DEBUG][org.apache.kafka.clients.NetworkClient.handleConnections:line951] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Completed connection to node 1001. Fetching API versions.
""[01:28:59.699][DEBUG][org.apache.kafka.clients.NetworkClient.handleInitiateApiVersionRequests:line965] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Initiating API versions fetch from node 1001.
""[01:28:59.699][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-5, correlationId=10) and timeout 30000 to node 1001: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.2')
""[01:28:59.701][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received API_VERSIONS response from node 1001 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-5, correlationId=10): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=12), ApiVersion(apiKey=2, minVersion=0, maxVersion=6), ApiVersion(apiKey=3, minVersion=0, maxVersion=11), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=7), ApiVersion(apiKey=10, minVersion=0, maxVersion=3), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
""[01:28:59.701][DEBUG][org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse:line921] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 6 [usable: 6], Metadata(3): 0 to 11 [usable: 11], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
""[01:28:59.702][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=9) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=0, sessionEpoch=0, topics=[FetchTopic(topic='reservation-topic', topicId=8aoMqokpSXGOqjBL2y8aPw, partitions=[FetchPartition(partition=0, currentLeaderEpoch=0, fetchOffset=34, lastFetchedEpoch=-1, logStartOffset=-1, partitionMaxBytes=1048576)])], forgottenTopicsData=[], rackId='')
""[01:29:00.204][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=9): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[FetchableTopicResponse(topic='reservation-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, partitions=[PartitionData(partitionIndex=0, errorCode=0, highWatermark=34, lastStableOffset=34, logStartOffset=0, divergingEpoch=EpochEndOffset(epoch=-1, endOffset=-1), currentLeader=LeaderIdAndEpoch(leaderId=-1, leaderEpoch=-1), snapshotId=SnapshotId(endOffset=-1, epoch=-1), abortedTransactions=null, preferredReadReplica=-1, records=MemoryRecords(size=0, buffer=java.nio.HeapByteBuffer[pos=0 lim=0 cap=3]))])])
""[01:29:00.204][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line561] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent a full fetch response that created a new incremental fetch session 1748962198 with 1 response partition(s)
""[01:29:00.204][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.onSuccess:line326] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Fetch READ_UNCOMMITTED at offset 34 for partition reservation-topic-0 returned fetch data PartitionData(partitionIndex=0, errorCode=0, highWatermark=34, lastStableOffset=34, logStartOffset=0, divergingEpoch=EpochEndOffset(epoch=-1, endOffset=-1), currentLeader=LeaderIdAndEpoch(leaderId=-1, leaderEpoch=-1), snapshotId=SnapshotId(endOffset=-1, epoch=-1), abortedTransactions=null, preferredReadReplica=-1, records=MemoryRecords(size=0, buffer=java.nio.HeapByteBuffer[pos=0 lim=0 cap=3]))
""[01:29:00.205][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:00.205][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=1) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:00.205][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:00.205][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=11) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=1, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:00.708][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=11): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[])
""[01:29:00.709][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1748962198 with 0 response partition(s), 1 implied partition(s)
""[01:29:00.709][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:00.709][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=2) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:00.709][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:00.709][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=12) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=2, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:01.212][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=12): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[])
""[01:29:01.213][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1748962198 with 0 response partition(s), 1 implied partition(s)
""[01:29:01.213][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:01.213][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=3) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:01.213][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:01.213][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=13) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=3, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:01.717][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=13): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[])
""[01:29:01.717][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1748962198 with 0 response partition(s), 1 implied partition(s)
""[01:29:01.717][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:01.718][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=4) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:01.718][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:01.718][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=14) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=4, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:02.221][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=14): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[])
""[01:29:02.221][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1748962198 with 0 response partition(s), 1 implied partition(s)
""[01:29:02.221][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:02.221][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=5) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:02.221][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:02.221][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=15) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=5, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:02.694][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending Heartbeat request with generation 52 and member id consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:02.694][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-5, correlationId=16) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=52, memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', groupInstanceId=null)
""[01:29:02.697][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-5, correlationId=16): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:02.697][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:02.725][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=15): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[])
""[01:29:02.725][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1748962198 with 0 response partition(s), 1 implied partition(s)
""[01:29:02.726][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:02.726][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=6) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:02.726][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:02.726][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=17) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=6, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:03.229][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=17): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[])
""[01:29:03.230][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1748962198 with 0 response partition(s), 1 implied partition(s)
""[01:29:03.230][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:03.230][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=7) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:03.230][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:03.230][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=18) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=7, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:03.732][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=18): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[])
""[01:29:03.732][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1748962198 with 0 response partition(s), 1 implied partition(s)
""[01:29:03.732][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:03.733][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=8) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:03.733][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:03.733][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=19) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=8, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:04.235][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=19): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[])
""[01:29:04.236][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1748962198 with 0 response partition(s), 1 implied partition(s)
""[01:29:04.236][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:04.236][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=9) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:04.236][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:04.236][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=20) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=9, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:04.663][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:04.663][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:04.740][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=20): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[])
""[01:29:04.740][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1748962198 with 0 response partition(s), 1 implied partition(s)
""[01:29:04.740][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:04.740][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=10) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:04.740][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:04.741][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=21) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=10, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:05.227][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:29:05.228][DEBUG][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line212] - Change set: [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\application.properties (MODIFY)]]
""[01:29:05.228][DEBUG][org.springframework.boot.devtools.restart.Restarter.restart:line249] - Restarting application
""[01:29:05.228][DEBUG][org.springframework.boot.devtools.restart.Restarter.stop:line305] - Stopping application
""[01:29:05.229][DEBUG][org.springframework.boot.availability.ApplicationAvailabilityBean.onApplicationEvent:line77] - Application availability state ReadinessState changed from ACCEPTING_TRAFFIC to REFUSING_TRAFFIC
""[01:29:05.229][DEBUG][org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext.doClose:line1052] - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@1f8de0ae, started on Fri Aug 18 01:28:58 KST 2023
""[01:29:05.230][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase 2147483647
""[01:29:05.230][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'webSocketHandlerMapping' completed its stop procedure
""[01:29:05.230][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'webServerGracefulShutdown' completed its stop procedure
""[01:29:05.230][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase 2147483646
""[01:29:05.243][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=21): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1748962198, responses=[])
""[01:29:05.244][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1748962198 with 0 response partition(s), 1 implied partition(s)
""[01:29:05.244][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:05.244][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Built incremental fetch (sessionId=1748962198, epoch=11) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:05.244][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:05.244][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-5, correlationId=22) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1748962198, sessionEpoch=11, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:05.248][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - About to unlock socket for:/[0:0:0:0:0:0:0:1]:8080
""[01:29:05.248][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - Socket unlock completed for:/[0:0:0:0:0:0:0:1]:8080
""[01:29:05.248][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:29:05.248][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Unregister host [localhost] at domain [null] for service [StandardService[Tomcat]]
""[01:29:05.248][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Unregister Context [] for service [StandardService[Tomcat]]
""[01:29:05.249][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Unregister Wrapper [dispatcherServlet] in Context [] for service [StandardService[Tomcat]]
""[01:29:05.249][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Stopping filters
""[01:29:05.249][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Stopping filter 'Tomcat WebSocket (JSR356) Filter'
""[01:29:05.249][DEBUG][org.apache.catalina.core.ApplicationFilterConfig.log:line173] - JMX de-registration complete for filter of type [org.apache.tomcat.websocket.server.WsFilter] and name [Tomcat WebSocket (JSR356) Filter]
""[01:29:05.249][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Stopping filter 'characterEncodingFilter'
""[01:29:05.249][DEBUG][org.apache.catalina.core.ApplicationFilterConfig.log:line173] - JMX de-registration complete for filter of type [org.springframework.boot.web.servlet.filter.OrderedCharacterEncodingFilter] and name [characterEncodingFilter]
""[01:29:05.249][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Stopping
""[01:29:05.249][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Unloading persisted sessions
""[01:29:05.249][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - No persisted sessions to unload
""[01:29:05.250][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Sending application stop events
""[01:29:05.250][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Processing standard container shutdown
""[01:29:05.250][DEBUG][org.apache.catalina.loader.WebappLoader.log:line173] - Stopping this Loader
""[01:29:05.250][DEBUG][org.apache.catalina.loader.WebappClassLoaderBase.log:line173] - getResourceAsStream(org/apache/catalina/loader/JdbcLeakPrevention.class)
""[01:29:05.250][DEBUG][org.apache.catalina.loader.WebappClassLoaderBase.log:line173] -   Delegating to parent classloader org.springframework.boot.devtools.restart.classloader.RestartClassLoader@37b3e632
""[01:29:05.251][DEBUG][org.apache.catalina.loader.WebappClassLoaderBase.log:line173] -   --> Returning stream from parent
""[01:29:05.252][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - resetContext Tomcat:j2eeType=WebModule,name=//localhost/,J2EEApplication=none,J2EEServer=none
""[01:29:05.253][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Stopping complete
""[01:29:05.254][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - Destroy initiated for 0.0.0.0/0.0.0.0:8080
""[01:29:05.254][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - Destroy completed for 0.0.0.0/0.0.0.0:8080
""[01:29:05.254][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'webServerStartStop' completed its stop procedure
""[01:29:05.254][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase 2147483547
""[01:29:05.254][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.wakeup:line189] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received user wakeup
""[01:29:05.254][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup:line512] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Raising WakeupException in response to user wakeup
""[01:29:05.255][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:05.255][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onLeavePrepare:line773] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Executing onLeavePrepare with generation Generation{generationId=52, memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', protocol='range'} and memberId consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc
""[01:29:05.255][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:29:05.255][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:29:05.255][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:05.255][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Member consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:29:05.255][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Sending LEAVE_GROUP request with header RequestHeader(apiKey=LEAVE_GROUP, apiVersion=4, clientId=consumer-my-consumer-group-5, correlationId=23) and timeout 30000 to node 2147482646: LeaveGroupRequestData(groupId='my-consumer-group', memberId='', members=[MemberIdentity(memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', groupInstanceId=null)])
""[01:29:05.255][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:29:05.255][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:29:05.255][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:29:05.255][DEBUG][org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler.shutdown:line224] - Shutting down ExecutorService
""[01:29:05.256][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.run:line1470] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Heartbeat thread has closed
""[01:29:05.256][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onLeavePrepare:line773] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Executing onLeavePrepare with generation Generation{generationId=-1, memberId='', protocol='null'} and memberId 
""[01:29:05.256][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:29:05.256][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:29:05.260][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Received LEAVE_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=LEAVE_GROUP, apiVersion=4, clientId=consumer-my-consumer-group-5, correlationId=23): LeaveGroupResponseData(throttleTimeMs=0, errorCode=0, members=[MemberResponse(memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', groupInstanceId=null, errorCode=0)])
""[01:29:05.261][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1095] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] LeaveGroup response with Generation{generationId=52, memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', protocol='range'} returned successfully: ClientResponse(receivedTimeMs=1692289745260, latencyMs=5, disconnected=false, requestHeader=RequestHeader(apiKey=LEAVE_GROUP, apiVersion=4, clientId=consumer-my-consumer-group-5, correlationId=23), responseBody=LeaveGroupResponseData(throttleTimeMs=0, errorCode=0, members=[MemberResponse(memberId='consumer-my-consumer-group-5-7a58e9f1-bf51-402a-96d0-284e94e57efc', groupInstanceId=null, errorCode=0)]))
""[01:29:05.261][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:29:05.261][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:29:05.261][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:29:05.262][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-5 unregistered
""[01:29:05.263][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer.close:line2403] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Kafka consumer has been closed
""[01:29:05.263][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:29:05.263][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - KafkaMessageListenerContainer [id=org.springframework.kafka.KafkaListenerEndpointContainer#0-0, clientIndex=-0, topicPartitions=[]] stopped normally
""[01:29:05.263][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry' completed its stop procedure
""[01:29:05.263][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase -2147483647
""[01:29:05.263][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'springBootLoggingLifecycle' completed its stop procedure
""[01:29:05.264][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.destroy:line452] - Unregistering JMX-exposed beans on shutdown
""[01:29:05.264][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.unregisterBeans:line186] - Unregistering JMX-exposed beans
""[01:29:05.264][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:29:05.264][DEBUG][org.hibernate.internal.SessionFactoryImpl.close:line821] - HHH000031: Closing
""[01:29:05.264][DEBUG][org.hibernate.type.spi.TypeConfiguration$Scope.unsetSessionFactory:line345] - Un-scoping TypeConfiguration [org.hibernate.type.spi.TypeConfiguration$Scope@438733e7] from SessionFactory [org.hibernate.internal.SessionFactoryImpl@310f3cf6]
""[01:29:05.264][DEBUG][org.hibernate.service.internal.AbstractServiceRegistryImpl.deRegisterChild:line428] - Implicitly destroying ServiceRegistry on de-registration of all child ServiceRegistries
""[01:29:05.264][DEBUG][org.hibernate.boot.registry.internal.BootstrapServiceRegistryImpl.deRegisterChild:line295] - Implicitly destroying Boot-strap registry on de-registration of all child ServiceRegistries
""[01:29:05.264][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-5 - Shutdown initiated...
""[01:29:05.265][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-5 - Before shutdown stats (total=10, active=0, idle=10, waiting=0)
""[01:29:05.265][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-5 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@7be05c42: (connection evicted)
""[01:29:05.265][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-5 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@27b24a19: (connection evicted)
""[01:29:05.265][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-5 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@668f4022: (connection evicted)
""[01:29:05.265][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-5 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@572346f8: (connection evicted)
""[01:29:05.266][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-5 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@6a0bf6d: (connection evicted)
""[01:29:05.266][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-5 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@89f5280: (connection evicted)
""[01:29:05.267][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-5 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@2eec56c: (connection evicted)
""[01:29:05.267][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-5 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@3606e6e: (connection evicted)
""[01:29:05.267][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-5 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@441b2877: (connection evicted)
""[01:29:05.267][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-5 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@7c652654: (connection evicted)
""[01:29:05.267][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-5 - After shutdown stats (total=0, active=0, idle=0, waiting=0)
""[01:29:05.268][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-5 - Shutdown completed.
""[01:29:05.297][DEBUG][org.springframework.boot.devtools.restart.classloader.RestartClassLoader.<init>:line85] - Created RestartClassLoader org.springframework.boot.devtools.restart.classloader.RestartClassLoader@728e905a
""[01:29:05.298][DEBUG][org.springframework.boot.devtools.restart.Restarter.doStart:line281] - Starting application com.jinseong.demo.Application with URLs [file:/C:/Users/jinsung/Documents/GitHub/RMS/demo/target/classes/]
""[01:29:05.351][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 22504 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:29:05.351][DEBUG][com.jinseong.demo.Application.logStarting:line56] - Running with Spring Boot v2.7.15-SNAPSHOT, Spring v5.3.29
""[01:29:05.351][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:29:05.351][DEBUG][org.springframework.boot.SpringApplication.load:line664] - Loading source class com.jinseong.demo.Application
""[01:29:05.355][DEBUG][org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext.prepareRefresh:line629] - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@370192a6
""[01:29:05.356][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor'
""[01:29:05.357][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory'
""[01:29:05.366][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\config\WebConfig.class]
""[01:29:05.366][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\config\WebSocketConfig.class]
""[01:29:05.367][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\controller\MainController.class]
""[01:29:05.369][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\handler\SocketHandler.class]
""[01:29:05.369][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line441] - Ignored because not a concrete top-level class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\repository\ReservationRepository.class]
""[01:29:05.370][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\service\KafkaConsumerService.class]
""[01:29:05.580][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:29:05.581][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.AutoConfigurationPackages'
""[01:29:05.581][DEBUG][org.springframework.boot.autoconfigure.AutoConfigurationPackages.get:line196] - @EnableAutoConfiguration was declared on a class in the package 'com.jinseong.demo'. Automatic @Repository and @Entity scanning is enabled.
""[01:29:05.581][DEBUG][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line145] - Scanning for JPA repositories in packages com.jinseong.demo.
""[01:29:05.590][DEBUG][org.springframework.data.repository.config.RepositoryComponentProvider.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\repository\ReservationRepository.class]
""[01:29:05.600][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 18 ms. Found 1 JPA repository interfaces.
""[01:29:05.638][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'propertySourcesPlaceholderConfigurer'
""[01:29:05.639][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'emBeanDefinitionRegistrarPostProcessor'
""[01:29:05.639][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor'
""[01:29:05.639][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.DevToolsDataSourceAutoConfiguration$DatabaseShutdownExecutorEntityManagerFactoryDependsOnPostProcessor'
""[01:29:05.645][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerProcessor'
""[01:29:05.646][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'preserveErrorControllerTargetClassPostProcessor'
""[01:29:05.646][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerFactory'
""[01:29:05.646][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.transaction.config.internalTransactionalEventListenerFactory'
""[01:29:05.647][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor'
""[01:29:05.647][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor'
""[01:29:05.647][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalPersistenceAnnotationProcessor'
""[01:29:05.647][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor'
""[01:29:05.648][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.internalConfigurationPropertiesBinder'
""[01:29:05.648][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.internalConfigurationPropertiesBinderFactory'
""[01:29:05.649][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.aop.config.internalAutoProxyCreator'
""[01:29:05.650][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'persistenceExceptionTranslationPostProcessor'
""[01:29:05.650][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'persistenceExceptionTranslationPostProcessor' via factory method to bean named 'environment'
""[01:29:05.650][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor'
""[01:29:05.651][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webServerFactoryCustomizerBeanPostProcessor'
""[01:29:05.651][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'errorPageRegistrarBeanPostProcessor'
""[01:29:05.651][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'projectingArgumentResolverBeanPostProcessor'
""[01:29:05.651][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.transaction.config.internalTransactionAdvisor'
""[01:29:05.652][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration'
""[01:29:05.653][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionAttributeSource'
""[01:29:05.654][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionInterceptor'
""[01:29:05.654][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'transactionInterceptor' via factory method to bean named 'transactionAttributeSource'
""[01:29:05.655][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.transaction.config.internalTransactionAdvisor' via factory method to bean named 'transactionAttributeSource'
""[01:29:05.655][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.transaction.config.internalTransactionAdvisor' via factory method to bean named 'transactionInterceptor'
""[01:29:05.655][DEBUG][org.springframework.ui.context.support.UiApplicationContextUtils.initThemeSource:line85] - Unable to locate ThemeSource with name 'themeSource': using default [org.springframework.ui.context.support.ResourceBundleThemeSource@5b31e736]
""[01:29:05.656][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'tomcatServletWebServerFactory'
""[01:29:05.656][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryConfiguration$EmbeddedTomcat'
""[01:29:05.657][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'websocketServletWebServerCustomizer'
""[01:29:05.657][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration'
""[01:29:05.657][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'servletWebServerFactoryCustomizer'
""[01:29:05.658][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration'
""[01:29:05.658][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:29:05.658][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.BoundConfigurationProperties'
""[01:29:05.664][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'servletWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:29:05.665][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'tomcatServletWebServerFactoryCustomizer'
""[01:29:05.665][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'tomcatServletWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:29:05.665][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'tomcatWebServerFactoryCustomizer'
""[01:29:05.665][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration$TomcatWebServerFactoryCustomizerConfiguration'
""[01:29:05.666][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'tomcatWebServerFactoryCustomizer' via factory method to bean named 'environment'
""[01:29:05.666][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'tomcatWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:29:05.666][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'localeCharsetMappingsCustomizer'
""[01:29:05.666][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration'
""[01:29:05.667][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:29:05.668][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'errorPageCustomizer'
""[01:29:05.668][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration'
""[01:29:05.668][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:29:05.668][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dispatcherServletRegistration'
""[01:29:05.669][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration$DispatcherServletRegistrationConfiguration'
""[01:29:05.669][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dispatcherServlet'
""[01:29:05.669][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration$DispatcherServletConfiguration'
""[01:29:05.669][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
""[01:29:05.671][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dispatcherServlet' via factory method to bean named 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
""[01:29:05.674][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dispatcherServletRegistration' via factory method to bean named 'dispatcherServlet'
""[01:29:05.674][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dispatcherServletRegistration' via factory method to bean named 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
""[01:29:05.675][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'multipartConfigElement'
""[01:29:05.675][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration'
""[01:29:05.675][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.servlet.multipart-org.springframework.boot.autoconfigure.web.servlet.MultipartProperties'
""[01:29:05.676][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration' via constructor to bean named 'spring.servlet.multipart-org.springframework.boot.autoconfigure.web.servlet.MultipartProperties'
""[01:29:05.677][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'errorPageCustomizer' via factory method to bean named 'dispatcherServletRegistration'
""[01:29:05.683][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol port=8080)
""[01:29:05.683][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol bindOnInit=false)
""[01:29:05.684][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.tomcat.util.net.NioEndpoint bindOnInit=false)
""[01:29:05.684][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol maxPostSize=2097152)
""[01:29:05.684][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.tomcat.util.net.NioEndpoint maxPostSize=2097152)
""[01:29:05.684][DEBUG][org.apache.catalina.core.ContainerBase.log:line173] - Add child StandardHost[localhost] StandardEngine[Tomcat]
""[01:29:05.684][DEBUG][org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getArchiveFileDocumentRoot:line81] - Code archive: C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot\2.7.15-SNAPSHOT\spring-boot-2.7.15-SNAPSHOT.jar
""[01:29:05.685][DEBUG][org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getExplodedWarFileDocumentRoot:line125] - Code archive: C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot\2.7.15-SNAPSHOT\spring-boot-2.7.15-SNAPSHOT.jar
""[01:29:05.686][DEBUG][org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.logNoDocumentRoots:line149] - None of the document roots [src/main/webapp, public, static] point to a directory and will be ignored.
""[01:29:05.687][DEBUG][org.apache.catalina.core.ContainerBase.log:line173] - Add child TomcatEmbeddedContext[] StandardEngine[Tomcat].StandardHost[localhost]
""[01:29:05.694][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:29:05.695][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol parseBodyMethods=POST)
""[01:29:05.695][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.tomcat.util.net.NioEndpoint parseBodyMethods=POST)
""[01:29:05.695][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:29:05.695][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:29:05.695][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Starting ROOT
""[01:29:05.701][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Configuring default Resources
""[01:29:05.706][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Processing standard container startup
""[01:29:05.706][DEBUG][org.apache.catalina.loader.WebappLoader.log:line173] - Starting this Loader
""[01:29:05.746][DEBUG][org.apache.catalina.authenticator.AuthenticatorBase.log:line173] - No SingleSignOn Valve is present
""[01:29:05.747][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:29:05.747][DEBUG][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line286] - Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
""[01:29:05.747][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 392 ms
""[01:29:05.748][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'characterEncodingFilter'
""[01:29:05.751][DEBUG][org.springframework.boot.web.servlet.ServletContextInitializerBeans.logMappings:line237] - Mapping filters: characterEncodingFilter urls=[/*] order=-2147483648
""[01:29:05.751][DEBUG][org.springframework.boot.web.servlet.ServletContextInitializerBeans.logMappings:line237] - Mapping servlets: dispatcherServlet urls=[/]
""[01:29:05.751][DEBUG][org.apache.catalina.core.ContainerBase.log:line173] - Add child StandardWrapper[dispatcherServlet] StandardEngine[Tomcat].StandardHost[localhost].TomcatEmbeddedContext[]
""[01:29:05.751][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Configuring application event listeners
""[01:29:05.751][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Sending application start events
""[01:29:05.751][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Start: Loading persisted sessions
""[01:29:05.752][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Loading persisted sessions from [C:\Users\jinsung\AppData\Local\Temp\8B19C3BAB13401F8F1E8E8FA5BBF4BD1C70DE7CC\servlet-sessions\SESSIONS.ser]
""[01:29:05.752][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - No persisted data file found
""[01:29:05.752][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Starting filters
""[01:29:05.752][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Starting filter 'Tomcat WebSocket (JSR356) Filter'
""[01:29:05.752][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Starting filter 'characterEncodingFilter'
""[01:29:05.752][DEBUG][org.springframework.boot.web.servlet.filter.OrderedCharacterEncodingFilter.init:line242] - Filter 'characterEncodingFilter' configured for use
""[01:29:05.753][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Starting completed
""[01:29:05.753][DEBUG][org.apache.catalina.mapper.Mapper.log:line173] - Registered host [localhost]
""[01:29:05.753][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Register Wrapper [dispatcherServlet] in Context [] for service [StandardService[Tomcat]]
""[01:29:05.753][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Register Context [] for service [StandardService[Tomcat]]
""[01:29:05.753][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Register host [localhost] at domain [null] for service [StandardService[Tomcat]]
""[01:29:05.754][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dataSourceScriptDatabaseInitializer'
""[01:29:05.754][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.sql.init.DataSourceInitializationConfiguration'
""[01:29:05.754][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dataSource'
""[01:29:05.755][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration$Hikari'
""[01:29:05.755][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
""[01:29:05.759][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dataSource' via factory method to bean named 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
""[01:29:05.759][DEBUG][com.zaxxer.hikari.HikariConfig.attemptFromContextLoader:line971] - Driver class com.mysql.cj.jdbc.Driver found in Thread context class loader org.springframework.boot.devtools.restart.classloader.RestartClassLoader@728e905a
""[01:29:05.766][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.sql.init-org.springframework.boot.autoconfigure.sql.init.SqlInitializationProperties'
""[01:29:05.767][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dataSourceScriptDatabaseInitializer' via factory method to bean named 'dataSource'
""[01:29:05.767][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dataSourceScriptDatabaseInitializer' via factory method to bean named 'spring.sql.init-org.springframework.boot.autoconfigure.sql.init.SqlInitializationProperties'
""[01:29:05.769][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'inMemoryDatabaseShutdownExecutor'
""[01:29:05.769][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.DevToolsDataSourceAutoConfiguration'
""[01:29:05.769][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'inMemoryDatabaseShutdownExecutor' via factory method to bean named 'dataSource'
""[01:29:05.771][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'inMemoryDatabaseShutdownExecutor' via factory method to bean named 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
""[01:29:05.772][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'entityManagerFactory'
""[01:29:05.772][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration'
""[01:29:05.773][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jpa-org.springframework.boot.autoconfigure.orm.jpa.JpaProperties'
""[01:29:05.774][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jpa.hibernate-org.springframework.boot.autoconfigure.orm.jpa.HibernateProperties'
""[01:29:05.775][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'dataSource'
""[01:29:05.775][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'spring.jpa-org.springframework.boot.autoconfigure.orm.jpa.JpaProperties'
""[01:29:05.775][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@4d5791ee'
""[01:29:05.775][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'spring.jpa.hibernate-org.springframework.boot.autoconfigure.orm.jpa.HibernateProperties'
""[01:29:05.775][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'hikariPoolDataSourceMetadataProvider'
""[01:29:05.775][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.metadata.DataSourcePoolMetadataProvidersConfiguration$HikariPoolDataSourceMetadataProviderConfiguration'
""[01:29:05.776][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'entityManagerFactoryBuilder'
""[01:29:05.777][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jpaVendorAdapter'
""[01:29:05.777][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'entityManagerFactoryBuilder' via factory method to bean named 'jpaVendorAdapter'
""[01:29:05.777][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'entityManagerFactory' via factory method to bean named 'entityManagerFactoryBuilder'
""[01:29:05.778][DEBUG][org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection:line117] - Fetching JDBC Connection from DataSource
""[01:29:05.778][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1103] - HikariPool-6 - configuration:
""[01:29:05.778][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - allowPoolSuspension................................false
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - autoCommit................................true
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - catalog................................none
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - connectionInitSql................................none
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - connectionTestQuery................................none
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - connectionTimeout................................30000
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSource................................none
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSourceClassName................................none
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSourceJNDI................................none
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSourceProperties................................{password=<masked>}
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - driverClassName................................"com.mysql.cj.jdbc.Driver"
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - exceptionOverrideClassName................................none
""[01:29:05.779][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - healthCheckProperties................................{}
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - healthCheckRegistry................................none
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - idleTimeout................................600000
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - initializationFailTimeout................................1
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - isolateInternalQueries................................false
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - jdbcUrl................................jdbc:mysql://localhost:3306/metadb?useSSL=false&serverTimezone=UTC&useLegacyDatetimeCode=false&allowPublicKeyRetrieval=true
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - keepaliveTime................................0
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - leakDetectionThreshold................................0
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - maxLifetime................................1800000
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - maximumPoolSize................................10
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - metricRegistry................................none
""[01:29:05.780][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - metricsTrackerFactory................................none
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - minimumIdle................................10
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - password................................<masked>
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - poolName................................"HikariPool-6"
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - readOnly................................false
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - registerMbeans................................false
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - scheduledExecutor................................none
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - schema................................none
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - threadFactory................................internal
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - transactionIsolation................................default
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - username................................"root"
""[01:29:05.781][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - validationTimeout................................5000
""[01:29:05.781][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-6 - Starting...
""[01:29:05.792][DEBUG][com.zaxxer.hikari.pool.HikariPool.checkFailFast:line565] - HikariPool-6 - Added connection com.mysql.cj.jdbc.ConnectionImpl@641eaf39
""[01:29:05.792][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-6 - Start completed.
""[01:29:05.800][DEBUG][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory:line361] - Building JPA container EntityManagerFactory for persistence unit 'default'
""[01:29:05.800][DEBUG][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line102] - PersistenceUnitInfo [
	name: default
	persistence provider classname: null
	classloader: org.springframework.boot.devtools.restart.classloader.RestartClassLoader@728e905a
	excludeUnlistedClasses: true
	JTA datasource: null
	Non JTA datasource: HikariDataSource (HikariPool-6)
	Transaction type: RESOURCE_LOCAL
	PU root URL: file:/C:/Users/jinsung/Documents/GitHub/RMS/demo/target/classes/
	Shared Cache Mode: UNSPECIFIED
	Validation Mode: AUTO
	Jar files URLs []
	Managed classes names [
		com.jinseong.demo.entity.Reservation]
	Mapping files names []
	Properties []
""[01:29:05.800][DEBUG][org.hibernate.integrator.internal.IntegratorServiceImpl.addIntegrator:line46] - Adding Integrator [org.hibernate.cfg.beanvalidation.BeanValidationIntegrator].
""[01:29:05.800][DEBUG][org.hibernate.integrator.internal.IntegratorServiceImpl.addIntegrator:line46] - Adding Integrator [org.hibernate.secure.spi.JaccIntegrator].
""[01:29:05.800][DEBUG][org.hibernate.integrator.internal.IntegratorServiceImpl.addIntegrator:line46] - Adding Integrator [org.hibernate.cache.internal.CollectionCacheInvalidator].
""[01:29:05.803][DEBUG][org.hibernate.service.spi.ServiceBinding.setService:line68] - Overriding existing service binding [org.hibernate.secure.spi.JaccService]
""[01:29:05.804][DEBUG][org.hibernate.cache.internal.RegionFactoryInitiator.resolveRegionFactory:line118] - Cannot default RegionFactory based on registered strategies as `[]` RegionFactory strategies were registered
""[01:29:05.804][DEBUG][org.hibernate.cache.internal.RegionFactoryInitiator.initiateService:line49] - Cache region factory : org.hibernate.cache.internal.NoCachingRegionFactory
""[01:29:05.804][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration boolean -> org.hibernate.type.BooleanType@65249d16
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration boolean -> org.hibernate.type.BooleanType@65249d16
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Boolean -> org.hibernate.type.BooleanType@65249d16
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration numeric_boolean -> org.hibernate.type.NumericBooleanType@59548376
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration true_false -> org.hibernate.type.TrueFalseType@a92c074
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration yes_no -> org.hibernate.type.YesNoType@59827e7b
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration byte -> org.hibernate.type.ByteType@180f8470
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration byte -> org.hibernate.type.ByteType@180f8470
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Byte -> org.hibernate.type.ByteType@180f8470
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration character -> org.hibernate.type.CharacterType@653deb34
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration char -> org.hibernate.type.CharacterType@653deb34
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Character -> org.hibernate.type.CharacterType@653deb34
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration short -> org.hibernate.type.ShortType@79300687
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration short -> org.hibernate.type.ShortType@79300687
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Short -> org.hibernate.type.ShortType@79300687
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration integer -> org.hibernate.type.IntegerType@338bde7c
""[01:29:05.805][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration int -> org.hibernate.type.IntegerType@338bde7c
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Integer -> org.hibernate.type.IntegerType@338bde7c
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration long -> org.hibernate.type.LongType@5743e079
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration long -> org.hibernate.type.LongType@5743e079
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Long -> org.hibernate.type.LongType@5743e079
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration float -> org.hibernate.type.FloatType@5d2dc5ee
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration float -> org.hibernate.type.FloatType@5d2dc5ee
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Float -> org.hibernate.type.FloatType@5d2dc5ee
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration double -> org.hibernate.type.DoubleType@24d0f4f2
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration double -> org.hibernate.type.DoubleType@24d0f4f2
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Double -> org.hibernate.type.DoubleType@24d0f4f2
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration big_decimal -> org.hibernate.type.BigDecimalType@4945a62a
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.math.BigDecimal -> org.hibernate.type.BigDecimalType@4945a62a
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration big_integer -> org.hibernate.type.BigIntegerType@14dc753
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.math.BigInteger -> org.hibernate.type.BigIntegerType@14dc753
""[01:29:05.806][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration string -> org.hibernate.type.StringType@327c7021
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.String -> org.hibernate.type.StringType@327c7021
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration nstring -> org.hibernate.type.StringNVarcharType@112865f8
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration ncharacter -> org.hibernate.type.CharacterNCharType@7538e501
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration url -> org.hibernate.type.UrlType@1a20c3aa
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.net.URL -> org.hibernate.type.UrlType@1a20c3aa
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Duration -> org.hibernate.type.DurationType@4b0c45b7
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.Duration -> org.hibernate.type.DurationType@4b0c45b7
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Instant -> org.hibernate.type.InstantType@1959fe8b
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.Instant -> org.hibernate.type.InstantType@1959fe8b
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration LocalDateTime -> org.hibernate.type.LocalDateTimeType@2bfb104c
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.LocalDateTime -> org.hibernate.type.LocalDateTimeType@2bfb104c
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration LocalDate -> org.hibernate.type.LocalDateType@37dabb0a
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.LocalDate -> org.hibernate.type.LocalDateType@37dabb0a
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration LocalTime -> org.hibernate.type.LocalTimeType@1e5261bb
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.LocalTime -> org.hibernate.type.LocalTimeType@1e5261bb
""[01:29:05.807][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration OffsetDateTime -> org.hibernate.type.OffsetDateTimeType@48a9795c
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.OffsetDateTime -> org.hibernate.type.OffsetDateTimeType@48a9795c
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration OffsetTime -> org.hibernate.type.OffsetTimeType@3b236975
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.OffsetTime -> org.hibernate.type.OffsetTimeType@3b236975
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration ZonedDateTime -> org.hibernate.type.ZonedDateTimeType@59c387f0
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.ZonedDateTime -> org.hibernate.type.ZonedDateTimeType@59c387f0
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration date -> org.hibernate.type.DateType@54917aca
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Date -> org.hibernate.type.DateType@54917aca
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration time -> org.hibernate.type.TimeType@57719a9d
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Time -> org.hibernate.type.TimeType@57719a9d
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration timestamp -> org.hibernate.type.TimestampType@773939c7
""[01:29:05.808][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Timestamp -> org.hibernate.type.TimestampType@773939c7
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Date -> org.hibernate.type.TimestampType@773939c7
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration dbtimestamp -> org.hibernate.type.DbTimestampType@3200ccd7
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration calendar -> org.hibernate.type.CalendarType@6d18b777
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Calendar -> org.hibernate.type.CalendarType@6d18b777
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.GregorianCalendar -> org.hibernate.type.CalendarType@6d18b777
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration calendar_date -> org.hibernate.type.CalendarDateType@36667d3b
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration calendar_time -> org.hibernate.type.CalendarTimeType@82f8d31
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration locale -> org.hibernate.type.LocaleType@3cfd8e97
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Locale -> org.hibernate.type.LocaleType@3cfd8e97
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration currency -> org.hibernate.type.CurrencyType@14762570
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Currency -> org.hibernate.type.CurrencyType@14762570
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration timezone -> org.hibernate.type.TimeZoneType@11fc0d60
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.TimeZone -> org.hibernate.type.TimeZoneType@11fc0d60
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration class -> org.hibernate.type.ClassType@654e4c6b
""[01:29:05.809][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Class -> org.hibernate.type.ClassType@654e4c6b
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration uuid-binary -> org.hibernate.type.UUIDBinaryType@3517ef63
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.UUID -> org.hibernate.type.UUIDBinaryType@3517ef63
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration uuid-char -> org.hibernate.type.UUIDCharType@10ef1114
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration binary -> org.hibernate.type.BinaryType@61899964
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration byte[] -> org.hibernate.type.BinaryType@61899964
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [B -> org.hibernate.type.BinaryType@61899964
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration wrapper-binary -> org.hibernate.type.WrapperBinaryType@7633ac2a
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Byte[] -> org.hibernate.type.WrapperBinaryType@7633ac2a
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [Ljava.lang.Byte; -> org.hibernate.type.WrapperBinaryType@7633ac2a
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration row_version -> org.hibernate.type.RowVersionType@7cd52978
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration image -> org.hibernate.type.ImageType@145af047
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration characters -> org.hibernate.type.CharArrayType@39351911
""[01:29:05.810][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration char[] -> org.hibernate.type.CharArrayType@39351911
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [C -> org.hibernate.type.CharArrayType@39351911
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration wrapper-characters -> org.hibernate.type.CharacterArrayType@520ca0e1
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [Ljava.lang.Character; -> org.hibernate.type.CharacterArrayType@520ca0e1
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Character[] -> org.hibernate.type.CharacterArrayType@520ca0e1
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration text -> org.hibernate.type.TextType@747cd31
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration ntext -> org.hibernate.type.NTextType@44dcdd56
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration blob -> org.hibernate.type.BlobType@5530b94d
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Blob -> org.hibernate.type.BlobType@5530b94d
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration materialized_blob -> org.hibernate.type.MaterializedBlobType@628c10a2
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration clob -> org.hibernate.type.ClobType@5b9b6787
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Clob -> org.hibernate.type.ClobType@5b9b6787
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration nclob -> org.hibernate.type.NClobType@790f27cf
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.NClob -> org.hibernate.type.NClobType@790f27cf
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration materialized_clob -> org.hibernate.type.MaterializedClobType@29250372
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration materialized_nclob -> org.hibernate.type.MaterializedNClobType@2bae1ff4
""[01:29:05.811][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration serializable -> org.hibernate.type.SerializableType@2b09e259
""[01:29:05.812][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration object -> org.hibernate.type.ObjectType@2b3889a8
""[01:29:05.812][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Object -> org.hibernate.type.ObjectType@2b3889a8
""[01:29:05.812][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_date -> org.hibernate.type.AdaptedImmutableType@555900a8
""[01:29:05.812][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_time -> org.hibernate.type.AdaptedImmutableType@7fbd37c8
""[01:29:05.812][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_timestamp -> org.hibernate.type.AdaptedImmutableType@741f5072
""[01:29:05.812][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_dbtimestamp -> org.hibernate.type.AdaptedImmutableType@49c270dd
""[01:29:05.812][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_calendar -> org.hibernate.type.AdaptedImmutableType@5403750d
""[01:29:05.812][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_calendar_date -> org.hibernate.type.AdaptedImmutableType@42960b32
""[01:29:05.812][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_binary -> org.hibernate.type.AdaptedImmutableType@4c044fd2
""[01:29:05.812][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_serializable -> org.hibernate.type.AdaptedImmutableType@169a8a17
""[01:29:05.815][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectJpaTempClassLoader:line259] - Injecting JPA temp ClassLoader [org.springframework.instrument.classloading.SimpleThrowawayClassLoader@2bc36152] into BootstrapContext; was [null]
""[01:29:05.816][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.injectTempClassLoader:line45] - ClassLoaderAccessImpl#injectTempClassLoader(org.springframework.instrument.classloading.SimpleThrowawayClassLoader@2bc36152) [was null]
""[01:29:05.816][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectScanEnvironment:line269] - Injecting ScanEnvironment [org.hibernate.jpa.boot.internal.StandardJpaScanEnvironmentImpl@4557c127] into BootstrapContext; was [null]
""[01:29:05.816][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectScanOptions:line264] - Injecting ScanOptions [org.hibernate.boot.archive.scan.internal.StandardScanOptions@75f21a8] into BootstrapContext; was [org.hibernate.boot.archive.scan.internal.StandardScanOptions@2f7f3709]
""[01:29:05.816][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectJpaTempClassLoader:line259] - Injecting JPA temp ClassLoader [null] into BootstrapContext; was [org.springframework.instrument.classloading.SimpleThrowawayClassLoader@2bc36152]
""[01:29:05.816][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.injectTempClassLoader:line45] - ClassLoaderAccessImpl#injectTempClassLoader(null) [was org.springframework.instrument.classloading.SimpleThrowawayClassLoader@2bc36152]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [uuid2] -> [org.hibernate.id.UUIDGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [guid] -> [org.hibernate.id.GUIDGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [uuid] -> [org.hibernate.id.UUIDHexGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [uuid.hex] -> [org.hibernate.id.UUIDHexGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [assigned] -> [org.hibernate.id.Assigned]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [identity] -> [org.hibernate.id.IdentityGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [select] -> [org.hibernate.id.SelectGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [sequence] -> [org.hibernate.id.enhanced.SequenceStyleGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [seqhilo] -> [org.hibernate.id.SequenceHiLoGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [increment] -> [org.hibernate.id.IncrementGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [foreign] -> [org.hibernate.id.ForeignGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [sequence-identity] -> [org.hibernate.id.SequenceIdentityGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [enhanced-sequence] -> [org.hibernate.id.enhanced.SequenceStyleGenerator]
""[01:29:05.817][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [enhanced-table] -> [org.hibernate.id.enhanced.TableGenerator]
""[01:29:05.818][DEBUG][org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.initiateService:line72] - Database ->
       name : MySQL
    version : 8.0.34
      major : 8
      minor : 0
""[01:29:05.818][DEBUG][org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.initiateService:line83] - Driver ->
       name : MySQL Connector/J
    version : mysql-connector-java-8.0.27 (Revision: e920b979015ae7117d60d72bcc8f077a839cd791)
      major : 8
      minor : 0
""[01:29:05.818][DEBUG][org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.debugf:line389] - JDBC version : 4.2
""[01:29:05.818][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:29:05.818][DEBUG][org.hibernate.engine.jdbc.env.spi.IdentifierHelperBuilder.applyIdentifierCasing:line119] - JDBC driver metadata reported database stores quoted identifiers in more than one case
""[01:29:05.818][DEBUG][org.hibernate.engine.jdbc.env.spi.IdentifierHelperBuilder.build:line197] - IdentifierCaseStrategy for both quoted and unquoted identifiers was set to the same strategy [MIXED]; that will likely lead to problems in schema update and validation if using quoted identifiers
""[01:29:05.819][DEBUG][org.hibernate.type.spi.TypeConfiguration$Scope.scope:line149] - Scoping TypeConfiguration [org.hibernate.type.spi.TypeConfiguration@1f861a45] to MetadataBuildingContext [org.hibernate.boot.internal.MetadataBuildingContextRootImpl@64a3ae6b]
""[01:29:05.820][DEBUG][org.hibernate.boot.model.relational.Namespace.<init>:line51] - Created database namespace [logicalName=Name{catalog=null, schema=null}, physicalName=Name{catalog=null, schema=null}]
""[01:29:05.820][DEBUG][org.hibernate.cfg.AnnotationBinder.bindClass:line547] - Binding entity from annotated class: com.jinseong.demo.entity.Reservation
""[01:29:05.820][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3DiscriminatorColumn{logicalColumnName'DTYPE', discriminatorTypeName='string'}
""[01:29:05.820][DEBUG][org.hibernate.cfg.annotations.EntityBinder.bindEntity:line431] - Import with entity name Reservation
""[01:29:05.820][DEBUG][org.hibernate.cfg.annotations.EntityBinder.bindTable:line874] - Bind entity com.jinseong.demo.entity.Reservation on table reservation
""[01:29:05.822][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=reservation_id, insertable=true, updatable=true, unique=false}
""[01:29:05.822][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line60] - Not known whether passed class name [com.jinseong.demo.entity.Reservation] is safe
""[01:29:05.823][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line62] - No temp ClassLoader provided; using live ClassLoader for loading potentially unsafe class : com.jinseong.demo.entity.Reservation
""[01:29:05.823][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property id with lazy=false
""[01:29:05.823][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:id]
""[01:29:05.823][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for id
""[01:29:05.823][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property id
""[01:29:05.823][DEBUG][org.hibernate.cfg.BinderHelper.makeIdGenerator:line514] - #makeIdGenerator(org.hibernate.mapping.SimpleValue([org.hibernate.mapping.Column(reservation_id)]), id, identity, , ...)
""[01:29:05.823][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=count, insertable=true, updatable=true, unique=false}
""[01:29:05.823][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property count with lazy=false
""[01:29:05.823][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:count]
""[01:29:05.823][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for count
""[01:29:05.824][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property count
""[01:29:05.824][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=date, insertable=true, updatable=true, unique=false}
""[01:29:05.824][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property date with lazy=false
""[01:29:05.824][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:date]
""[01:29:05.824][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for date
""[01:29:05.824][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property date
""[01:29:05.824][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=name, insertable=true, updatable=true, unique=false}
""[01:29:05.824][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property name with lazy=false
""[01:29:05.824][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:name]
""[01:29:05.824][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for name
""[01:29:05.824][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property name
""[01:29:05.825][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=number, insertable=true, updatable=true, unique=false}
""[01:29:05.825][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property number with lazy=false
""[01:29:05.825][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:number]
""[01:29:05.825][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for number
""[01:29:05.825][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property number
""[01:29:05.825][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=time, insertable=true, updatable=true, unique=false}
""[01:29:05.825][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property time with lazy=false
""[01:29:05.825][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:time]
""[01:29:05.825][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for time
""[01:29:05.825][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property time
""[01:29:05.827][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for id
""[01:29:05.827][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for count
""[01:29:05.827][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for date
""[01:29:05.827][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for name
""[01:29:05.827][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for number
""[01:29:05.827][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for time
""[01:29:05.827][DEBUG][org.hibernate.mapping.PrimaryKey.addColumn:line36] - Forcing column [reservation_id] to be non-null as it is part of the primary key for table [reservation]
""[01:29:05.829][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line208] - Building session factory
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line68] - SessionFactory name : null
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line69] - Automatic flush during beforeCompletion(): enabled
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line70] - Automatic session close at end of transaction: disabled
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line72] - Statistics: disabled
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line74] - Deleted entity synthetic identifier rollback: disabled
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line75] - Default entity-mode: pojo
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line76] - Check Nullability in Core (should be disabled when Bean Validation is on): enabled
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line77] - Allow initialization of lazy state outside session : disabled
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line79] - Using BatchFetchStyle : LEGACY
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line80] - Default batch fetch size: -1
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line81] - Maximum outer join fetch depth: 2
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line82] - Default null ordering: NONE
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line83] - Order SQL updates by primary key: disabled
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line84] - Order SQL inserts for batching: disabled
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line86] - multi-tenancy strategy : NONE
""[01:29:05.830][DEBUG][org.hibernate.cfg.Settings.<init>:line88] - JTA Track by Thread: enabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line90] - Query language substitutions: {}
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line91] - Named query checking : enabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line93] - Second-level cache: disabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line94] - Second-level query cache: disabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line95] - Second-level query cache factory: null
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line96] - Second-level cache region prefix: null
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line97] - Optimize second-level cache for minimal puts: disabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line98] - Structured second-level cache entries: disabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line99] - Second-level cache direct-reference entries: disabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line100] - Automatic eviction of collection cache: disabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line102] - JDBC batch size: 15
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line103] - JDBC batch updates for versioned data: enabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line104] - Scrollable result sets: enabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line105] - Wrap result sets: disabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line106] - JDBC3 getGeneratedKeys(): enabled
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line107] - JDBC result set fetch size: null
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line108] - Connection release mode: ON_CLOSE
""[01:29:05.831][DEBUG][org.hibernate.cfg.Settings.<init>:line109] - Generate SQL with comments: disabled
""[01:29:05.832][DEBUG][org.hibernate.cfg.Settings.<init>:line111] - JPA compliance - query : disabled
""[01:29:05.832][DEBUG][org.hibernate.cfg.Settings.<init>:line112] - JPA compliance - closed-handling : disabled
""[01:29:05.832][DEBUG][org.hibernate.cfg.Settings.<init>:line113] - JPA compliance - lists : disabled
""[01:29:05.832][DEBUG][org.hibernate.cfg.Settings.<init>:line114] - JPA compliance - transactions : disabled
""[01:29:05.834][DEBUG][org.hibernate.service.internal.SessionFactoryServiceRegistryImpl.getService:line92] - EventListenerRegistry access via ServiceRegistry is deprecated.  Use `sessionFactory.getEventEngine().getListenerRegistry()` instead
""[01:29:05.834][DEBUG][org.hibernate.service.internal.SessionFactoryServiceRegistryImpl.getService:line92] - EventListenerRegistry access via ServiceRegistry is deprecated.  Use `sessionFactory.getEventEngine().getListenerRegistry()` instead
""[01:29:05.834][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line276] - Session factory constructed with filter configurations : {}
""[01:29:05.834][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line277] - Instantiating session factory with properties: {hibernate.id.new_generator_mappings=true, java.specification.version=17, sun.cpu.isalist=amd64, hibernate.resource.beans.container=org.springframework.orm.hibernate5.SpringBeanContainer@4c9e3a01, hibernate.connection.handling_mode=DELAYED_ACQUISITION_AND_HOLD, sun.jnu.encoding=MS949, hibernate.implicit_naming_strategy=org.springframework.boot.orm.jpa.hibernate.SpringImplicitNamingStrategy, java.class.path=C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-web\2.7.15-SNAPSHOT\spring-boot-starter-web-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter\2.7.15-SNAPSHOT\spring-boot-starter-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-logging\2.7.15-SNAPSHOT\spring-boot-starter-logging-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\ch\qos\logback\logback-classic\1.2.12\logback-classic-1.2.12.jar;C:\Users\jinsung\.m2\repository\ch\qos\logback\logback-core\1.2.12\logback-core-1.2.12.jar;C:\Users\jinsung\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.17.2\log4j-to-slf4j-2.17.2.jar;C:\Users\jinsung\.m2\repository\org\apache\logging\log4j\log4j-api\2.17.2\log4j-api-2.17.2.jar;C:\Users\jinsung\.m2\repository\org\slf4j\jul-to-slf4j\1.7.36\jul-to-slf4j-1.7.36.jar;C:\Users\jinsung\.m2\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;C:\Users\jinsung\.m2\repository\org\yaml\snakeyaml\1.30\snakeyaml-1.30.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-json\2.7.15-SNAPSHOT\spring-boot-starter-json-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.13.5\jackson-databind-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.13.5\jackson-annotations-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.13.5\jackson-core-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.13.5\jackson-datatype-jdk8-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.13.5\jackson-datatype-jsr310-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.13.5\jackson-module-parameter-names-2.13.5.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat\2.7.15-SNAPSHOT\spring-boot-starter-tomcat-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.78\tomcat-embed-core-9.0.78.jar;C:\Users\jinsung\.m2\repository\org\apache\tomcat\embed\tomcat-embed-el\9.0.78\tomcat-embed-el-9.0.78.jar;C:\Users\jinsung\.m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.78\tomcat-embed-websocket-9.0.78.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-web\5.3.29\spring-web-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-beans\5.3.29\spring-beans-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-webmvc\5.3.29\spring-webmvc-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-aop\5.3.29\spring-aop-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-expression\5.3.29\spring-expression-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-devtools\2.7.15-SNAPSHOT\spring-boot-devtools-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot\2.7.15-SNAPSHOT\spring-boot-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\2.7.15-SNAPSHOT\spring-boot-autoconfigure-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\projectlombok\lombok\1.18.28\lombok-1.18.28.jar;C:\Users\jinsung\.m2\repository\org\slf4j\slf4j-api\1.7.36\slf4j-api-1.7.36.jar;C:\Users\jinsung\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\2.3.3\jakarta.xml.bind-api-2.3.3.jar;C:\Users\jinsung\.m2\repository\jakarta\activation\jakarta.activation-api\1.2.2\jakarta.activation-api-1.2.2.jar;C:\Users\jinsung\.m2\repository\net\bytebuddy\byte-buddy\1.12.23\byte-buddy-1.12.23.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-core\5.3.29\spring-core-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-jcl\5.3.29\spring-jcl-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-thymeleaf\2.7.15-SNAPSHOT\spring-boot-starter-thymeleaf-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\thymeleaf\thymeleaf-spring5\3.0.15.RELEASE\thymeleaf-spring5-3.0.15.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\thymeleaf\thymeleaf\3.0.15.RELEASE\thymeleaf-3.0.15.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\attoparser\attoparser\2.0.5.RELEASE\attoparser-2.0.5.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\unbescape\unbescape\1.1.6.RELEASE\unbescape-1.1.6.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\thymeleaf\extras\thymeleaf-extras-java8time\3.0.4.RELEASE\thymeleaf-extras-java8time-3.0.4.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\springframework\kafka\spring-kafka\2.8.11\spring-kafka-2.8.11.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-context\5.3.29\spring-context-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-messaging\5.3.29\spring-messaging-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-tx\5.3.29\spring-tx-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\retry\spring-retry\1.3.4\spring-retry-1.3.4.jar;C:\Users\jinsung\.m2\repository\org\apache\kafka\kafka-clients\3.1.2\kafka-clients-3.1.2.jar;C:\Users\jinsung\.m2\repository\com\github\luben\zstd-jni\1.5.0-4\zstd-jni-1.5.0-4.jar;C:\Users\jinsung\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\jinsung\.m2\repository\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\Users\jinsung\.m2\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-data-jpa\2.7.15-SNAPSHOT\spring-boot-starter-data-jpa-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-aop\2.7.15-SNAPSHOT\spring-boot-starter-aop-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\aspectj\aspectjweaver\1.9.7\aspectjweaver-1.9.7.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\2.7.15-SNAPSHOT\spring-boot-starter-jdbc-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\com\zaxxer\HikariCP\4.0.3\HikariCP-4.0.3.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-jdbc\5.3.29\spring-jdbc-5.3.29.jar;C:\Users\jinsung\.m2\repository\jakarta\transaction\jakarta.transaction-api\1.3.3\jakarta.transaction-api-1.3.3.jar;C:\Users\jinsung\.m2\repository\jakarta\persistence\jakarta.persistence-api\2.2.3\jakarta.persistence-api-2.2.3.jar;C:\Users\jinsung\.m2\repository\org\hibernate\hibernate-core\5.6.15.Final\hibernate-core-5.6.15.Final.jar;C:\Users\jinsung\.m2\repository\org\jboss\logging\jboss-logging\3.4.3.Final\jboss-logging-3.4.3.Final.jar;C:\Users\jinsung\.m2\repository\antlr\antlr\2.7.7\antlr-2.7.7.jar;C:\Users\jinsung\.m2\repository\org\jboss\jandex\2.4.2.Final\jandex-2.4.2.Final.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\jinsung\.m2\repository\org\hibernate\common\hibernate-commons-annotations\5.1.2.Final\hibernate-commons-annotations-5.1.2.Final.jar;C:\Users\jinsung\.m2\repository\org\glassfish\jaxb\jaxb-runtime\2.3.8\jaxb-runtime-2.3.8.jar;C:\Users\jinsung\.m2\repository\org\glassfish\jaxb\txw2\2.3.8\txw2-2.3.8.jar;C:\Users\jinsung\.m2\repository\com\sun\istack\istack-commons-runtime\3.0.12\istack-commons-runtime-3.0.12.jar;C:\Users\jinsung\.m2\repository\com\sun\activation\jakarta.activation\1.2.2\jakarta.activation-1.2.2.jar;C:\Users\jinsung\.m2\repository\org\springframework\data\spring-data-jpa\2.7.15-SNAPSHOT\spring-data-jpa-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\data\spring-data-commons\2.7.15-SNAPSHOT\spring-data-commons-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-orm\5.3.29\spring-orm-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-aspects\5.3.29\spring-aspects-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-websocket\2.7.15-SNAPSHOT\spring-boot-starter-websocket-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-websocket\5.3.29\spring-websocket-5.3.29.jar;C:\Users\jinsung\.m2\repository\mysql\mysql-connector-java\8.0.27\mysql-connector-java-8.0.27.jar;C:\Users\jinsung\.m2\repository\com\google\protobuf\protobuf-java\3.11.4\protobuf-java-3.11.4.jar, com.sun.management.jmxremote.authenticate=false, java.vm.vendor=Eclipse Adoptium, sun.arch.data.model=64, user.variant=, java.vendor.url=https://adoptium.net/, catalina.useNaming=false, user.timezone=Asia/Seoul, jakarta.persistence.sharedCache.mode=UNSPECIFIED, java.vm.specification.version=17, os.name=Windows 10, javax.persistence.validation.mode=AUTO, jakarta.persistence.nonJtaDataSource=HikariDataSource (HikariPool-6), sun.java.launcher=SUN_STANDARD, user.country=KR, sun.boot.library.path=C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin, com.sun.management.jmxremote.ssl=false, sun.java.command=com.jinseong.demo.Application --spring.output.ansi.enabled=always, spring.application.admin.enabled=true, javax.persistence.nonJtaDataSource=HikariDataSource (HikariPool-6), hibernate.transaction.jta.platform=org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform@636555e5, com.sun.management.jmxremote=, javax.persistence.sharedCache.mode=UNSPECIFIED, jdk.debug=release, sun.cpu.endian=little, spring.boot.project.name=demo, user.home=C:\Users\jinsung, user.language=ko, java.specification.vendor=Oracle Corporation, java.version.date=2023-01-17, java.home=C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre, file.separator=\, java.vm.compressedOopsMode=Zero based, line.separator=
, hibernate.persistenceUnitName=default, java.vm.specification.vendor=Oracle Corporation, java.specification.name=Java Platform API Specification, FILE_LOG_CHARSET=UTF-8, hibernate.transaction.coordinator_class=class org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorBuilderImpl, java.awt.headless=true, jakarta.persistence.validation.mode=AUTO, user.script=, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, java.runtime.version=17.0.6+10, user.name=jinsung, spring.jmx.enabled=true, path.separator=;, management.endpoints.jmx.exposure.include=*, os.version=10.0, java.runtime.name=OpenJDK Runtime Environment, file.encoding=UTF-8, hibernate.ejb.persistenceUnitName=default, spring.beaninfo.ignore=true, java.vm.name=OpenJDK 64-Bit Server VM, java.vendor.version=Temurin-17.0.6+10, java.vendor.url.bug=https://github.com/adoptium/adoptium-support/issues, java.io.tmpdir=C:\Users\jinsung\AppData\Local\Temp\, com.zaxxer.hikari.pool_number=1, catalina.home=C:\Users\jinsung\AppData\Local\Temp\tomcat.8080.8212133563761113161, com.sun.management.jmxremote.port=50267, java.version=17.0.6, hibernate.physical_naming_strategy=org.hibernate.boot.model.naming.CamelCaseToUnderscoresNamingStrategy, user.dir=C:\Users\jinsung\Documents\GitHub\RMS\demo, os.arch=amd64, java.vm.specification.name=Java Virtual Machine Specification, PID=22504, sun.os.patch.level=, CONSOLE_LOG_CHARSET=UTF-8, catalina.base=C:\Users\jinsung\AppData\Local\Temp\tomcat.8080.8212133563761113161, hibernate.boot.CfgXmlAccessService.key=org.hibernate.boot.registry.StandardServiceRegistryBuilder$1@1a4c6f14, native.encoding=MS949, java.library.path=C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;., java.vendor=Eclipse Adoptium, java.vm.info=mixed mode, emulated-client, java.vm.version=17.0.6+10, hibernate.bytecode.use_reflection_optimizer=false, java.rmi.server.randomIDs=true, java.rmi.server.hostname=localhost, sun.io.unicode.encoding=UnicodeLittle, hibernate.archive.scanner=org.hibernate.boot.archive.scan.internal.DisabledScanner, hibernate.connection.datasource=HikariDataSource (HikariPool-6), java.class.version=61.0}
""[01:29:05.836][DEBUG][org.hibernate.secure.spi.JaccIntegrator.doIntegration:line84] - Skipping JACC integration as it was not enabled
""[01:29:05.837][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line316] - Instantiated session factory
""[01:29:05.837][DEBUG][org.hibernate.type.spi.TypeConfiguration$Scope.scope:line154] - Scoping TypeConfiguration [org.hibernate.type.spi.TypeConfiguration@1f861a45] to SessionFactoryImpl [org.hibernate.internal.SessionFactoryImpl@7c2c5b5a]
""[01:29:05.837][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line60] - Not known whether passed class name [com.jinseong.demo.entity.Reservation] is safe
""[01:29:05.837][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line62] - No temp ClassLoader provided; using live ClassLoader for loading potentially unsafe class : com.jinseong.demo.entity.Reservation
""[01:29:05.844][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4031] - Static SQL for entity: com.jinseong.demo.entity.Reservation
""[01:29:05.845][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4036] -  Version select: select reservation_id from reservation where reservation_id =?
""[01:29:05.845][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4039] -  Snapshot select: select reservatio_.reservation_id, reservatio_.count as count2_0_, reservatio_.date as date3_0_, reservatio_.name as name4_0_, reservatio_.number as number5_0_, reservatio_.time as time6_0_ from reservation reservatio_ where reservatio_.reservation_id=?
""[01:29:05.845][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.debugf:line394] -  Insert 0: insert into reservation (count, date, name, number, time, reservation_id) values (?, ?, ?, ?, ?, ?)
""[01:29:05.845][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.debugf:line394] -  Update 0: update reservation set count=?, date=?, name=?, number=?, time=? where reservation_id=?
""[01:29:05.845][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.debugf:line394] -  Delete 0: delete from reservation where reservation_id=?
""[01:29:05.845][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4047] -  Identity insert: insert into reservation (count, date, name, number, time) values (?, ?, ?, ?, ?)
""[01:29:05.845][DEBUG][org.hibernate.loader.plan.build.internal.spaces.QuerySpacesImpl.registerQuerySpace:line174] - Adding QuerySpace : uid = <gen:0> -> org.hibernate.loader.plan.build.internal.spaces.EntityQuerySpaceImpl@15ad7642]
""[01:29:05.845][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : count
""[01:29:05.845][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : date
""[01:29:05.845][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : name
""[01:29:05.845][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : number
""[01:29:05.845][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : time
""[01:29:05.846][DEBUG][org.hibernate.loader.plan.build.internal.FetchStyleLoadPlanBuildingAssociationVisitationStrategy.buildLoadPlan:line160] - Building LoadPlan...
""[01:29:05.846][DEBUG][org.hibernate.loader.plan.exec.internal.LoadQueryJoinAndFetchProcessor.processQuerySpaceJoins:line102] - processing queryspace <gen:0>
""[01:29:05.846][DEBUG][org.hibernate.loader.plan.build.spi.LoadPlanTreePrinter.logTree:line55] - LoadPlan(entity=com.jinseong.demo.entity.Reservation)
    - Returns
       - EntityReturnImpl(entity=com.jinseong.demo.entity.Reservation, querySpaceUid=<gen:0>, path=com.jinseong.demo.entity.Reservation)
    - QuerySpaces
       - EntityQuerySpaceImpl(uid=<gen:0>, entity=com.jinseong.demo.entity.Reservation)
          - SQL table alias mapping - reservatio0_
          - alias suffix - 0_
          - suffixed key columns - {reservat1_0_0_}

""[01:29:05.846][DEBUG][org.hibernate.loader.entity.plan.EntityLoader.<init>:line129] - Static select for entity com.jinseong.demo.entity.Reservation [NONE]: select reservatio0_.reservation_id as reservat1_0_0_, reservatio0_.count as count2_0_0_, reservatio0_.date as date3_0_0_, reservatio0_.name as name4_0_0_, reservatio0_.number as number5_0_0_, reservatio0_.time as time6_0_0_ from reservation reservatio0_ where reservatio0_.reservation_id=?
""[01:29:05.847][DEBUG][org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.interpret:line556] - No schema actions specified
""[01:29:05.847][DEBUG][org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process:line69] - No actions specified; doing nothing
""[01:29:05.847][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:29:05.847][DEBUG][org.hibernate.service.internal.SessionFactoryServiceRegistryImpl.getService:line92] - EventListenerRegistry access via ServiceRegistry is deprecated.  Use `sessionFactory.getEventEngine().getListenerRegistry()` instead
""[01:29:05.847][DEBUG][org.hibernate.hql.internal.QueryTranslatorFactoryInitiator.initiateService:line45] - QueryTranslatorFactory: org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory@35e07c5b
""[01:29:05.847][DEBUG][org.hibernate.query.spi.NamedQueryRepository.checkNamedQueries:line171] - Checking 0 named HQL queries
""[01:29:05.847][DEBUG][org.hibernate.query.spi.NamedQueryRepository.checkNamedQueries:line185] - Checking 0 named SQL queries
""[01:29:05.848][DEBUG][org.hibernate.internal.SessionFactoryRegistry.addSessionFactory:line73] - Registering SessionFactory: f3333b0b-c46f-438c-b684-84b04f840245 (<unnamed>)
""[01:29:05.848][DEBUG][org.hibernate.internal.SessionFactoryRegistry.addSessionFactory:line80] - Not binding SessionFactory to JNDI, no JNDI name configured
""[01:29:05.848][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:29:05.856][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'application'
""[01:29:05.857][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webConfig'
""[01:29:05.857][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webSocketConfig'
""[01:29:05.858][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'socketHandler'
""[01:29:05.859][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mainController'
""[01:29:05.860][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaConsumerService'
""[01:29:05.860][DEBUG][org.springframework.kafka.annotation.KafkaListenerAnnotationBeanPostProcessor.debug:line313] - No retry topic configuration found for topics [reservation-topic]
""[01:29:05.861][DEBUG][org.springframework.kafka.annotation.KafkaListenerAnnotationBeanPostProcessor.debug:line313] - 1 @KafkaListener methods processed on bean 'kafkaConsumerService': {public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException=[@org.springframework.kafka.annotation.KafkaListener(topicPattern="", containerFactory="", beanRef="__listener", contentTypeConverter="", topics={"reservation-topic"}, groupId="my-consumer-group", batch="", clientIdPrefix="", topicPartitions={}, splitIterables=true, concurrency="", autoStartup="", filter="", containerGroup="", idIsGroup=true, errorHandler="", id="", properties={}, info="")]}
""[01:29:05.861][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.web.servlet.config.annotation.DelegatingWebMvcConfiguration'
""[01:29:05.861][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'openEntityManagerInViewInterceptorConfigurer'
""[01:29:05.861][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration'
""[01:29:05.862][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration' via constructor to bean named 'spring.jpa-org.springframework.boot.autoconfigure.orm.jpa.JpaProperties'
""[01:29:05.862][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'openEntityManagerInViewInterceptor'
""[01:29:05.862][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:29:05.863][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'openEntityManagerInViewInterceptorConfigurer' via factory method to bean named 'openEntityManagerInViewInterceptor'
""[01:29:05.864][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.web.config.SpringDataWebConfiguration'
""[01:29:05.864][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.data.web.config.SpringDataWebConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@370192a6'
""[01:29:05.866][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'requestMappingHandlerMapping'
""[01:29:05.866][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcContentNegotiationManager'
""[01:29:05.866][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcConversionService'
""[01:29:05.868][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcResourceUrlProvider'
""[01:29:05.868][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcContentNegotiationManager'
""[01:29:05.868][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:29:05.868][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:29:05.869][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.detectHandlerMethods:line295] - 
	c.j.d.c.MainController:
	{GET [/]}: index(Model)
""[01:29:05.870][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.detectHandlerMethods:line295] - 
	o.s.b.a.w.s.e.BasicErrorController:
	{ [/error]}: error(HttpServletRequest)
	{ [/error], produces [text/html]}: errorHtml(HttpServletRequest,HttpServletResponse)
""[01:29:05.871][DEBUG][org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping.handlerMethodsInitialized:line367] - 3 mappings in 'requestMappingHandlerMapping'
""[01:29:05.873][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcPatternParser'
""[01:29:05.873][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcUrlPathHelper'
""[01:29:05.873][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcPathMatcher'
""[01:29:05.874][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'viewControllerHandlerMapping'
""[01:29:05.874][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'viewControllerHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:29:05.874][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'viewControllerHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:29:05.874][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'beanNameHandlerMapping'
""[01:29:05.874][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'beanNameHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:29:05.874][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'beanNameHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:29:05.875][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.detectHandlers:line86] - 'beanNameHandlerMapping' {}
""[01:29:05.876][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'routerFunctionMapping'
""[01:29:05.877][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'routerFunctionMapping' via factory method to bean named 'mvcConversionService'
""[01:29:05.877][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'routerFunctionMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:29:05.882][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'resourceHandlerMapping'
""[01:29:05.882][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcContentNegotiationManager'
""[01:29:05.882][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:29:05.882][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:29:05.883][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'defaultServletHandlerMapping'
""[01:29:05.883][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'requestMappingHandlerAdapter'
""[01:29:05.883][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcValidator'
""[01:29:05.884][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcContentNegotiationManager'
""[01:29:05.884][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcConversionService'
""[01:29:05.884][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcValidator'
""[01:29:05.885][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'sortResolver'
""[01:29:05.886][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'sortCustomizer'
""[01:29:05.886][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration'
""[01:29:05.886][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.data.web-org.springframework.boot.autoconfigure.data.web.SpringDataWebProperties'
""[01:29:05.887][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration' via constructor to bean named 'spring.data.web-org.springframework.boot.autoconfigure.data.web.SpringDataWebProperties'
""[01:29:05.888][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'pageableResolver'
""[01:29:05.888][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'pageableCustomizer'
""[01:29:05.890][DEBUG][org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.initControllerAdviceCache:line625] - ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
""[01:29:05.891][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'handlerFunctionAdapter'
""[01:29:05.892][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcUriComponentsContributor'
""[01:29:05.892][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mvcUriComponentsContributor' via factory method to bean named 'mvcConversionService'
""[01:29:05.892][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mvcUriComponentsContributor' via factory method to bean named 'requestMappingHandlerAdapter'
""[01:29:05.893][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'httpRequestHandlerAdapter'
""[01:29:05.893][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'simpleControllerHandlerAdapter'
""[01:29:05.893][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'handlerExceptionResolver'
""[01:29:05.893][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'handlerExceptionResolver' via factory method to bean named 'mvcContentNegotiationManager'
""[01:29:05.894][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-6 - Pool stats (total=1, active=0, idle=1, waiting=0)
""[01:29:05.896][DEBUG][org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver.initExceptionHandlerAdviceCache:line307] - ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
""[01:29:05.896][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcViewResolver'
""[01:29:05.897][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mvcViewResolver' via factory method to bean named 'mvcContentNegotiationManager'
""[01:29:05.897][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'localeResolver'
""[01:29:05.897][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'themeResolver'
""[01:29:05.898][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'flashMapManager'
""[01:29:05.898][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'viewNameTranslator'
""[01:29:05.898][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'viewResolver'
""[01:29:05.902][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-6 - Added connection com.mysql.cj.jdbc.ConnectionImpl@bb7f70b
""[01:29:05.902][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.web.socket.config.annotation.DelegatingWebSocketConfiguration'
""[01:29:05.903][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webSocketHandlerMapping'
""[01:29:05.903][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'defaultSockJsTaskScheduler'
""[01:29:05.904][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'webSocketHandlerMapping' via factory method to bean named 'defaultSockJsTaskScheduler'
""[01:29:05.904][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.logMappings:line177] - 'webSocketHandlerMapping' {/ws=org.springframework.web.socket.server.support.WebSocketHttpRequestHandler@4b35082f}
""[01:29:05.906][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration'
""[01:29:05.906][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration'
""[01:29:05.907][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.EnableConfigurationPropertiesRegistrar.methodValidationExcludeFilter'
""[01:29:05.907][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration'
""[01:29:05.907][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration'
""[01:29:05.908][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'taskExecutorBuilder'
""[01:29:05.908][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
""[01:29:05.909][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'taskExecutorBuilder' via factory method to bean named 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
""[01:29:05.909][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration'
""[01:29:05.909][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'error'
""[01:29:05.910][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'beanNameViewResolver'
""[01:29:05.910][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration'
""[01:29:05.910][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
""[01:29:05.911][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-6 - Added connection com.mysql.cj.jdbc.ConnectionImpl@4a8afd30
""[01:29:05.912][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@370192a6'
""[01:29:05.913][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration' via constructor to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
""[01:29:05.913][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'conventionErrorViewResolver'
""[01:29:05.913][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'errorAttributes'
""[01:29:05.913][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'basicErrorController'
""[01:29:05.914][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'basicErrorController' via factory method to bean named 'errorAttributes'
""[01:29:05.915][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration'
""[01:29:05.915][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties'
""[01:29:05.916][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' via constructor to bean named 'spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties'
""[01:29:05.916][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mbeanExporter'
""[01:29:05.916][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'objectNamingStrategy'
""[01:29:05.917][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'objectNamingStrategy'
""[01:29:05.917][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@4d5791ee'
""[01:29:05.917][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mbeanServer'
""[01:29:05.918][DEBUG][org.springframework.jmx.support.JmxUtils.locateMBeanServer:line127] - Found MBeanServer: com.sun.jmx.mbeanserver.JmxMBeanServer@1f554b06
""[01:29:05.919][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-6 - Added connection com.mysql.cj.jdbc.ConnectionImpl@7b0ad257
""[01:29:05.920][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration'
""[01:29:05.920][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'springApplicationAdminRegistrar'
""[01:29:05.921][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'springApplicationAdminRegistrar' via factory method to bean named 'environment'
""[01:29:05.922][DEBUG][org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin.afterPropertiesSet:line131] - Application Admin MBean registered with name 'org.springframework.boot:type=Admin,name=SpringApplication'
""[01:29:05.923][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$AspectJAutoProxyingConfiguration$CglibAutoProxyConfiguration'
""[01:29:05.923][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$AspectJAutoProxyingConfiguration'
""[01:29:05.923][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration'
""[01:29:05.923][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration'
""[01:29:05.924][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'applicationAvailability'
""[01:29:05.924][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$Jackson2ObjectMapperBuilderCustomizerConfiguration'
""[01:29:05.924][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'standardJacksonObjectMapperBuilderCustomizer'
""[01:29:05.924][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
""[01:29:05.926][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'standardJacksonObjectMapperBuilderCustomizer' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@370192a6'
""[01:29:05.926][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'standardJacksonObjectMapperBuilderCustomizer' via factory method to bean named 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
""[01:29:05.926][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperBuilderConfiguration'
""[01:29:05.926][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$ParameterNamesModuleConfiguration'
""[01:29:05.927][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'parameterNamesModule'
""[01:29:05.927][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperConfiguration'
""[01:29:05.927][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jacksonObjectMapper'
""[01:29:05.928][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-6 - Added connection com.mysql.cj.jdbc.ConnectionImpl@2aa5027f
""[01:29:05.928][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@370192a6'
""[01:29:05.929][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'standardJacksonObjectMapperBuilderCustomizer'
""[01:29:05.929][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jsonComponentModule'
""[01:29:05.929][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration'
""[01:29:05.931][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jsonMixinModule'
""[01:29:05.931][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jsonMixinModule' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@370192a6'
""[01:29:05.937][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-6 - Added connection com.mysql.cj.jdbc.ConnectionImpl@433dd201
""[01:29:05.939][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jacksonGeoModule'
""[01:29:05.939][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.web.config.SpringDataJacksonConfiguration'
""[01:29:05.940][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jacksonObjectMapper' via factory method to bean named 'jacksonObjectMapperBuilder'
""[01:29:05.945][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration'
""[01:29:05.945][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceJmxConfiguration$Hikari'
""[01:29:05.945][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-6 - Added connection com.mysql.cj.jdbc.ConnectionImpl@2eeb5c73
""[01:29:05.946][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jdbc.DataSourceJmxConfiguration$Hikari' via constructor to bean named 'dataSource'
""[01:29:05.946][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceJmxConfiguration'
""[01:29:05.946][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration$PooledDataSourceConfiguration'
""[01:29:05.946][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.metadata.DataSourcePoolMetadataProvidersConfiguration'
""[01:29:05.946][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration'
""[01:29:05.947][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionManager'
""[01:29:05.947][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'platformTransactionManagerCustomizers'
""[01:29:05.947][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration'
""[01:29:05.948][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.transaction-org.springframework.boot.autoconfigure.transaction.TransactionProperties'
""[01:29:05.949][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration'
""[01:29:05.950][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration'
""[01:29:05.950][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration'
""[01:29:05.950][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'lifecycleProcessor'
""[01:29:05.950][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties'
""[01:29:05.951][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'lifecycleProcessor' via factory method to bean named 'spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties'
""[01:29:05.951][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration'
""[01:29:05.952][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration'
""[01:29:05.952][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.jpa.util.JpaMetamodelCacheCleanup'
""[01:29:05.952][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.jpa.repository.support.JpaEvaluationContextExtension'
""[01:29:05.952][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'reservationRepository'
""[01:29:05.954][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-6 - Added connection com.mysql.cj.jdbc.ConnectionImpl@2ca30ce9
""[01:29:05.963][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-6 - Added connection com.mysql.cj.jdbc.ConnectionImpl@c7f534a
""[01:29:05.970][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-6 - Added connection com.mysql.cj.jdbc.ConnectionImpl@226ee066
""[01:29:05.970][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-6 - After adding stats (total=10, active=0, idle=10, waiting=0)
""[01:29:05.975][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jpaMappingContext'
""[01:29:05.975][DEBUG][org.springframework.data.jpa.repository.config.JpaMetamodelMappingContextFactoryBean.createInstance:line77] - Initializing JpaMetamodelMappingContext
""[01:29:05.975][DEBUG][org.springframework.data.jpa.repository.config.JpaMetamodelMappingContextFactoryBean.createInstance:line84] - Finished initializing JpaMetamodelMappingContext!
""[01:29:05.978][DEBUG][org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke:line306] - Creating new EntityManager for shared EntityManager invocation
""[01:29:05.978][DEBUG][org.hibernate.stat.internal.StatisticsInitiator.initiateServiceInternal:line101] - Statistics initialized [enabled=false]
""[01:29:05.980][DEBUG][org.springframework.beans.CachedIntrospectionResults.forClass:line190] - Not strongly caching class [com.jinseong.demo.entity.Reservation] because it is not cache-safe
""[01:29:05.982][DEBUG][org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository:line280] - Initializing repository instance for com.jinseong.demo.repository.ReservationRepository
""[01:29:05.985][DEBUG][org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke:line306] - Creating new EntityManager for shared EntityManager invocation
""[01:29:05.997][DEBUG][org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository:line377] - Finished creation of repository instance for com.jinseong.demo.repository.ReservationRepository.
""[01:29:05.998][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration$StringHttpMessageConverterConfiguration'
""[01:29:05.999][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'stringHttpMessageConverter'
""[01:29:05.999][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'stringHttpMessageConverter' via factory method to bean named 'environment'
""[01:29:06.000][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.JacksonHttpMessageConvertersConfiguration$MappingJackson2HttpMessageConverterConfiguration'
""[01:29:06.000][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mappingJackson2HttpMessageConverter'
""[01:29:06.000][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mappingJackson2HttpMessageConverter' via factory method to bean named 'jacksonObjectMapper'
""[01:29:06.001][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.JacksonHttpMessageConvertersConfiguration'
""[01:29:06.001][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration'
""[01:29:06.001][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'messageConverters'
""[01:29:06.004][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.web.config.ProjectingArgumentResolverRegistrar'
""[01:29:06.004][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration'
""[01:29:06.005][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
""[01:29:06.005][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration' via constructor to bean named 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
""[01:29:06.005][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.JdbcTemplateConfiguration'
""[01:29:06.006][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jdbcTemplate'
""[01:29:06.006][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jdbc-org.springframework.boot.autoconfigure.jdbc.JdbcProperties'
""[01:29:06.006][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jdbcTemplate' via factory method to bean named 'dataSource'
""[01:29:06.006][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jdbcTemplate' via factory method to bean named 'spring.jdbc-org.springframework.boot.autoconfigure.jdbc.JdbcProperties'
""[01:29:06.009][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.NamedParameterJdbcTemplateConfiguration'
""[01:29:06.010][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'namedParameterJdbcTemplate'
""[01:29:06.010][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'namedParameterJdbcTemplate' via factory method to bean named 'jdbcTemplate'
""[01:29:06.011][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration'
""[01:29:06.011][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration$EnableKafkaConfiguration'
""[01:29:06.011][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
""[01:29:06.012][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration'
""[01:29:06.012][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
""[01:29:06.016][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
""[01:29:06.017][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaTemplate'
""[01:29:06.017][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration'
""[01:29:06.017][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
""[01:29:06.018][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaProducerFactory'
""[01:29:06.020][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaProducerListener'
""[01:29:06.020][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'kafkaTemplate' via factory method to bean named 'kafkaProducerFactory'
""[01:29:06.020][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'kafkaTemplate' via factory method to bean named 'kafkaProducerListener'
""[01:29:06.023][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaListenerContainerFactoryConfigurer'
""[01:29:06.023][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaListenerContainerFactory'
""[01:29:06.023][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'kafkaListenerContainerFactory' via factory method to bean named 'kafkaListenerContainerFactoryConfigurer'
""[01:29:06.024][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaConsumerFactory'
""[01:29:06.026][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaAdmin'
""[01:29:06.026][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.sql.init.SqlInitializationAutoConfiguration'
""[01:29:06.026][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration'
""[01:29:06.026][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'taskSchedulerBuilder'
""[01:29:06.027][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
""[01:29:06.027][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'taskSchedulerBuilder' via factory method to bean named 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
""[01:29:06.028][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafJava8TimeDialect'
""[01:29:06.028][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'java8TimeDialect'
""[01:29:06.028][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafWebMvcConfiguration$ThymeleafViewResolverConfiguration'
""[01:29:06.028][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'thymeleafViewResolver'
""[01:29:06.029][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:29:06.030][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'templateEngine'
""[01:29:06.030][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.TemplateEngineConfigurations$DefaultTemplateEngineConfiguration'
""[01:29:06.031][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'templateEngine' via factory method to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:29:06.031][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'defaultTemplateResolver'
""[01:29:06.031][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration'
""[01:29:06.031][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration' via constructor to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:29:06.031][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@370192a6'
""[01:29:06.034][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'thymeleafViewResolver' via factory method to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:29:06.034][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'thymeleafViewResolver' via factory method to bean named 'templateEngine'
""[01:29:06.035][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafWebMvcConfiguration'
""[01:29:06.035][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration'
""[01:29:06.035][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration$JdbcTransactionManagerConfiguration'
""[01:29:06.036][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration'
""[01:29:06.036][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration$CglibAutoProxyConfiguration'
""[01:29:06.036][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration'
""[01:29:06.036][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$TransactionTemplateConfiguration'
""[01:29:06.036][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionTemplate'
""[01:29:06.036][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'transactionTemplate' via factory method to bean named 'transactionManager'
""[01:29:06.037][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration'
""[01:29:06.037][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration'
""[01:29:06.037][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'multipartResolver'
""[01:29:06.038][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration'
""[01:29:06.038][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartConfiguration'
""[01:29:06.038][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.devtools-org.springframework.boot.devtools.autoconfigure.DevToolsProperties'
""[01:29:06.039][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartConfiguration' via constructor to bean named 'spring.devtools-org.springframework.boot.devtools.autoconfigure.DevToolsProperties'
""[01:29:06.039][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'restartingClassPathChangedEventListener'
""[01:29:06.039][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'fileSystemWatcherFactory'
""[01:29:06.040][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'restartingClassPathChangedEventListener' via factory method to bean named 'fileSystemWatcherFactory'
""[01:29:06.040][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'classPathFileSystemWatcher'
""[01:29:06.040][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'classPathRestartStrategy'
""[01:29:06.040][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'classPathFileSystemWatcher' via factory method to bean named 'fileSystemWatcherFactory'
""[01:29:06.040][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'classPathFileSystemWatcher' via factory method to bean named 'classPathRestartStrategy'
""[01:29:06.041][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'conditionEvaluationDeltaLoggingListener'
""[01:29:06.041][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$LiveReloadConfiguration'
""[01:29:06.041][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'optionalLiveReloadServer'
""[01:29:06.042][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'optionalLiveReloadServer' via factory method to bean named 'liveReloadServer'
""[01:29:06.042][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:29:06.042][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'liveReloadServerEventListener'
""[01:29:06.042][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'liveReloadServerEventListener' via factory method to bean named 'optionalLiveReloadServer'
""[01:29:06.042][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration'
""[01:29:06.049][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.afterSingletonsInstantiated:line434] - Registering beans for JMX exposure on startup
""[01:29:06.049][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.registerBeans:line541] - Autodetecting user-defined JMX MBeans
""[01:29:06.049][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.autodetect:line896] - Bean with name 'dataSource' has been autodetected for JMX exposure
""[01:29:06.051][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.registerBeanInstance:line669] - Located MBean 'dataSource': registering with JMX server as MBean [com.zaxxer.hikari:name=dataSource,type=HikariDataSource]
""[01:29:06.063][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase -2147483647
""[01:29:06.064][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'springBootLoggingLifecycle'
""[01:29:06.064][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase 2147483547
""[01:29:06.064][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:29:06.065][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer.<init>:line695] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Initializing the Kafka consumer
""[01:29:06.068][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:29:06.068][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:29:06.069][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:29:06.069][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692289746068
""[01:29:06.069][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer.<init>:line815] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Kafka consumer initialized
""[01:29:06.069][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:29:06.069][DEBUG][org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler.initialize:line184] - Initializing ExecutorService
""[01:29:06.070][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
""[01:29:06.070][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase 2147483646
""[01:29:06.070][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:06.070][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendFindCoordinatorRequest:line821] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FindCoordinator request to broker localhost:9092 (id: -1 rack: null)
""[01:29:06.070][DEBUG][org.apache.kafka.clients.ClientUtils.resolve:line113] - Resolved host localhost as 127.0.0.1
""[01:29:06.070][DEBUG][org.apache.kafka.clients.NetworkClient.initiateConnect:line989] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Initiating connection to node localhost:9092 (id: -1 rack: null) using address localhost/127.0.0.1
""[01:29:06.071][DEBUG][org.apache.kafka.common.network.Selector.pollSelectionKeys:line531] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
""[01:29:06.071][DEBUG][org.apache.kafka.clients.NetworkClient.handleConnections:line951] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Completed connection to node -1. Fetching API versions.
""[01:29:06.072][DEBUG][org.apache.kafka.clients.NetworkClient.handleInitiateApiVersionRequests:line965] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Initiating API versions fetch from node -1.
""[01:29:06.072][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-6, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.2')
""[01:29:06.074][DEBUG][org.apache.tomcat.util.threads.LimitLatch.log:line173] - Counting up[http-nio-8080-Acceptor] latch=0
""[01:29:06.074][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:29:06.074][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'webServerStartStop'
""[01:29:06.074][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase 2147483647
""[01:29:06.074][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'webSocketHandlerMapping'
""[01:29:06.074][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'webServerGracefulShutdown'
""[01:29:06.075][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-6, correlationId=1): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=12), ApiVersion(apiKey=2, minVersion=0, maxVersion=6), ApiVersion(apiKey=3, minVersion=0, maxVersion=11), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=7), ApiVersion(apiKey=10, minVersion=0, maxVersion=3), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
""[01:29:06.075][DEBUG][org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse:line921] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node -1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 6 [usable: 6], Metadata(3): 0 to 11 [usable: 11], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
""[01:29:06.075][DEBUG][org.apache.kafka.clients.NetworkClient.maybeUpdate:line1143] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='reservation-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:9092 (id: -1 rack: null)
""[01:29:06.075][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=11, clientId=consumer-my-consumer-group-6, correlationId=2) and timeout 30000 to node -1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='reservation-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
""[01:29:06.075][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-my-consumer-group-6, correlationId=0) and timeout 30000 to node -1: FindCoordinatorRequestData(key='my-consumer-group', keyType=0, coordinatorKeys=[])
""[01:29:06.077][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=11, clientId=consumer-my-consumer-group-6, correlationId=2): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=1001, host='127.0.0.1', port=9092, rack=null)], clusterId='TgEACWKoRbSzp0Inn-GuTg', controllerId=1001, topics=[MetadataResponseTopic(errorCode=0, name='reservation-topic', topicId=8aoMqokpSXGOqjBL2y8aPw, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=1001, leaderEpoch=0, replicaNodes=[1001], isrNodes=[1001], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
""[01:29:06.078][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:29:06.078][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:29:06.078][DEBUG][org.apache.kafka.clients.Metadata.update:line291] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='TgEACWKoRbSzp0Inn-GuTg', nodes={1001=127.0.0.1:9092 (id: 1001 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=reservation-topic-0, leader=Optional[1001], leaderEpoch=Optional[0], replicas=1001, isr=1001, offlineReplicas=)], controller=127.0.0.1:9092 (id: 1001 rack: null)}
""[01:29:06.079][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FIND_COORDINATOR response from node -1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-my-consumer-group-6, correlationId=0): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=1001, host='127.0.0.1', port=9092, coordinators=[])
""[01:29:06.079][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line834] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FindCoordinator response ClientResponse(receivedTimeMs=1692289746079, latencyMs=9, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-my-consumer-group-6, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=1001, host='127.0.0.1', port=9092, coordinators=[]))
""[01:29:06.079][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:06.079][DEBUG][org.apache.kafka.clients.ClientUtils.resolve:line113] - Resolved host 127.0.0.1 as 127.0.0.1
""[01:29:06.079][DEBUG][org.apache.kafka.clients.NetworkClient.initiateConnect:line989] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Initiating connection to node 127.0.0.1:9092 (id: 2147482646 rack: null) using address /127.0.0.1
""[01:29:06.079][DEBUG][org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener.logAutoConfigurationReport:line126] - 


============================
CONDITIONS EVALUATION REPORT
============================


Positive matches:
-----------------

   AopAutoConfiguration matched:
      - @ConditionalOnProperty (spring.aop.auto=true) matched (OnPropertyCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration matched:
      - @ConditionalOnClass found required class 'org.aspectj.weaver.Advice' (OnClassCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration.CglibAutoProxyConfiguration matched:
      - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   ApplicationAvailabilityAutoConfiguration#applicationAvailability matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.availability.ApplicationAvailability; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)
      - @ConditionalOnMissingBean (types: io.r2dbc.spi.ConnectionFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceAutoConfiguration.PooledDataSourceConfiguration matched:
      - AnyNestedCondition 1 matched 1 did not; NestedCondition on DataSourceAutoConfiguration.PooledDataSourceCondition.PooledDataSourceAvailable PooledDataSource found supported DataSource; NestedCondition on DataSourceAutoConfiguration.PooledDataSourceCondition.ExplicitType @ConditionalOnProperty (spring.datasource.type) did not find property 'type' (DataSourceAutoConfiguration.PooledDataSourceCondition)
      - @ConditionalOnMissingBean (types: javax.sql.DataSource,javax.sql.XADataSource; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceConfiguration.Hikari matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)
      - @ConditionalOnProperty (spring.datasource.type=com.zaxxer.hikari.HikariDataSource) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: javax.sql.DataSource; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceInitializationConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.jdbc.datasource.init.DatabasePopulator' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource'; @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.sql.init.SqlDataSourceScriptDatabaseInitializer,org.springframework.boot.autoconfigure.sql.init.SqlR2dbcScriptDatabaseInitializer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceJmxConfiguration matched:
      - @ConditionalOnProperty (spring.jmx.enabled=true) matched (OnPropertyCondition)

   DataSourceJmxConfiguration.Hikari matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   DataSourcePoolMetadataProvidersConfiguration.HikariPoolDataSourceMetadataProviderConfiguration matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.jdbc.core.JdbcTemplate', 'org.springframework.transaction.TransactionManager' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration.JdbcTransactionManagerConfiguration matched:
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   DevToolsDataSourceAutoConfiguration matched:
      - Devtools devtools enabled. (OnEnabledDevToolsCondition)
      - DevTools DataSource Condition found auto-configured DataSource (DevToolsDataSourceAutoConfiguration.DevToolsDataSourceCondition)

   DevToolsDataSourceAutoConfiguration.DatabaseShutdownExecutorEntityManagerFactoryDependsOnPostProcessor matched:
      - @ConditionalOnClass found required class 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean' (OnClassCondition)
      - @ConditionalOnBean (types: org.springframework.orm.jpa.AbstractEntityManagerFactoryBean; SearchStrategy: all) found bean '&entityManagerFactory' (OnBeanCondition)

   DispatcherServletAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.servlet.DispatcherServlet' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   DispatcherServletAutoConfiguration.DispatcherServletConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRegistration' (OnClassCondition)
      - Default DispatcherServlet did not find dispatcher servlet beans (DispatcherServletAutoConfiguration.DefaultDispatcherServletCondition)

   DispatcherServletAutoConfiguration.DispatcherServletRegistrationConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRegistration' (OnClassCondition)
      - DispatcherServlet Registration did not find servlet registration bean (DispatcherServletAutoConfiguration.DispatcherServletRegistrationCondition)

   DispatcherServletAutoConfiguration.DispatcherServletRegistrationConfiguration#dispatcherServletRegistration matched:
      - @ConditionalOnBean (names: dispatcherServlet types: org.springframework.web.servlet.DispatcherServlet; SearchStrategy: all) found bean 'dispatcherServlet' (OnBeanCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration matched:
      - @ConditionalOnWebApplication (required) found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnWarDeployment the application is not deployed as a WAR file. (OnWarDeploymentCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.TomcatWebServerFactoryCustomizerConfiguration matched:
      - @ConditionalOnClass found required classes 'org.apache.catalina.startup.Tomcat', 'org.apache.coyote.UpgradeProtocol' (OnClassCondition)

   ErrorMvcAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.servlet.DispatcherServlet' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   ErrorMvcAutoConfiguration#basicErrorController matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.error.ErrorController; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration#errorAttributes matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.error.ErrorAttributes; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.DefaultErrorViewResolverConfiguration#conventionErrorViewResolver matched:
      - @ConditionalOnBean (types: org.springframework.web.servlet.DispatcherServlet; SearchStrategy: all) found bean 'dispatcherServlet'; @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.web.servlet.error.ErrorViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration matched:
      - @ConditionalOnProperty (server.error.whitelabel.enabled) matched (OnPropertyCondition)
      - ErrorTemplate Missing did not find error template view (ErrorMvcAutoConfiguration.ErrorTemplateMissingCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration#beanNameViewResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.servlet.view.BeanNameViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration#defaultErrorView matched:
      - @ConditionalOnMissingBean (names: error; SearchStrategy: all) did not find any beans (OnBeanCondition)

   GenericCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.GenericCacheConfiguration automatic cache type (CacheCondition)

   HibernateJpaAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean', 'javax.persistence.EntityManager', 'org.hibernate.engine.spi.SessionImplementor' (OnClassCondition)

   HibernateJpaConfiguration matched:
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   HttpEncodingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.filter.CharacterEncodingFilter' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (server.servlet.encoding.enabled) matched (OnPropertyCondition)

   HttpEncodingAutoConfiguration#characterEncodingFilter matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.filter.CharacterEncodingFilter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   HttpMessageConvertersAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.HttpMessageConverter' (OnClassCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication did not find reactive web application classes (HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition)

   HttpMessageConvertersAutoConfiguration#messageConverters matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.http.HttpMessageConverters; SearchStrategy: all) did not find any beans (OnBeanCondition)

   HttpMessageConvertersAutoConfiguration.StringHttpMessageConverterConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.StringHttpMessageConverter' (OnClassCondition)

   HttpMessageConvertersAutoConfiguration.StringHttpMessageConverterConfiguration#stringHttpMessageConverter matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.StringHttpMessageConverter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)

   JacksonAutoConfiguration.Jackson2ObjectMapperBuilderCustomizerConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration#jacksonObjectMapperBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.json.Jackson2ObjectMapperBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration#jacksonObjectMapper matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.module.paramnames.ParameterNamesModule' (OnClassCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration#parameterNamesModule matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.module.paramnames.ParameterNamesModule; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2HttpMessageConverterConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)
      - @ConditionalOnProperty (spring.mvc.converters.preferred-json-mapper=jackson) matched (OnPropertyCondition)
      - @ConditionalOnBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) found bean 'jacksonObjectMapper' (OnBeanCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2HttpMessageConverterConfiguration#mappingJackson2HttpMessageConverter matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.json.MappingJackson2HttpMessageConverter ignored: org.springframework.hateoas.server.mvc.TypeConstrainedMappingJackson2HttpMessageConverter,org.springframework.data.rest.webmvc.alps.AlpsJsonHttpMessageConverter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JdbcTemplateAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.core.JdbcTemplate' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   JdbcTemplateConfiguration matched:
      - @ConditionalOnMissingBean (types: org.springframework.jdbc.core.JdbcOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.jmx.export.MBeanExporter' (OnClassCondition)
      - @ConditionalOnProperty (spring.jmx.enabled=true) matched (OnPropertyCondition)

   JmxAutoConfiguration#mbeanExporter matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.MBeanExporter; SearchStrategy: current) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#mbeanServer matched:
      - @ConditionalOnMissingBean (types: javax.management.MBeanServer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#objectNamingStrategy matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.naming.ObjectNamingStrategy; SearchStrategy: current) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#entityManagerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean,javax.persistence.EntityManagerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#entityManagerFactoryBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.orm.jpa.EntityManagerFactoryBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#jpaVendorAdapter matched:
      - @ConditionalOnMissingBean (types: org.springframework.orm.jpa.JpaVendorAdapter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#transactionManager matched:
      - @ConditionalOnMissingBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration.JpaWebConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.jpa.open-in-view=true) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: org.springframework.orm.jpa.support.OpenEntityManagerInViewInterceptor,org.springframework.orm.jpa.support.OpenEntityManagerInViewFilter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaRepositoriesAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.data.jpa.repository.JpaRepository' (OnClassCondition)
      - @ConditionalOnProperty (spring.data.jpa.repositories.enabled=true) matched (OnPropertyCondition)
      - @ConditionalOnBean (types: javax.sql.DataSource; SearchStrategy: all) found bean 'dataSource'; @ConditionalOnMissingBean (types: org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean,org.springframework.data.jpa.repository.config.JpaRepositoryConfigExtension; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JtaAutoConfiguration matched:
      - @ConditionalOnClass found required class 'javax.transaction.Transaction' (OnClassCondition)
      - @ConditionalOnProperty (spring.jta.enabled) matched (OnPropertyCondition)

   KafkaAnnotationDrivenConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.annotation.EnableKafka' (OnClassCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactory matched:
      - @ConditionalOnMissingBean (names: kafkaListenerContainerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactoryConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.kafka.ConcurrentKafkaListenerContainerFactoryConfigurer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration.EnableKafkaConfiguration matched:
      - @ConditionalOnMissingBean (names: org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.core.KafkaTemplate' (OnClassCondition)

   KafkaAutoConfiguration#kafkaAdmin matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaAdmin; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaConsumerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ConsumerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaProducerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ProducerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaProducerListener matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.support.ProducerListener; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaTemplate matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaTemplate; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LifecycleAutoConfiguration#defaultLifecycleProcessor matched:
      - @ConditionalOnMissingBean (names: lifecycleProcessor; SearchStrategy: current) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration matched:
      - Initialized Restarter Condition available and initialized (OnInitializedRestarterCondition)

   LocalDevToolsAutoConfiguration.LiveReloadConfiguration matched:
      - @ConditionalOnProperty (spring.devtools.livereload.enabled) matched (OnPropertyCondition)

   LocalDevToolsAutoConfiguration.LiveReloadConfiguration#liveReloadServer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.devtools.livereload.LiveReloadServer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration matched:
      - @ConditionalOnProperty (spring.devtools.restart.enabled) matched (OnPropertyCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration#classPathFileSystemWatcher matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.devtools.classpath.ClassPathFileSystemWatcher; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration#classPathRestartStrategy matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.devtools.classpath.ClassPathRestartStrategy; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration#conditionEvaluationDeltaLoggingListener matched:
      - @ConditionalOnProperty (spring.devtools.restart.log-condition-evaluation-delta) matched (OnPropertyCondition)

   MultipartAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.multipart.support.StandardServletMultipartResolver', 'javax.servlet.MultipartConfigElement' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.servlet.multipart.enabled) matched (OnPropertyCondition)

   MultipartAutoConfiguration#multipartConfigElement matched:
      - @ConditionalOnMissingBean (types: javax.servlet.MultipartConfigElement,org.springframework.web.multipart.commons.CommonsMultipartResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   MultipartAutoConfiguration#multipartResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.multipart.MultipartResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   NamedParameterJdbcTemplateConfiguration matched:
      - @ConditionalOnSingleCandidate (types: org.springframework.jdbc.core.JdbcTemplate; SearchStrategy: all) found a single bean 'jdbcTemplate'; @ConditionalOnMissingBean (types: org.springframework.jdbc.core.namedparam.NamedParameterJdbcOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   NoOpCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.NoOpCacheConfiguration automatic cache type (CacheCondition)

   PersistenceExceptionTranslationAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor' (OnClassCondition)

   PersistenceExceptionTranslationAutoConfiguration#persistenceExceptionTranslationPostProcessor matched:
      - @ConditionalOnProperty (spring.dao.exceptiontranslation.enabled) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   PropertyPlaceholderAutoConfiguration#propertySourcesPlaceholderConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.context.support.PropertySourcesPlaceholderConfigurer; SearchStrategy: current) did not find any beans (OnBeanCondition)

   RestTemplateAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.client.RestTemplate' (OnClassCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication did not find reactive web application classes (RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition)

   RestTemplateAutoConfiguration#restTemplateBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.client.RestTemplateBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   RestTemplateAutoConfiguration#restTemplateBuilderConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.web.client.RestTemplateBuilderConfigurer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ServletWebServerFactoryAutoConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRequest' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   ServletWebServerFactoryAutoConfiguration#tomcatServletWebServerFactoryCustomizer matched:
      - @ConditionalOnClass found required class 'org.apache.catalina.startup.Tomcat' (OnClassCondition)

   ServletWebServerFactoryConfiguration.EmbeddedTomcat matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.apache.catalina.startup.Tomcat', 'org.apache.coyote.UpgradeProtocol' (OnClassCondition)
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.server.ServletWebServerFactory; SearchStrategy: current) did not find any beans (OnBeanCondition)

   SimpleCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.SimpleCacheConfiguration automatic cache type (CacheCondition)

   SpringApplicationAdminJmxAutoConfiguration matched:
      - @ConditionalOnProperty (spring.application.admin.enabled=true) matched (OnPropertyCondition)

   SpringApplicationAdminJmxAutoConfiguration#springApplicationAdminRegistrar matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.data.web.PageableHandlerMethodArgumentResolver', 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnMissingBean (types: org.springframework.data.web.PageableHandlerMethodArgumentResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration#pageableCustomizer matched:
      - @ConditionalOnMissingBean (types: org.springframework.data.web.config.PageableHandlerMethodArgumentResolverCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration#sortCustomizer matched:
      - @ConditionalOnMissingBean (types: org.springframework.data.web.config.SortHandlerMethodArgumentResolverCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SqlInitializationAutoConfiguration matched:
      - @ConditionalOnProperty (spring.sql.init.enabled) matched (OnPropertyCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on SqlInitializationAutoConfiguration.SqlInitializationModeCondition.ModeIsNever @ConditionalOnProperty (spring.sql.init.mode=never) did not find property 'mode' (SqlInitializationAutoConfiguration.SqlInitializationModeCondition)

   TaskExecutionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor' (OnClassCondition)

   TaskExecutionAutoConfiguration#applicationTaskExecutor matched:
      - @ConditionalOnMissingBean (types: java.util.concurrent.Executor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskExecutionAutoConfiguration#taskExecutorBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskExecutorBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskSchedulingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler' (OnClassCondition)

   TaskSchedulingAutoConfiguration#taskSchedulerBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskSchedulerBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TemplateEngineConfigurations.DefaultTemplateEngineConfiguration#templateEngine matched:
      - @ConditionalOnMissingBean (types: org.thymeleaf.spring5.ISpringTemplateEngine; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.thymeleaf.templatemode.TemplateMode', 'org.thymeleaf.spring5.SpringTemplateEngine' (OnClassCondition)

   ThymeleafAutoConfiguration.DefaultTemplateResolverConfiguration matched:
      - @ConditionalOnMissingBean (names: defaultTemplateResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration.ThymeleafJava8TimeDialect matched:
      - @ConditionalOnClass found required class 'org.thymeleaf.extras.java8time.dialect.Java8TimeDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafJava8TimeDialect#java8TimeDialect matched:
      - @ConditionalOnMissingBean (types: org.thymeleaf.extras.java8time.dialect.Java8TimeDialect; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration matched:
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.thymeleaf.enabled) matched (OnPropertyCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration.ThymeleafViewResolverConfiguration#thymeleafViewResolver matched:
      - @ConditionalOnMissingBean (names: thymeleafViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.transaction.PlatformTransactionManager' (OnClassCondition)

   TransactionAutoConfiguration#platformTransactionManagerCustomizers matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.transaction.TransactionManagerCustomizers; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration matched:
      - @ConditionalOnBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) found bean 'transactionManager'; @ConditionalOnMissingBean (types: org.springframework.transaction.annotation.AbstractTransactionManagementConfiguration; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.CglibAutoProxyConfiguration matched:
      - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   TransactionAutoConfiguration.TransactionTemplateConfiguration matched:
      - @ConditionalOnSingleCandidate (types: org.springframework.transaction.PlatformTransactionManager; SearchStrategy: all) found a single bean 'transactionManager' (OnBeanCondition)

   TransactionAutoConfiguration.TransactionTemplateConfiguration#transactionTemplate matched:
      - @ConditionalOnMissingBean (types: org.springframework.transaction.support.TransactionOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebSocketMessagingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.socket.config.annotation.WebSocketMessageBrokerConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'javax.websocket.server.ServerContainer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration.TomcatWebSocketConfiguration matched:
      - @ConditionalOnClass found required classes 'org.apache.catalina.startup.Tomcat', 'org.apache.tomcat.websocket.server.WsSci' (OnClassCondition)

   WebSocketServletAutoConfiguration.TomcatWebSocketConfiguration#websocketServletWebServerCustomizer matched:
      - @ConditionalOnMissingBean (names: websocketServletWebServerCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)


Negative matches:
-----------------

   ActiveMQAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.ConnectionFactory' (OnClassCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)

   AopAutoConfiguration.ClassProxyingConfiguration:
      Did not match:
         - @ConditionalOnMissingClass found unwanted class 'org.aspectj.weaver.Advice' (OnClassCondition)

   ArtemisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.ConnectionFactory' (OnClassCondition)

   AtomikosJtaConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.atomikos.icatch.jta.UserTransactionManager' (OnClassCondition)

   BatchAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.batch.core.launch.JobLauncher' (OnClassCondition)

   Cache2kCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.cache2k.Cache2kBuilder' (OnClassCondition)

   CacheAutoConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.cache.interceptor.CacheAspectSupport; SearchStrategy: all) did not find any beans of type org.springframework.cache.interceptor.CacheAspectSupport (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.cache.CacheManager' (OnClassCondition)

   CacheAutoConfiguration.CacheManagerEntityManagerFactoryDependsOnPostProcessor:
      Did not match:
         - Ancestor org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean' (OnClassCondition)

   CaffeineCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.github.benmanes.caffeine.cache.Caffeine' (OnClassCondition)

   CassandraAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.cassandra.ReactiveSession' (OnClassCondition)

   CassandraRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   ClientHttpConnectorAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   CodecsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   CouchbaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   CouchbaseReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   DataSourceAutoConfiguration.EmbeddedDatabaseConfiguration:
      Did not match:
         - EmbeddedDataSource spring.datasource.url is set (DataSourceAutoConfiguration.EmbeddedDatabaseCondition)

   DataSourceConfiguration.Dbcp2:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.commons.dbcp2.BasicDataSource' (OnClassCondition)

   DataSourceConfiguration.Generic:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.type) did not find property 'spring.datasource.type' (OnPropertyCondition)

   DataSourceConfiguration.OracleUcp:
      Did not match:
         - @ConditionalOnClass did not find required classes 'oracle.ucp.jdbc.PoolDataSourceImpl', 'oracle.jdbc.OracleConnection' (OnClassCondition)

   DataSourceConfiguration.Tomcat:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSource' (OnClassCondition)

   DataSourceJmxConfiguration.TomcatDataSourceJmxConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSourceProxy' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.CommonsDbcp2PoolDataSourceMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.commons.dbcp2.BasicDataSource' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.OracleUcpPoolDataSourceMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'oracle.ucp.jdbc.PoolDataSource', 'oracle.jdbc.OracleConnection' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.TomcatDataSourcePoolMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSource' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration.JdbcTransactionManagerConfiguration#transactionManager:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) found beans of type 'org.springframework.transaction.TransactionManager' transactionManager (OnBeanCondition)

   DevToolsR2dbcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   DispatcherServletAutoConfiguration.DispatcherServletConfiguration#multipartResolver:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.web.multipart.MultipartResolver; SearchStrategy: all) did not find any beans of type org.springframework.web.multipart.MultipartResolver (OnBeanCondition)

   EhCacheCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'net.sf.ehcache.Cache' (OnClassCondition)

   ElasticsearchDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.core.ElasticsearchRestTemplate' (OnClassCondition)

   ElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.Client' (OnClassCondition)

   ElasticsearchRestClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.RestClientBuilder' (OnClassCondition)

   EmbeddedLdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.unboundid.ldap.listener.InMemoryDirectoryServer' (OnClassCondition)

   EmbeddedMongoAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.MongoClientSettings' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.JettyWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.util.Loader', 'org.eclipse.jetty.webapp.WebAppContext' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.NettyWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.netty.http.server.HttpServer' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.UndertowWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.undertow.Undertow', 'org.xnio.SslClientAuthMode' (OnClassCondition)

   ErrorWebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   FlywayAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.flywaydb.core.Flyway' (OnClassCondition)

   FreeMarkerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'freemarker.template.Configuration' (OnClassCondition)

   GraphQlAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlQueryByExampleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlQuerydslAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlRSocketAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlReactiveQueryByExampleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlReactiveQuerydslAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebFluxSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebMvcSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GroovyTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'groovy.text.markup.MarkupTemplateEngine' (OnClassCondition)

   GsonAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.google.gson.Gson' (OnClassCondition)

   GsonHttpMessageConvertersConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.google.gson.Gson' (OnClassCondition)

   H2ConsoleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.h2.server.web.WebServlet' (OnClassCondition)

   HazelcastAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastJpaDependencyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HttpHandlerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.DispatcherHandler' (OnClassCondition)

   HypermediaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.hateoas.EntityModel' (OnClassCondition)

   InfinispanCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.infinispan.spring.embedded.provider.SpringEmbeddedCacheManager' (OnClassCondition)

   InfluxDbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.influxdb.InfluxDB' (OnClassCondition)

   IntegrationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.integration.config.EnableIntegration' (OnClassCondition)

   JCacheCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.cache.Caching' (OnClassCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2XmlHttpMessageConverterConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.fasterxml.jackson.dataformat.xml.XmlMapper' (OnClassCondition)

   JdbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.jdbc.repository.config.AbstractJdbcConfiguration' (OnClassCondition)

   JerseyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.glassfish.jersey.server.spring.SpringComponentProvider' (OnClassCondition)

   JmsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.Message' (OnClassCondition)

   JndiConnectionFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jms.core.JmsTemplate' (OnClassCondition)

   JndiDataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.jndi-name) did not find property 'jndi-name' (OnPropertyCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)

   JndiJtaConfiguration:
      Did not match:
         - @ConditionalOnJndi JNDI environment is not available (OnJndiCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.transaction.jta.JtaTransactionManager' (OnClassCondition)

   JooqAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.jooq.DSLContext' (OnClassCondition)

   JpaRepositoriesAutoConfiguration#entityManagerFactoryBootstrapExecutorCustomizer:
      Did not match:
         - AnyNestedCondition 0 matched 2 did not; NestedCondition on JpaRepositoriesAutoConfiguration.BootstrapExecutorCondition.LazyBootstrapMode @ConditionalOnProperty (spring.data.jpa.repositories.bootstrap-mode=lazy) did not find property 'bootstrap-mode'; NestedCondition on JpaRepositoriesAutoConfiguration.BootstrapExecutorCondition.DeferredBootstrapMode @ConditionalOnProperty (spring.data.jpa.repositories.bootstrap-mode=deferred) did not find property 'bootstrap-mode' (JpaRepositoriesAutoConfiguration.BootstrapExecutorCondition)

   JsonbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.json.bind.Jsonb' (OnClassCondition)

   JsonbHttpMessageConvertersConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.json.bind.Jsonb' (OnClassCondition)

   KafkaAutoConfiguration#kafkaJaasInitializer:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.jaas.enabled) did not find property 'spring.kafka.jaas.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaRetryTopicConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.retry.topic.enabled) did not find property 'spring.kafka.retry.topic.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaTransactionManager:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.producer.transaction-id-prefix) did not find property 'spring.kafka.producer.transaction-id-prefix' (OnPropertyCondition)

   KafkaStreamsAnnotationDrivenConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.kafka.streams.StreamsBuilder' (OnClassCondition)

   LdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ldap.core.ContextSource' (OnClassCondition)

   LdapRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.ldap.repository.LdapRepository' (OnClassCondition)

   LiquibaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'liquibase.change.DatabaseChange' (OnClassCondition)

   MailSenderAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.mail.internet.MimeMessage' (OnClassCondition)

   MailSenderValidatorAutoConfiguration:
      Did not match:
         - @ConditionalOnSingleCandidate did not find required type 'org.springframework.mail.javamail.JavaMailSenderImpl' (OnBeanCondition)

   MessageSourceAutoConfiguration:
      Did not match:
         - ResourceBundle did not find bundle with basename messages (MessageSourceAutoConfiguration.ResourceBundleCondition)

   MongoAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MustacheAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.samskivert.mustache.Mustache' (OnClassCondition)

   Neo4jAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   NettyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.netty.util.NettyRuntime' (OnClassCondition)

   OAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.configuration.EnableWebSecurity' (OnClassCondition)

   OAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.oauth2.server.resource.BearerTokenAuthenticationToken' (OnClassCondition)

   ProjectInfoAutoConfiguration#buildProperties:
      Did not match:
         - @ConditionalOnResource did not find resource '${spring.info.build.location:classpath:META-INF/build-info.properties}' (OnResourceCondition)

   ProjectInfoAutoConfiguration#gitProperties:
      Did not match:
         - GitResource did not find git info at classpath:git.properties (ProjectInfoAutoConfiguration.GitResourceAvailableCondition)

   QuartzAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.quartz.Scheduler' (OnClassCondition)

   R2dbcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   R2dbcDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.r2dbc.core.R2dbcEntityTemplate' (OnClassCondition)

   R2dbcInitializationConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.r2dbc.spi.ConnectionFactory', 'org.springframework.r2dbc.connection.init.DatabasePopulator' (OnClassCondition)

   R2dbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   R2dbcTransactionManagerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.r2dbc.connection.R2dbcTransactionManager' (OnClassCondition)

   RSocketGraphQlClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   RSocketMessagingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RSocketRequesterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RSocketSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.rsocket.core.SecuritySocketAcceptorInterceptor' (OnClassCondition)

   RSocketServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.core.RSocketServer' (OnClassCondition)

   RSocketStrategiesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.netty.buffer.PooledByteBufAllocator' (OnClassCondition)

   RabbitAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.rabbitmq.client.Channel' (OnClassCondition)

   ReactiveElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.client.reactive.ReactiveElasticsearchClient' (OnClassCondition)

   ReactiveElasticsearchRestClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.netty.http.client.HttpClient' (OnClassCondition)

   ReactiveMultipartAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   ReactiveOAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   ReactiveOAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.reactive.EnableWebFluxSecurity' (OnClassCondition)

   ReactiveSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   ReactiveUserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.ReactiveAuthenticationManager' (OnClassCondition)

   ReactiveWebServerFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnWebApplication did not find reactive web application classes (OnWebApplicationCondition)

   RedisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.core.RedisOperations' (OnClassCondition)

   RedisCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.connection.RedisConnectionFactory' (OnClassCondition)

   RedisReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   RedisRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.repository.configuration.EnableRedisRepositories' (OnClassCondition)

   RemoteDevToolsAutoConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.devtools.remote.secret) did not find property 'secret' (OnPropertyCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.servlet.Filter', 'org.springframework.http.server.ServerHttpRequest' (OnClassCondition)

   RepositoryRestMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.rest.webmvc.config.RepositoryRestMvcConfiguration' (OnClassCondition)

   Saml2RelyingPartyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.saml2.provider.service.registration.RelyingPartyRegistrationRepository' (OnClassCondition)

   SecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.DefaultAuthenticationEventPublisher' (OnClassCondition)

   SecurityFilterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.http.SessionCreationPolicy' (OnClassCondition)

   SendGridAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.sendgrid.SendGrid' (OnClassCondition)

   ServletWebServerFactoryAutoConfiguration.ForwardedHeaderFilterConfiguration:
      Did not match:
         - @ConditionalOnProperty (server.forward-headers-strategy=framework) did not find property 'server.forward-headers-strategy' (OnPropertyCondition)

   ServletWebServerFactoryConfiguration.EmbeddedJetty:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.util.Loader', 'org.eclipse.jetty.webapp.WebAppContext' (OnClassCondition)

   ServletWebServerFactoryConfiguration.EmbeddedUndertow:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.undertow.Undertow', 'org.xnio.SslClientAuthMode' (OnClassCondition)

   SessionAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.session.Session' (OnClassCondition)

   SolrAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.solr.client.solrj.impl.CloudSolrClient' (OnClassCondition)

   TaskSchedulingAutoConfiguration#scheduledBeanLazyInitializationExcludeFilter:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   TaskSchedulingAutoConfiguration#taskScheduler:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   TemplateEngineConfigurations.ReactiveTemplateEngineConfiguration:
      Did not match:
         - did not find reactive web application classes (OnWebApplicationCondition)

   ThymeleafAutoConfiguration.DataAttributeDialectConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.github.mxab.thymeleaf.extras.dataattribute.dialect.DataAttributeDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafSecurityDialectConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.thymeleaf.extras.springsecurity5.dialect.SpringSecurityDialect', 'org.springframework.security.web.server.csrf.CsrfToken' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafWebFluxConfiguration:
      Did not match:
         - did not find reactive web application classes (OnWebApplicationCondition)

   ThymeleafAutoConfiguration.ThymeleafWebLayoutConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'nz.net.ultraq.thymeleaf.layoutdialect.LayoutDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration#resourceUrlEncodingFilter:
      Did not match:
         - @ConditionalOnEnabledResourceChain did not find class org.webjars.WebJarAssetLocator (OnEnabledResourceChainCondition)

   TransactionAutoConfiguration#transactionalOperator:
      Did not match:
         - @ConditionalOnSingleCandidate (types: org.springframework.transaction.ReactiveTransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)

   UserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.AuthenticationManager' (OnClassCondition)

   ValidationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.validation.executable.ExecutableValidator' (OnClassCondition)

   WebClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   WebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   WebMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport; SearchStrategy: all) found beans of type 'org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport' org.springframework.web.servlet.config.annotation.DelegatingWebMvcConfiguration (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.servlet.DispatcherServlet', 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
         - found 'session' scope (OnWebApplicationCondition)

   WebMvcAutoConfiguration.ResourceChainCustomizerConfiguration:
      Did not match:
         - @ConditionalOnEnabledResourceChain did not find class org.webjars.WebJarAssetLocator (OnEnabledResourceChainCondition)
         - Ancestor org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)

   WebServiceTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.oxm.Marshaller' (OnClassCondition)

   WebServicesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ws.transport.http.MessageDispatcherServlet' (OnClassCondition)

   WebSessionIdResolverAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Mono' (OnClassCondition)

   WebSocketMessagingAutoConfiguration.WebSocketMessageConverterConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.web.socket.config.annotation.DelegatingWebSocketMessageBrokerConfiguration,com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) did not find any beans of type org.springframework.web.socket.config.annotation.DelegatingWebSocketMessageBrokerConfiguration (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required classes 'com.fasterxml.jackson.databind.ObjectMapper', 'org.springframework.messaging.simp.config.AbstractMessageBrokerConfiguration' (OnClassCondition)

   WebSocketReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnWebApplication did not find reactive web application classes (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration.Jetty10WebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.websocket.javax.server.internal.JavaxWebSocketServerContainer', 'org.eclipse.jetty.websocket.server.JettyWebSocketServerContainer' (OnClassCondition)

   WebSocketServletAutoConfiguration.JettyWebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.eclipse.jetty.websocket.jsr356.server.deploy.WebSocketServerContainerInitializer' (OnClassCondition)

   WebSocketServletAutoConfiguration.UndertowWebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.undertow.websockets.jsr.Bootstrap' (OnClassCondition)

   XADataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.boot.jdbc.XADataSourceWrapper; SearchStrategy: all) did not find any beans of type org.springframework.boot.jdbc.XADataSourceWrapper (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'javax.transaction.TransactionManager', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)


Exclusions:
-----------

    None


Unconditional classes:
----------------------

    org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration

    org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration

    org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration

    org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration

    org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration



""[01:29:06.080][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare:line707] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Executing onJoinPrepare with generation -1 and memberId 
""[01:29:06.080][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] (Re-)joining group
""[01:29:06.080][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.run:line1367] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Heartbeat thread started
""[01:29:06.080][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.metadata:line219] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Joining group with current subscription: [reservation-topic]
""[01:29:06.080][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 0.772 seconds (JVM running for 331.863)
""[01:29:06.080][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line547] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending JoinGroup (JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])) to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:06.080][DEBUG][org.springframework.boot.availability.ApplicationAvailabilityBean.onApplicationEvent:line77] - Application availability state LivenessState changed to CORRECT
""[01:29:06.081][DEBUG][org.apache.kafka.common.network.Selector.pollSelectionKeys:line531] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147482646
""[01:29:06.081][DEBUG][org.apache.kafka.clients.NetworkClient.handleConnections:line951] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Completed connection to node 2147482646. Fetching API versions.
""[01:29:06.081][DEBUG][org.apache.kafka.clients.NetworkClient.handleInitiateApiVersionRequests:line965] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Initiating API versions fetch from node 2147482646.
""[01:29:06.081][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-6, correlationId=4) and timeout 30000 to node 2147482646: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.2')
""[01:29:06.081][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:29:06.081][DEBUG][org.springframework.boot.availability.ApplicationAvailabilityBean.onApplicationEvent:line77] - Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
""[01:29:06.083][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received API_VERSIONS response from node 2147482646 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-6, correlationId=4): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=12), ApiVersion(apiKey=2, minVersion=0, maxVersion=6), ApiVersion(apiKey=3, minVersion=0, maxVersion=11), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=7), ApiVersion(apiKey=10, minVersion=0, maxVersion=3), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
""[01:29:06.083][DEBUG][org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse:line921] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 2147482646 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 6 [usable: 6], Metadata(3): 0 to 11 [usable: 11], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
""[01:29:06.083][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending JOIN_GROUP request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-6, correlationId=3) and timeout 305000 to node 2147482646: JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:29:06.085][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received JOIN_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-6, correlationId=3): JoinGroupResponseData(throttleTimeMs=0, errorCode=79, generationId=-1, protocolType=null, protocolName=null, leader='', memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', members=[])
""[01:29:06.086][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line654] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] JoinGroup failed due to non-fatal error: MEMBER_ID_REQUIRED Will set the member id as consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f and then rejoin. Sent generation was  Generation{generationId=-1, memberId='', protocol='null'}
""[01:29:06.086][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:29:06.086][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] (Re-)joining group
""[01:29:06.086][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.metadata:line219] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Joining group with current subscription: [reservation-topic]
""[01:29:06.087][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line547] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending JoinGroup (JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])) to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:06.087][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending JOIN_GROUP request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-6, correlationId=5) and timeout 305000 to node 2147482646: JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:29:06.091][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received JOIN_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-6, correlationId=5): JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=54, protocolType='consumer', protocolName='range', leader='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', members=[JoinGroupResponseMember(memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null, metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:29:06.091][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line575] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=54, protocolType='consumer', protocolName='range', leader='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', members=[JoinGroupResponseMember(memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null, metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:29:06.092][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.enable:line1335] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Enabling heartbeat thread
""[01:29:06.092][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', protocol='range'}
""[01:29:06.092][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line645] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Performing assignment using strategy range with subscriptions {consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f=Subscription(topics=[reservation-topic], ownedPartitions=[], groupInstanceId=null)}
""[01:29:06.092][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Finished assignment for group at generation 54: {consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f=Assignment(partitions=[reservation-topic-0])}
""[01:29:06.092][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinLeader:line716] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending leader SyncGroup to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) at generation Generation{generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', protocol='range'}: SyncGroupRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null, protocolType='consumer', protocolName='range', assignments=[SyncGroupRequestAssignment(memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])])
""[01:29:06.092][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending SYNC_GROUP request with header RequestHeader(apiKey=SYNC_GROUP, apiVersion=5, clientId=consumer-my-consumer-group-6, correlationId=6) and timeout 30000 to node 2147482646: SyncGroupRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null, protocolType='consumer', protocolName='range', assignments=[SyncGroupRequestAssignment(memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])])
""[01:29:06.096][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received SYNC_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=SYNC_GROUP, apiVersion=5, clientId=consumer-my-consumer-group-6, correlationId=6): SyncGroupResponseData(throttleTimeMs=0, errorCode=0, protocolType='consumer', protocolName='range', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])
""[01:29:06.097][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line745] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful SyncGroup response: SyncGroupResponseData(throttleTimeMs=0, errorCode=0, protocolType='consumer', protocolName='range', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])
""[01:29:06.097][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', protocol='range'}
""[01:29:06.097][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete:line353] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Executing onJoinComplete with generation 54 and memberId consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f
""[01:29:06.098][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:29:06.098][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:29:06.098][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetFetchRequest:line1337] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Fetching committed offsets for partitions: [reservation-topic-0]
""[01:29:06.098][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending OFFSET_FETCH request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-6, correlationId=7) and timeout 30000 to node 2147482646: OffsetFetchRequestData(groupId='my-consumer-group', topics=[OffsetFetchRequestTopic(name='reservation-topic', partitionIndexes=[0])], groups=[], requireStable=true)
""[01:29:06.100][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received OFFSET_FETCH response from node 2147482646 for request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-6, correlationId=7): OffsetFetchResponseData(throttleTimeMs=0, topics=[OffsetFetchResponseTopic(name='reservation-topic', partitions=[OffsetFetchResponsePartition(partitionIndex=0, committedOffset=34, committedLeaderEpoch=-1, metadata='', errorCode=0)])], errorCode=0, groups=[])
""[01:29:06.100][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetFetchRequest:line1337] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Fetching committed offsets for partitions: [reservation-topic-0]
""[01:29:06.101][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending OFFSET_FETCH request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-6, correlationId=8) and timeout 30000 to node 2147482646: OffsetFetchRequestData(groupId='my-consumer-group', topics=[OffsetFetchRequestTopic(name='reservation-topic', partitionIndexes=[0])], groups=[], requireStable=true)
""[01:29:06.103][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received OFFSET_FETCH response from node 2147482646 for request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-6, correlationId=8): OffsetFetchResponseData(throttleTimeMs=0, topics=[OffsetFetchResponseTopic(name='reservation-topic', partitions=[OffsetFetchResponsePartition(partitionIndex=0, committedOffset=34, committedLeaderEpoch=-1, metadata='', errorCode=0)])], errorCode=0, groups=[])
""[01:29:06.103][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:29:06.103][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:29:06.103][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:06.103][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 1001 with 1 partition(s).
""[01:29:06.103][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED FullFetchRequest(toSend=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:06.103][DEBUG][org.apache.kafka.clients.ClientUtils.resolve:line113] - Resolved host 127.0.0.1 as 127.0.0.1
""[01:29:06.104][DEBUG][org.apache.kafka.clients.NetworkClient.initiateConnect:line989] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Initiating connection to node 127.0.0.1:9092 (id: 1001 rack: null) using address /127.0.0.1
""[01:29:06.105][DEBUG][org.apache.kafka.common.network.Selector.pollSelectionKeys:line531] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1001
""[01:29:06.105][DEBUG][org.apache.kafka.clients.NetworkClient.handleConnections:line951] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Completed connection to node 1001. Fetching API versions.
""[01:29:06.105][DEBUG][org.apache.kafka.clients.NetworkClient.handleInitiateApiVersionRequests:line965] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Initiating API versions fetch from node 1001.
""[01:29:06.105][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-6, correlationId=10) and timeout 30000 to node 1001: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.2')
""[01:29:06.107][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received API_VERSIONS response from node 1001 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-6, correlationId=10): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=12), ApiVersion(apiKey=2, minVersion=0, maxVersion=6), ApiVersion(apiKey=3, minVersion=0, maxVersion=11), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=7), ApiVersion(apiKey=10, minVersion=0, maxVersion=3), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
""[01:29:06.107][DEBUG][org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse:line921] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 6 [usable: 6], Metadata(3): 0 to 11 [usable: 11], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
""[01:29:06.108][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=9) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=0, sessionEpoch=0, topics=[FetchTopic(topic='reservation-topic', topicId=8aoMqokpSXGOqjBL2y8aPw, partitions=[FetchPartition(partition=0, currentLeaderEpoch=0, fetchOffset=34, lastFetchedEpoch=-1, logStartOffset=-1, partitionMaxBytes=1048576)])], forgottenTopicsData=[], rackId='')
""[01:29:06.611][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=9): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[FetchableTopicResponse(topic='reservation-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, partitions=[PartitionData(partitionIndex=0, errorCode=0, highWatermark=34, lastStableOffset=34, logStartOffset=0, divergingEpoch=EpochEndOffset(epoch=-1, endOffset=-1), currentLeader=LeaderIdAndEpoch(leaderId=-1, leaderEpoch=-1), snapshotId=SnapshotId(endOffset=-1, epoch=-1), abortedTransactions=null, preferredReadReplica=-1, records=MemoryRecords(size=0, buffer=java.nio.HeapByteBuffer[pos=0 lim=0 cap=3]))])])
""[01:29:06.611][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line561] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent a full fetch response that created a new incremental fetch session 1256273455 with 1 response partition(s)
""[01:29:06.611][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.onSuccess:line326] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Fetch READ_UNCOMMITTED at offset 34 for partition reservation-topic-0 returned fetch data PartitionData(partitionIndex=0, errorCode=0, highWatermark=34, lastStableOffset=34, logStartOffset=0, divergingEpoch=EpochEndOffset(epoch=-1, endOffset=-1), currentLeader=LeaderIdAndEpoch(leaderId=-1, leaderEpoch=-1), snapshotId=SnapshotId(endOffset=-1, epoch=-1), abortedTransactions=null, preferredReadReplica=-1, records=MemoryRecords(size=0, buffer=java.nio.HeapByteBuffer[pos=0 lim=0 cap=3]))
""[01:29:06.611][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:06.611][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=1) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:06.611][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:06.611][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=11) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=1, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:07.115][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=11): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:07.116][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:07.116][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:07.116][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=2) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:07.117][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:07.117][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=12) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=2, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:07.619][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=12): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:07.619][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:07.619][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:07.619][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=3) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:07.619][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:07.619][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=13) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=3, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:08.122][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=13): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:08.123][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:08.124][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:08.124][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=4) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:08.124][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:08.124][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=14) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=4, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:08.626][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=14): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:08.627][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:08.627][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:08.627][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=5) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:08.627][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:08.627][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=15) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=5, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:09.094][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:09.094][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=16) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:09.096][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=16): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:09.096][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:09.130][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=15): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:09.130][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:09.130][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:09.130][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=6) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:09.130][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:09.130][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=17) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=6, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:09.632][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=17): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:09.633][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:09.633][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:09.633][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=7) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:09.633][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:09.633][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=18) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=7, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:10.136][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=18): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:10.136][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:10.136][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:10.137][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=8) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:10.137][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:10.137][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=19) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=8, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:10.640][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=19): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:10.640][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:10.640][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:10.640][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=9) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:10.640][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:10.641][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=20) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=9, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:11.071][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:11.071][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:11.143][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=20): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:11.143][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:11.143][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:11.143][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=10) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:11.143][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:11.143][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=21) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=10, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:11.646][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=21): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:11.647][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:11.647][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:11.647][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=11) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:11.647][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:11.647][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=22) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=11, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:12.098][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:12.098][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=23) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:12.101][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=23): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:12.101][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:12.149][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=22): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:12.149][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:12.149][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:12.150][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=12) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:12.150][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:12.150][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=24) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=12, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:12.653][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=24): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:12.653][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:12.653][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:12.653][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=13) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:12.653][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:12.653][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=25) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=13, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:13.156][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=25): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:13.157][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:13.158][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:13.158][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=14) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:13.158][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:13.158][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=26) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=14, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:13.660][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=26): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:13.661][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:13.661][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:13.661][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=15) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:13.661][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:13.661][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=27) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=15, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:14.162][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=27): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:14.162][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:14.163][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:14.163][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=16) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:14.163][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:14.163][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=28) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=16, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:14.666][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=28): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:14.667][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:14.667][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:14.667][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=17) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:14.667][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:14.667][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=29) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=17, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:15.099][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:15.100][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=30) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:15.103][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=30): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:15.104][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:15.177][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=29): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:15.178][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:15.179][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:15.179][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=18) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:15.179][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:15.179][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=31) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=18, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:15.683][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=31): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:15.683][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:15.683][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:15.683][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=19) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:15.684][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:15.684][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=32) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=19, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:16.074][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:16.074][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:16.186][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=32): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:16.186][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:16.186][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:16.186][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=20) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:16.186][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:16.186][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=33) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=20, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:16.690][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=33): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:16.690][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:16.691][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:16.691][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=21) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:16.691][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:16.691][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=34) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=21, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:17.193][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=34): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:17.193][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:17.193][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:17.193][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=22) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:17.194][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:17.194][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=35) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=22, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:17.696][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=35): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:17.696][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:17.697][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:17.697][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=23) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:17.697][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:17.697][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=36) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=23, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:18.103][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:18.103][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=37) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:18.106][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=37): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:18.106][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:18.200][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=36): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:18.201][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:18.201][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:18.201][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=24) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:18.201][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:18.201][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=38) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=24, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:18.704][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=38): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:18.705][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:18.705][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:18.705][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=25) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:18.705][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:18.705][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=39) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=25, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:19.208][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=39): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:19.208][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:19.208][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:19.208][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=26) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:19.208][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:19.209][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=40) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=26, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:19.710][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=40): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:19.712][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:19.713][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:19.713][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=27) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:19.713][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:19.713][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=41) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=27, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:20.215][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=41): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:20.215][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:20.215][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:20.215][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=28) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:20.216][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:20.216][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=42) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=28, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:20.718][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=42): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:20.718][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:20.718][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:20.718][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=29) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:20.718][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:20.718][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=43) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=29, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:21.086][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:21.086][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:21.117][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:21.117][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=44) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:21.120][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=44): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:21.120][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:21.222][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=43): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:21.222][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:21.222][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:21.223][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=30) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:21.223][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:21.223][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=45) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=30, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:21.725][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=45): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:21.725][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:21.725][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:21.725][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=31) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:21.726][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:21.726][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=46) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=31, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:22.228][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=46): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:22.228][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:22.228][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:22.228][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=32) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:22.228][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:22.228][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=47) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=32, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:22.731][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=47): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:22.731][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:22.731][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:22.731][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=33) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:22.731][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:22.731][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=48) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=33, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:23.233][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=48): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:23.234][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:23.234][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:23.234][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=34) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:23.234][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:23.235][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=49) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=34, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:23.737][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=49): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:23.737][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:23.737][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:23.737][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=35) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:23.738][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:23.738][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=50) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=35, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:24.126][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:24.126][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=51) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:24.129][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=51): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:24.129][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:24.241][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=50): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:24.241][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:24.241][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:24.241][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=36) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:24.242][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:24.242][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=52) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=36, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:24.745][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=52): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:24.745][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:24.745][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:24.745][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=37) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:24.746][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:24.746][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=53) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=37, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:25.248][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=53): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:25.248][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:25.249][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:25.249][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=38) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:25.249][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:25.249][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=54) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=38, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:25.751][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=54): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:25.752][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:25.752][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:25.752][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=39) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:25.752][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:25.752][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=55) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=39, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:26.087][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:26.088][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:26.255][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=55): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:26.255][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:26.256][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:26.256][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=40) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:26.256][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:26.256][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=56) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=40, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:26.759][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=56): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:26.759][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:26.760][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:26.760][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=41) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:26.761][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:26.761][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=57) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=41, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:27.136][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:27.136][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=58) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:27.138][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=58): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:27.138][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:27.263][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=57): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:27.264][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:27.264][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:27.264][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=42) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:27.264][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:27.264][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=59) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=42, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:27.767][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=59): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:27.767][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:27.767][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:27.768][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=43) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:27.768][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:27.768][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=60) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=43, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:28.270][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=60): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:28.270][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:28.270][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:28.270][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=44) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:28.271][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:28.271][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=61) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=44, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:28.773][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=61): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:28.773][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:28.774][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:28.774][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=45) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:28.774][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:28.774][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=62) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=45, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:29.277][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=62): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:29.277][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:29.277][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:29.277][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=46) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:29.277][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:29.277][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=63) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=46, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:29.780][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=63): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:29.780][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:29.781][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:29.781][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=47) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:29.781][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:29.781][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=64) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=47, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:30.150][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:30.150][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=65) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:30.153][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=65): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:30.153][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:30.284][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=64): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:30.284][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:30.284][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:30.284][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=48) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:30.284][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:30.284][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=66) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=48, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:30.787][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=66): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:30.787][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:30.789][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:30.789][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=49) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:30.789][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:30.789][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=67) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=49, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:31.100][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:31.100][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:31.292][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=67): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:31.292][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:31.293][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:31.293][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=50) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:31.293][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:31.293][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=68) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=50, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:31.796][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=68): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:31.796][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:31.796][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:31.796][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=51) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:31.797][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:31.797][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=69) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=51, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:32.299][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=69): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:32.299][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:32.299][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:32.299][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=52) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:32.299][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:32.299][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=70) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=52, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:32.803][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=70): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:32.803][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:32.804][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:32.804][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=53) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:32.804][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:32.804][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=71) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=53, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:33.160][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:33.160][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=72) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:33.163][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=72): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:33.163][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:33.306][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=71): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:33.306][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:33.307][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:33.307][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=54) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:33.307][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:33.307][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=73) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=54, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:33.811][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=73): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:33.811][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:33.811][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:33.811][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=55) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:33.811][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:33.811][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=74) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=55, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:34.313][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=74): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:34.313][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:34.314][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:34.314][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=56) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:34.314][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:34.314][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=75) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=56, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:34.817][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=75): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:34.818][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:34.818][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:34.818][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=57) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:34.819][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:34.819][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=76) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=57, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:35.315][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(9)-127.0.0.1: accepted socket from [127.0.0.1:50558]
""[01:29:35.317][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(9)-127.0.0.1: (port 50271) op = 80
""[01:29:35.317][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  1
""[01:29:35.321][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=76): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:35.321][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:35.321][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:35.322][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=58) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:35.322][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:35.322][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=77) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=58, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:35.825][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=77): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:35.825][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:35.825][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:35.825][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=59) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:35.825][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:35.826][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=78) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=59, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:35.901][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-6 - Pool stats (total=10, active=0, idle=10, waiting=0)
""[01:29:35.901][DEBUG][com.zaxxer.hikari.pool.HikariPool.fillPool:line518] - HikariPool-6 - Fill pool skipped, pool is at sufficient level.
""[01:29:36.104][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:36.104][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:36.166][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:36.166][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=79) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:36.169][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=79): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:36.169][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:36.328][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=78): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:36.329][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:36.329][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:36.329][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=60) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:36.329][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:36.329][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=80) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=60, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:36.831][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=80): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:36.832][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:36.832][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:36.832][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=61) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:36.832][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:36.832][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=81) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=61, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:37.334][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=81): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:37.334][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:37.334][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:37.334][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=62) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:37.335][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:37.335][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=82) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=62, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:37.837][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=82): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:37.837][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:37.838][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:37.838][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=63) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:37.838][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:37.838][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=83) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=63, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:38.342][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=83): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:38.342][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:38.342][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:38.342][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=64) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:38.342][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:38.342][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=84) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=64, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:38.844][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=84): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:38.845][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:38.845][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:38.846][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=65) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:38.846][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:38.846][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=85) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=65, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:39.171][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:39.171][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=86) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:39.175][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=86): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:39.175][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:39.348][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=85): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:39.348][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:39.349][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:39.349][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=66) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:39.349][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:39.349][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=87) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=66, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:39.851][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=87): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:39.851][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:39.851][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:39.852][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=67) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:39.852][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:39.852][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=88) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=67, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:40.354][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=88): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:40.354][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:40.354][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:40.354][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=68) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:40.355][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:40.355][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=89) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=68, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:40.857][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=89): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:40.857][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:40.858][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:40.858][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=69) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:40.858][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:40.858][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=90) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=69, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:41.109][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:41.109][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:41.360][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=90): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:41.360][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:41.360][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:41.360][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=70) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:41.360][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:41.361][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=91) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=70, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:41.863][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=91): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:41.863][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:41.864][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:41.864][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=71) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:41.864][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:41.864][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=92) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=71, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:42.184][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:42.184][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=93) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:42.188][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=93): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:42.189][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:42.366][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=92): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:42.366][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:42.367][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:42.367][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=72) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:42.367][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:42.367][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=94) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=72, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:42.869][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=94): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:42.869][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:42.869][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:42.869][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=73) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:42.869][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:42.870][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=95) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=73, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:43.372][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=95): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:43.373][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:43.373][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:43.373][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=74) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:43.373][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:43.373][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=96) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=74, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:43.876][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=96): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:43.876][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:43.876][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:43.877][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=75) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:43.877][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:43.877][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=97) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=75, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:44.380][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=97): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:44.380][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:44.380][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:44.380][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=76) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:44.380][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:44.381][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=98) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=76, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:44.883][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=98): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:44.883][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:44.884][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:44.884][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=77) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:44.884][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:44.884][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=99) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=77, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:45.187][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:45.187][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=100) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:45.191][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=100): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:45.191][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:45.386][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=99): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:45.386][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:45.386][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:45.386][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=78) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:45.386][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:45.387][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=101) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=78, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:45.890][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=101): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:45.890][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:45.890][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:45.890][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=79) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:45.891][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:45.891][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=102) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=79, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:46.112][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:46.112][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:46.394][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=102): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:46.394][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:46.395][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:46.395][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=80) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:46.395][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:46.395][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=103) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=80, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:46.898][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=103): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:46.898][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:46.899][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:46.899][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=81) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:46.899][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:46.900][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=104) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=81, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:47.402][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=104): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:47.403][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:47.403][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:47.404][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=82) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:47.404][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:47.404][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=105) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=82, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:47.907][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=105): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:47.907][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:47.908][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:47.908][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=83) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:47.908][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:47.908][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=106) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=83, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:48.189][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:48.189][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=107) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:48.191][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=107): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:48.192][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:48.411][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=106): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:48.411][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:48.411][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:48.412][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=84) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:48.412][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:48.412][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=108) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=84, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:48.914][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=108): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:48.915][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:48.915][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:48.915][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=85) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:48.916][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:48.916][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=109) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=85, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:49.418][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=109): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:49.419][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:49.419][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:49.419][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=86) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:49.419][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:49.419][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=110) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=86, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:49.921][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=110): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:49.922][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:49.922][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:49.922][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=87) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:49.922][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:49.923][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=111) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=87, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:50.320][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(9)-127.0.0.1: (port 50271) connection closed
""[01:29:50.320][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(9)-127.0.0.1: close connection, socket: Socket[addr=/127.0.0.1,port=50558,localport=50271]
""[01:29:50.320][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(9)-127.0.0.1: socket close: Socket[addr=/127.0.0.1,port=50558,localport=50271]
""[01:29:50.425][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=111): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:50.425][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:50.426][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:50.426][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=88) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:50.426][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:50.426][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=112) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=88, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:50.928][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=112): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:50.928][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:50.929][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:50.929][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=89) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:50.929][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:50.929][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=113) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=89, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:51.116][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:51.116][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:51.192][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:51.192][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=114) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:51.195][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=114): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:51.195][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:51.431][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=113): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:51.431][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:51.432][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:51.432][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=90) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:51.432][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:51.432][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=115) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=90, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:51.935][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=115): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:51.935][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:51.935][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:51.935][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=91) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:51.935][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:51.935][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=116) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=91, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:52.439][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=116): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:52.440][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:52.440][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:52.440][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=92) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:52.440][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:52.440][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=117) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=92, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:52.943][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=117): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:52.944][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:52.944][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:52.944][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=93) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:52.944][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:52.944][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=118) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=93, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:53.447][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=118): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:53.447][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:53.447][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:53.447][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=94) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:53.447][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:53.447][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=119) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=94, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:53.950][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=119): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:53.950][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:53.950][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:53.950][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=95) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:53.950][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:53.950][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=120) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=95, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:54.199][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:54.199][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=121) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:54.201][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=121): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:54.201][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:54.452][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=120): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:54.452][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:54.452][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:54.452][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=96) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:54.452][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:54.452][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=122) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=96, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:54.956][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=122): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:54.957][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:54.957][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:54.957][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=97) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:54.957][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:54.957][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=123) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=97, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:55.461][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=123): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:55.461][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:55.462][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:55.462][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=98) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:55.462][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:55.462][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=124) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=98, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:55.965][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=124): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:55.965][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:55.965][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:55.965][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=99) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:55.966][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:55.966][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=125) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=99, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:56.119][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:29:56.119][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:29:56.469][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=125): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:56.469][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:56.469][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:56.469][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=100) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:56.470][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:56.470][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=126) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=100, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:56.972][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=126): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:56.972][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:56.972][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:56.972][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=101) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:56.973][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:56.973][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=127) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=101, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:57.206][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:29:57.206][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=128) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:29:57.210][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=128): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:29:57.210][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:29:57.477][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=127): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:57.477][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:57.477][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:57.477][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=102) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:57.478][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:57.478][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=129) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=102, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:57.980][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=129): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:57.980][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:57.980][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:57.980][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=103) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:57.980][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:57.980][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=130) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=103, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:58.484][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=130): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:58.484][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:58.484][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:58.484][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=104) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:58.484][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:58.484][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=131) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=104, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:58.987][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=131): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:58.988][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:58.988][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:58.988][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=105) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:58.989][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:58.989][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=132) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=105, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:59.492][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=132): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:59.492][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:59.492][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:59.492][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=106) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:59.492][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:59.493][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=133) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=106, topics=[], forgottenTopicsData=[], rackId='')
""[01:29:59.995][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=133): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:29:59.995][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:29:59.996][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:59.996][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=107) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:29:59.996][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:29:59.996][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=134) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=107, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:00.210][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:30:00.210][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=135) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:30:00.213][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=135): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:30:00.213][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:30:00.499][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=134): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:00.499][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:00.499][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:00.499][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=108) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:00.500][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:00.500][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=136) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=108, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:01.002][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=136): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:01.002][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:01.003][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:01.003][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=109) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:01.003][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:01.003][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=137) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=109, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:01.133][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:30:01.133][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:30:01.505][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=137): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:01.505][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:01.506][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:01.506][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=110) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:01.506][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:01.506][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=138) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=110, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:02.009][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=138): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:02.009][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:02.009][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:02.009][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=111) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:02.009][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:02.009][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=139) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=111, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:02.511][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=139): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:02.512][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:02.512][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:02.512][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=112) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:02.512][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:02.512][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=140) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=112, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:03.015][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=140): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:03.015][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:03.016][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:03.016][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=113) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:03.016][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:03.016][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=141) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=113, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:03.212][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:30:03.212][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=142) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:30:03.215][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=142): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:30:03.215][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:30:03.518][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=141): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:03.518][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:03.518][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:03.518][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=114) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:03.519][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:03.519][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=143) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=114, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:04.021][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=143): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:04.022][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:04.022][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:04.022][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=115) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:04.023][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:04.023][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=144) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=115, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:04.525][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=144): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:04.526][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:04.526][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:04.526][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=116) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:04.526][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:04.526][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=145) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=116, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:05.029][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=145): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:05.029][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:05.029][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:05.029][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=117) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:05.029][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:05.029][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=146) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=117, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:05.532][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=146): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:05.533][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:05.533][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:05.533][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=118) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:05.533][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:05.534][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=147) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=118, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:05.817][DEBUG][org.apache.catalina.session.ManagerBase.log:line173] - Start expire sessions StandardManager at 1692289805817 sessioncount 0
""[01:30:05.817][DEBUG][org.apache.catalina.session.ManagerBase.log:line173] - End expire sessions StandardManager processingTime 0 expired sessions: 0
""[01:30:05.908][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-6 - Pool stats (total=10, active=0, idle=10, waiting=0)
""[01:30:05.908][DEBUG][com.zaxxer.hikari.pool.HikariPool.fillPool:line518] - HikariPool-6 - Fill pool skipped, pool is at sufficient level.
""[01:30:06.036][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=147): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:06.036][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:06.037][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:06.037][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=119) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:06.037][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:06.037][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=148) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=119, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:06.141][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:30:06.141][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:30:06.219][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:30:06.219][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=149) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:30:06.221][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=149): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:30:06.222][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:30:06.540][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=148): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:06.540][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:06.540][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:06.540][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=120) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:06.541][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:06.541][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=150) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=120, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:07.043][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=150): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:07.044][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:07.044][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:07.044][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=121) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:07.044][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:07.044][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=151) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=121, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:07.547][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=151): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:07.547][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:07.548][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:07.548][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=122) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:07.548][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:07.548][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=152) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=122, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:08.050][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=152): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:08.050][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:08.051][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:08.051][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=123) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:08.051][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:08.051][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=153) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=123, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:08.554][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=153): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:08.554][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:08.555][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:08.555][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=124) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:08.555][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:08.555][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=154) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=124, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:09.058][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=154): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:09.059][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:09.059][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:09.059][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=125) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:09.059][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:09.059][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=155) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=125, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:09.222][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:30:09.222][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=156) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:30:09.225][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=156): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:30:09.225][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:30:09.562][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=155): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:09.562][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:09.562][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:09.562][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=126) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:09.563][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:09.563][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=157) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=126, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:10.066][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=157): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:10.067][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:10.067][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:10.067][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=127) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:10.067][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:10.067][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=158) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=127, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:10.570][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=158): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:10.570][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:10.570][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:10.570][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=128) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:10.570][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:10.571][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=159) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=128, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:11.073][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=159): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:11.074][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:11.074][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:11.074][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=129) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:11.074][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:11.074][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=160) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=129, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:11.150][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:30:11.150][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:30:11.577][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=160): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:11.577][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:11.578][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:11.578][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=130) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:11.578][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:11.578][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=161) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=130, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:12.080][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=161): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:12.080][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:12.080][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:12.080][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=131) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:12.081][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:12.081][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=162) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=131, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:12.226][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:30:12.226][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=163) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:30:12.228][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=163): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:30:12.228][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:30:12.583][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=162): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:12.583][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:12.584][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:12.584][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=132) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:12.584][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:12.584][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=164) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=132, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:13.087][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=164): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:13.088][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:13.088][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:13.088][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=133) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:13.088][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:13.088][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=165) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=133, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:13.592][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=165): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:13.592][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:13.592][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:13.593][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=134) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:13.593][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:13.593][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=166) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=134, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:14.096][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=166): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:14.097][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:14.097][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:14.097][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=135) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:14.097][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:14.097][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=167) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=135, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:14.599][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=167): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:14.599][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:14.600][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:14.600][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=136) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:14.600][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:14.600][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=168) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=136, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:15.103][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=168): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:15.103][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:15.104][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:15.104][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=137) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:15.104][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:15.104][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=169) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=137, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:15.235][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:30:15.235][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=170) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:30:15.237][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=170): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:30:15.237][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:30:15.607][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=169): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:15.607][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:15.608][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:15.608][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=138) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:15.608][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:15.608][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=171) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=138, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:16.111][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=171): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:16.111][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:16.111][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:16.111][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=139) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:16.112][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:16.112][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=172) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=139, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:16.155][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:30:16.155][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:30:16.614][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=172): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:16.614][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:16.615][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:16.615][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=140) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:16.615][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:16.615][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=173) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=140, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:17.117][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=173): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:17.117][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:17.117][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:17.117][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=141) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:17.117][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:17.117][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=174) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=141, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:17.621][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=174): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:17.621][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:17.621][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:17.621][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=142) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:17.621][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:17.622][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=175) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=142, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:18.124][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=175): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:18.125][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:18.125][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:18.126][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=143) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:18.126][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:18.126][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=176) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=143, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:18.236][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:30:18.236][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=177) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:30:18.239][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=177): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:30:18.239][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:30:18.629][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=176): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:18.629][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:18.629][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:18.629][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=144) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:18.629][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:18.629][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=178) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=144, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:19.130][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=178): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:19.131][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:19.132][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:19.132][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=145) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:19.132][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:19.132][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=179) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=145, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:19.635][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=179): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:19.635][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:19.635][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:19.635][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=146) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:19.635][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:19.636][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=180) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=146, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:20.138][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=180): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:20.138][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:20.139][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:20.139][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=147) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:20.139][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:20.139][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=181) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=147, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:20.641][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=181): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:20.642][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:20.642][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:20.642][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=148) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:20.642][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:20.642][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=182) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=148, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:21.145][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=182): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:21.146][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:21.147][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:21.147][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=149) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:21.147][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:21.147][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=183) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=149, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:21.161][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:30:21.161][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:30:21.239][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending Heartbeat request with generation 54 and member id consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:30:21.239][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=184) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)
""[01:30:21.242][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=184): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:30:21.242][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received successful Heartbeat response
""[01:30:21.625][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(10)-127.0.0.1: accepted socket from [127.0.0.1:50580]
""[01:30:21.626][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(10)-127.0.0.1: (port 50267) op = 80
""[01:30:21.630][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(11)-127.0.0.1: accepted socket from [127.0.0.1:50581]
""[01:30:21.631][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(11)-127.0.0.1: (port 50271) op = 80
""[01:30:21.633][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "[Ljava.rmi.server.ObjID;", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.633][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "java.rmi.server.ObjID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.634][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "java.rmi.server.UID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.634][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "java.rmi.dgc.Lease", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.635][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "java.rmi.dgc.VMID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.635][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "[B", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.635][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(10)-127.0.0.1: (port 50267) op = 82
""[01:30:21.636][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(10)-127.0.0.1: (port 50267) op = 84
""[01:30:21.636][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(11)-127.0.0.1: (port 50271) op = 80
""[01:30:21.637][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(11)-127.0.0.1: (port 50271) op = 80
""[01:30:21.637][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "[Ljava.rmi.server.ObjID;", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.637][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "java.rmi.server.ObjID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.638][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "java.rmi.server.UID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.638][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "java.rmi.dgc.Lease", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.638][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "java.rmi.dgc.VMID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.638][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "[B", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@3a3aa15f
""[01:30:21.639][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(11)-127.0.0.1: (port 50271) op = 84
""[01:30:21.639][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(11)-127.0.0.1: (port 50271) op = 80
""[01:30:21.641][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(11)-127.0.0.1: (port 50271) op = 80
""[01:30:21.641][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:30:21.642][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(11)-127.0.0.1: name = "java.rmi.MarshalledObject", codebase = ""
""[01:30:21.643][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  2 unwrapping params with MBean extended ClassLoader.
""[01:30:21.647][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  2, name=org.springframework.boot:type=Admin,name=SpringApplication, operationName=shutdown, signature=null
""[01:30:21.647][INFO ][org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin.shutdown:line159] - Application shutdown requested.
""[01:30:21.647][DEBUG][org.springframework.boot.availability.ApplicationAvailabilityBean.onApplicationEvent:line77] - Application availability state ReadinessState changed from ACCEPTING_TRAFFIC to REFUSING_TRAFFIC
""[01:30:21.647][DEBUG][org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext.doClose:line1052] - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@370192a6, started on Fri Aug 18 01:29:05 KST 2023
""[01:30:21.648][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase 2147483647
""[01:30:21.648][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'webSocketHandlerMapping' completed its stop procedure
""[01:30:21.648][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'webServerGracefulShutdown' completed its stop procedure
""[01:30:21.648][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase 2147483646
""[01:30:21.649][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=183): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1256273455, responses=[])
""[01:30:21.649][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1256273455 with 0 response partition(s), 1 implied partition(s)
""[01:30:21.649][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:21.650][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Built incremental fetch (sessionId=1256273455, epoch=150) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:30:21.650][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:30:21.650][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-6, correlationId=185) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1256273455, sessionEpoch=150, topics=[], forgottenTopicsData=[], rackId='')
""[01:30:21.659][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - About to unlock socket for:/[0:0:0:0:0:0:0:1]:8080
""[01:30:21.659][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - Socket unlock completed for:/[0:0:0:0:0:0:0:1]:8080
""[01:30:21.660][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:30:21.660][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Unregister host [localhost] at domain [null] for service [StandardService[Tomcat]]
""[01:30:21.660][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Unregister Context [] for service [StandardService[Tomcat]]
""[01:30:21.660][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Unregister Wrapper [dispatcherServlet] in Context [] for service [StandardService[Tomcat]]
""[01:30:21.660][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Stopping filters
""[01:30:21.660][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Stopping filter 'Tomcat WebSocket (JSR356) Filter'
""[01:30:21.660][DEBUG][org.apache.catalina.core.ApplicationFilterConfig.log:line173] - JMX de-registration complete for filter of type [org.apache.tomcat.websocket.server.WsFilter] and name [Tomcat WebSocket (JSR356) Filter]
""[01:30:21.660][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Stopping filter 'characterEncodingFilter'
""[01:30:21.661][DEBUG][org.apache.catalina.core.ApplicationFilterConfig.log:line173] - JMX de-registration complete for filter of type [org.springframework.boot.web.servlet.filter.OrderedCharacterEncodingFilter] and name [characterEncodingFilter]
""[01:30:21.661][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Stopping
""[01:30:21.661][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Unloading persisted sessions
""[01:30:21.661][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - No persisted sessions to unload
""[01:30:21.661][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Sending application stop events
""[01:30:21.662][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Processing standard container shutdown
""[01:30:21.662][DEBUG][org.apache.catalina.loader.WebappLoader.log:line173] - Stopping this Loader
""[01:30:21.662][DEBUG][org.apache.catalina.loader.WebappClassLoaderBase.log:line173] - getResourceAsStream(org/apache/catalina/loader/JdbcLeakPrevention.class)
""[01:30:21.662][DEBUG][org.apache.catalina.loader.WebappClassLoaderBase.log:line173] -   Delegating to parent classloader org.springframework.boot.devtools.restart.classloader.RestartClassLoader@728e905a
""[01:30:21.663][DEBUG][org.apache.catalina.loader.WebappClassLoaderBase.log:line173] -   --> Returning stream from parent
""[01:30:21.664][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - resetContext Tomcat:j2eeType=WebModule,name=//localhost/,J2EEApplication=none,J2EEServer=none
""[01:30:21.665][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Stopping complete
""[01:30:21.665][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - Destroy initiated for 0.0.0.0/0.0.0.0:8080
""[01:30:21.666][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - Destroy completed for 0.0.0.0/0.0.0.0:8080
""[01:30:21.666][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'webServerStartStop' completed its stop procedure
""[01:30:21.666][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase 2147483547
""[01:30:21.666][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.wakeup:line189] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received user wakeup
""[01:30:21.666][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup:line512] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Raising WakeupException in response to user wakeup
""[01:30:21.667][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:30:21.667][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onLeavePrepare:line773] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Executing onLeavePrepare with generation Generation{generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', protocol='range'} and memberId consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f
""[01:30:21.667][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:30:21.667][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:30:21.667][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:30:21.667][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Member consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:30:21.667][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Sending LEAVE_GROUP request with header RequestHeader(apiKey=LEAVE_GROUP, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=186) and timeout 30000 to node 2147482646: LeaveGroupRequestData(groupId='my-consumer-group', memberId='', members=[MemberIdentity(memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null)])
""[01:30:21.667][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:30:21.667][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:30:21.667][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:30:21.668][DEBUG][org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler.shutdown:line224] - Shutting down ExecutorService
""[01:30:21.668][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.run:line1470] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Heartbeat thread has closed
""[01:30:21.668][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onLeavePrepare:line773] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Executing onLeavePrepare with generation Generation{generationId=-1, memberId='', protocol='null'} and memberId 
""[01:30:21.668][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:30:21.668][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:30:21.673][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Received LEAVE_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=LEAVE_GROUP, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=186): LeaveGroupResponseData(throttleTimeMs=0, errorCode=0, members=[MemberResponse(memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null, errorCode=0)])
""[01:30:21.674][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1095] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] LeaveGroup response with Generation{generationId=54, memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', protocol='range'} returned successfully: ClientResponse(receivedTimeMs=1692289821673, latencyMs=6, disconnected=false, requestHeader=RequestHeader(apiKey=LEAVE_GROUP, apiVersion=4, clientId=consumer-my-consumer-group-6, correlationId=186), responseBody=LeaveGroupResponseData(throttleTimeMs=0, errorCode=0, members=[MemberResponse(memberId='consumer-my-consumer-group-6-c44c6cec-53b9-4e11-9509-31324f2ee63f', groupInstanceId=null, errorCode=0)]))
""[01:30:21.674][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:30:21.674][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:30:21.674][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:30:21.675][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-6 unregistered
""[01:30:21.675][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer.close:line2403] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Kafka consumer has been closed
""[01:30:21.675][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:30:21.676][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - KafkaMessageListenerContainer [id=org.springframework.kafka.KafkaListenerEndpointContainer#0-0, clientIndex=-0, topicPartitions=[]] stopped normally
""[01:30:21.676][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry' completed its stop procedure
""[01:30:21.676][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase -2147483647
""[01:30:21.676][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'springBootLoggingLifecycle' completed its stop procedure
""[01:30:21.677][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.destroy:line452] - Unregistering JMX-exposed beans on shutdown
""[01:30:21.677][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.unregisterBeans:line186] - Unregistering JMX-exposed beans
""[01:30:21.677][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:30:21.677][DEBUG][org.hibernate.internal.SessionFactoryImpl.close:line821] - HHH000031: Closing
""[01:30:21.677][DEBUG][org.hibernate.type.spi.TypeConfiguration$Scope.unsetSessionFactory:line345] - Un-scoping TypeConfiguration [org.hibernate.type.spi.TypeConfiguration$Scope@2cf382f8] from SessionFactory [org.hibernate.internal.SessionFactoryImpl@7c2c5b5a]
""[01:30:21.677][DEBUG][org.hibernate.service.internal.AbstractServiceRegistryImpl.deRegisterChild:line428] - Implicitly destroying ServiceRegistry on de-registration of all child ServiceRegistries
""[01:30:21.677][DEBUG][org.hibernate.boot.registry.internal.BootstrapServiceRegistryImpl.deRegisterChild:line295] - Implicitly destroying Boot-strap registry on de-registration of all child ServiceRegistries
""[01:30:21.678][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-6 - Shutdown initiated...
""[01:30:21.678][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-6 - Before shutdown stats (total=10, active=0, idle=10, waiting=0)
""[01:30:21.678][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-6 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@641eaf39: (connection evicted)
""[01:30:21.678][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-6 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@bb7f70b: (connection evicted)
""[01:30:21.679][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-6 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@4a8afd30: (connection evicted)
""[01:30:21.679][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-6 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@7b0ad257: (connection evicted)
""[01:30:21.680][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-6 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@2aa5027f: (connection evicted)
""[01:30:21.680][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-6 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@433dd201: (connection evicted)
""[01:30:21.680][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-6 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@2eeb5c73: (connection evicted)
""[01:30:21.680][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-6 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@2ca30ce9: (connection evicted)
""[01:30:21.680][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-6 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@c7f534a: (connection evicted)
""[01:30:21.680][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-6 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@226ee066: (connection evicted)
""[01:30:21.681][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-6 - After shutdown stats (total=0, active=0, idle=0, waiting=0)
""[01:30:21.681][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-6 - Shutdown completed.
""[01:41:56.667][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 28464 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:41:56.668][DEBUG][com.jinseong.demo.Application.logStarting:line56] - Running with Spring Boot v2.7.15-SNAPSHOT, Spring v5.3.29
""[01:41:56.669][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:41:56.670][DEBUG][org.springframework.boot.SpringApplication.load:line664] - Loading source class com.jinseong.demo.Application
""[01:41:56.717][DEBUG][org.springframework.boot.devtools.restart.ChangeableUrls.logTo:line252] - Matching URLs for reloading : [file:/C:/Users/jinsung/Documents/GitHub/RMS/demo/target/classes/]
""[01:41:56.717][DEBUG][org.springframework.boot.devtools.settings.DevToolsSettings.logTo:line252] - Included patterns for restart : []
""[01:41:56.717][DEBUG][org.springframework.boot.devtools.settings.DevToolsSettings.logTo:line252] - Excluded patterns for restart : [/spring-boot-starter-[\w-]+/, /spring-boot/(bin|build|out)/, /spring-boot-starter/(bin|build|out)/, /spring-boot-devtools/(bin|build|out)/, /spring-boot-actuator/(bin|build|out)/, /spring-boot-autoconfigure/(bin|build|out)/]
""[01:41:56.717][INFO ][org.springframework.boot.devtools.env.DevToolsPropertyDefaultsPostProcessor.logTo:line255] - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
""[01:41:56.718][INFO ][org.springframework.boot.devtools.env.DevToolsPropertyDefaultsPostProcessor.logTo:line255] - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
""[01:41:56.718][DEBUG][org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext.prepareRefresh:line629] - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@797c8eb9
""[01:41:56.740][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor'
""[01:41:56.754][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory'
""[01:41:56.816][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\config\WebConfig.class]
""[01:41:56.819][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\config\WebSocketConfig.class]
""[01:41:56.824][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\controller\MainController.class]
""[01:41:56.828][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\handler\SocketHandler.class]
""[01:41:56.830][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line441] - Ignored because not a concrete top-level class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\repository\ReservationRepository.class]
""[01:41:56.836][DEBUG][org.springframework.context.annotation.ClassPathBeanDefinitionScanner.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\service\KafkaConsumerService.class]
""[01:41:56.980][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:41:56.981][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:41:56.982][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:41:56.983][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  1, name=org.springframework.boot:type=Admin,name=SpringApplication, attribute=Ready
""[01:41:56.990][DEBUG][sun.rmi.server.call.log:line236] - RMI TCP Connection(2)-127.0.0.1: [127.0.0.1] exception: 
"javax.management.InstanceNotFoundException: org.springframework.boot:type=Admin,name=SpringApplication
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1088)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:640)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1449)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1310)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1405)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:639)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at java.rmi/sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:360)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:200)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.rmi/sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:587)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:828)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:705)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:704)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
"[01:41:57.371][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:41:57.380][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.AutoConfigurationPackages'
""[01:41:57.380][DEBUG][org.springframework.boot.autoconfigure.AutoConfigurationPackages.get:line196] - @EnableAutoConfiguration was declared on a class in the package 'com.jinseong.demo'. Automatic @Repository and @Entity scanning is enabled.
""[01:41:57.381][DEBUG][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line145] - Scanning for JPA repositories in packages com.jinseong.demo.
""[01:41:57.396][DEBUG][org.springframework.data.repository.config.RepositoryComponentProvider.scanCandidateComponents:line435] - Identified candidate component class: file [C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes\com\jinseong\demo\repository\ReservationRepository.class]
""[01:41:57.433][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 50 ms. Found 1 JPA repository interfaces.
""[01:41:57.498][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:41:57.498][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:41:57.499][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:41:57.500][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  1, name=org.springframework.boot:type=Admin,name=SpringApplication, attribute=Ready
""[01:41:57.500][DEBUG][sun.rmi.server.call.log:line236] - RMI TCP Connection(2)-127.0.0.1: [127.0.0.1] exception: 
"javax.management.InstanceNotFoundException: org.springframework.boot:type=Admin,name=SpringApplication
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1088)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:640)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1449)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1310)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1405)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:639)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at java.rmi/sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:360)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:200)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.rmi/sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:587)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:828)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:705)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:704)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
"[01:41:57.630][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'propertySourcesPlaceholderConfigurer'
""[01:41:57.636][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'emBeanDefinitionRegistrarPostProcessor'
""[01:41:57.637][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor'
""[01:41:57.637][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.DevToolsDataSourceAutoConfiguration$DatabaseShutdownExecutorEntityManagerFactoryDependsOnPostProcessor'
""[01:41:57.669][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerProcessor'
""[01:41:57.671][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'preserveErrorControllerTargetClassPostProcessor'
""[01:41:57.672][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerFactory'
""[01:41:57.672][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.transaction.config.internalTransactionalEventListenerFactory'
""[01:41:57.675][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor'
""[01:41:57.677][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor'
""[01:41:57.680][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalPersistenceAnnotationProcessor'
""[01:41:57.681][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor'
""[01:41:57.681][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.internalConfigurationPropertiesBinder'
""[01:41:57.681][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.internalConfigurationPropertiesBinderFactory'
""[01:41:57.684][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.aop.config.internalAutoProxyCreator'
""[01:41:57.717][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'persistenceExceptionTranslationPostProcessor'
""[01:41:57.729][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'persistenceExceptionTranslationPostProcessor' via factory method to bean named 'environment'
""[01:41:57.733][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor'
""[01:41:57.741][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webServerFactoryCustomizerBeanPostProcessor'
""[01:41:57.741][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'errorPageRegistrarBeanPostProcessor'
""[01:41:57.741][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'projectingArgumentResolverBeanPostProcessor'
""[01:41:57.743][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.transaction.config.internalTransactionAdvisor'
""[01:41:57.743][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration'
""[01:41:57.756][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionAttributeSource'
""[01:41:57.761][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionInterceptor'
""[01:41:57.762][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'transactionInterceptor' via factory method to bean named 'transactionAttributeSource'
""[01:41:57.771][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.transaction.config.internalTransactionAdvisor' via factory method to bean named 'transactionAttributeSource'
""[01:41:57.771][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.transaction.config.internalTransactionAdvisor' via factory method to bean named 'transactionInterceptor'
""[01:41:57.800][DEBUG][org.springframework.ui.context.support.UiApplicationContextUtils.initThemeSource:line85] - Unable to locate ThemeSource with name 'themeSource': using default [org.springframework.ui.context.support.ResourceBundleThemeSource@7261bc7]
""[01:41:57.800][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'tomcatServletWebServerFactory'
""[01:41:57.801][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryConfiguration$EmbeddedTomcat'
""[01:41:57.858][DEBUG][org.apache.catalina.core.AprLifecycleListener.log:line175] - The Apache Tomcat Native library could not be found using names [tcnative-2, libtcnative-2, tcnative-1, libtcnative-1] on the java.library.path [C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;.]. The errors reported were [Can't load library: C:\Users\jinsung\Documents\GitHub\RMS\demo\bin\tcnative-2.dll, Can't load library: C:\Users\jinsung\Documents\GitHub\RMS\demo\bin\libtcnative-2.dll, Can't load library: C:\Users\jinsung\Documents\GitHub\RMS\demo\bin\tcnative-1.dll, Can't load library: C:\Users\jinsung\Documents\GitHub\RMS\demo\bin\libtcnative-1.dll, no tcnative-2 in java.library.path: C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;., no libtcnative-2 in java.library.path: C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;., no tcnative-1 in java.library.path: C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;., no libtcnative-1 in java.library.path: C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;.]
"org.apache.tomcat.jni.LibraryNotFoundError: Can't load library: C:\Users\jinsung\Documents\GitHub\RMS\demo\bin\tcnative-2.dll, Can't load library: C:\Users\jinsung\Documents\GitHub\RMS\demo\bin\libtcnative-2.dll, Can't load library: C:\Users\jinsung\Documents\GitHub\RMS\demo\bin\tcnative-1.dll, Can't load library: C:\Users\jinsung\Documents\GitHub\RMS\demo\bin\libtcnative-1.dll, no tcnative-2 in java.library.path: C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;., no libtcnative-2 in java.library.path: C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;., no tcnative-1 in java.library.path: C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;., no libtcnative-1 in java.library.path: C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;.
	at org.apache.tomcat.jni.Library.<init>(Library.java:91)
	at org.apache.tomcat.jni.Library.initialize(Library.java:232)
	at org.apache.catalina.core.AprLifecycleListener.init(AprLifecycleListener.java:194)
	at org.apache.catalina.core.AprLifecycleListener.isAprAvailable(AprLifecycleListener.java:107)
	at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getDefaultServerLifecycleListeners(TomcatServletWebServerFactory.java:182)
	at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.<init>(TomcatServletWebServerFactory.java:129)
	at org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryConfiguration$EmbeddedTomcat.tomcatServletWebServerFactory(ServletWebServerFactoryConfiguration.java:76)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:638)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1352)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1195)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:213)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getWebServerFactory(ServletWebServerApplicationContext.java:219)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:182)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:162)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:577)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:731)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1303)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1292)
	at com.jinseong.demo.Application.main(Application.java:10)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:50)
"[01:41:57.873][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'websocketServletWebServerCustomizer'
""[01:41:57.873][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration'
""[01:41:57.874][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'servletWebServerFactoryCustomizer'
""[01:41:57.875][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration'
""[01:41:57.876][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:41:57.884][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.BoundConfigurationProperties'
""[01:41:57.906][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'servletWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:41:57.907][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'tomcatServletWebServerFactoryCustomizer'
""[01:41:57.908][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'tomcatServletWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:41:57.908][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'tomcatWebServerFactoryCustomizer'
""[01:41:57.909][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration$TomcatWebServerFactoryCustomizerConfiguration'
""[01:41:57.910][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'tomcatWebServerFactoryCustomizer' via factory method to bean named 'environment'
""[01:41:57.910][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'tomcatWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:41:57.911][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'localeCharsetMappingsCustomizer'
""[01:41:57.912][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration'
""[01:41:57.913][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:41:57.932][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'errorPageCustomizer'
""[01:41:57.932][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration'
""[01:41:57.933][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
""[01:41:57.934][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dispatcherServletRegistration'
""[01:41:57.934][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration$DispatcherServletRegistrationConfiguration'
""[01:41:57.934][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dispatcherServlet'
""[01:41:57.935][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration$DispatcherServletConfiguration'
""[01:41:57.936][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
""[01:41:57.939][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dispatcherServlet' via factory method to bean named 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
""[01:41:57.953][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dispatcherServletRegistration' via factory method to bean named 'dispatcherServlet'
""[01:41:57.954][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dispatcherServletRegistration' via factory method to bean named 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
""[01:41:57.955][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'multipartConfigElement'
""[01:41:57.955][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration'
""[01:41:57.956][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.servlet.multipart-org.springframework.boot.autoconfigure.web.servlet.MultipartProperties'
""[01:41:57.960][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration' via constructor to bean named 'spring.servlet.multipart-org.springframework.boot.autoconfigure.web.servlet.MultipartProperties'
""[01:41:57.965][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'errorPageCustomizer' via factory method to bean named 'dispatcherServletRegistration'
""[01:41:57.984][DEBUG][org.apache.tomcat.util.compat.Jre19Compat.log:line175] - Class not found so assuming code is running on a pre-Java 19 JVM
"java.lang.ClassNotFoundException: java.lang.WrongThreadException
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520)
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:375)
	at org.apache.tomcat.util.compat.Jre19Compat.<clinit>(Jre19Compat.java:37)
	at org.apache.tomcat.util.compat.JreCompat.<clinit>(JreCompat.java:73)
	at org.apache.catalina.startup.Tomcat.<clinit>(Tomcat.java:1299)
	at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:194)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:184)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:162)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:577)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:731)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1303)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1292)
	at com.jinseong.demo.Application.main(Application.java:10)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:50)
"[01:41:57.985][DEBUG][org.apache.tomcat.util.compat.Jre21Compat.log:line175] - Class not found so assuming code is running on a pre-Java 21 JVM
"java.lang.ClassNotFoundException: java.lang.Thread$Builder
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520)
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:375)
	at org.apache.tomcat.util.compat.Jre21Compat.<clinit>(Jre21Compat.java:43)
	at org.apache.tomcat.util.compat.JreCompat.<clinit>(JreCompat.java:73)
	at org.apache.catalina.startup.Tomcat.<clinit>(Tomcat.java:1299)
	at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:194)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:184)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:162)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:577)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:731)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1303)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1292)
	at com.jinseong.demo.Application.main(Application.java:10)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:50)
"[01:41:58.034][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol port=8080)
""[01:41:58.041][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol bindOnInit=false)
""[01:41:58.042][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.tomcat.util.net.NioEndpoint bindOnInit=false)
""[01:41:58.044][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol maxPostSize=2097152)
""[01:41:58.045][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.tomcat.util.net.NioEndpoint maxPostSize=2097152)
""[01:41:58.053][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:41:58.053][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:41:58.054][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:41:58.054][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  1, name=org.springframework.boot:type=Admin,name=SpringApplication, attribute=Ready
""[01:41:58.054][DEBUG][sun.rmi.server.call.log:line236] - RMI TCP Connection(2)-127.0.0.1: [127.0.0.1] exception: 
"javax.management.InstanceNotFoundException: org.springframework.boot:type=Admin,name=SpringApplication
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1088)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:640)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1449)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1310)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1405)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:639)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at java.rmi/sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:360)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:200)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.rmi/sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:587)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:828)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:705)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:704)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
"[01:41:58.057][DEBUG][org.apache.catalina.core.ContainerBase.log:line173] - Add child StandardHost[localhost] StandardEngine[Tomcat]
""[01:41:58.058][DEBUG][org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getArchiveFileDocumentRoot:line81] - Code archive: C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot\2.7.15-SNAPSHOT\spring-boot-2.7.15-SNAPSHOT.jar
""[01:41:58.058][DEBUG][org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getExplodedWarFileDocumentRoot:line125] - Code archive: C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot\2.7.15-SNAPSHOT\spring-boot-2.7.15-SNAPSHOT.jar
""[01:41:58.059][DEBUG][org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.logNoDocumentRoots:line149] - None of the document roots [src/main/webapp, public, static] point to a directory and will be ignored.
""[01:41:58.077][DEBUG][org.apache.catalina.core.ContainerBase.log:line173] - Add child TomcatEmbeddedContext[] StandardEngine[Tomcat].StandardHost[localhost]
""[01:41:58.136][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:41:58.144][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.coyote.http11.Http11NioProtocol parseBodyMethods=POST)
""[01:41:58.145][DEBUG][org.apache.tomcat.util.IntrospectionUtils.log:line173] - IntrospectionUtils: setProperty(class org.apache.tomcat.util.net.NioEndpoint parseBodyMethods=POST)
""[01:41:58.146][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:41:58.147][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:41:58.150][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Starting ROOT
""[01:41:58.159][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Configuring default Resources
""[01:41:58.214][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Processing standard container startup
""[01:41:58.214][DEBUG][org.apache.catalina.loader.WebappLoader.log:line173] - Starting this Loader
""[01:41:58.269][DEBUG][org.apache.catalina.authenticator.AuthenticatorBase.log:line173] - No SingleSignOn Valve is present
""[01:41:58.276][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:41:58.276][DEBUG][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line286] - Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
""[01:41:58.276][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 1558 ms
""[01:41:58.282][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'characterEncodingFilter'
""[01:41:58.290][DEBUG][org.springframework.boot.web.servlet.ServletContextInitializerBeans.logMappings:line237] - Mapping filters: characterEncodingFilter urls=[/*] order=-2147483648
""[01:41:58.290][DEBUG][org.springframework.boot.web.servlet.ServletContextInitializerBeans.logMappings:line237] - Mapping servlets: dispatcherServlet urls=[/]
""[01:41:58.292][DEBUG][org.apache.catalina.core.ContainerBase.log:line173] - Add child StandardWrapper[dispatcherServlet] StandardEngine[Tomcat].StandardHost[localhost].TomcatEmbeddedContext[]
""[01:41:58.312][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Configuring application event listeners
""[01:41:58.312][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Sending application start events
""[01:41:58.314][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Start: Loading persisted sessions
""[01:41:58.315][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Loading persisted sessions from [C:\Users\jinsung\AppData\Local\Temp\8B19C3BAB13401F8F1E8E8FA5BBF4BD1C70DE7CC\servlet-sessions\SESSIONS.ser]
""[01:41:58.315][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - No persisted data file found
""[01:41:58.315][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Starting filters
""[01:41:58.315][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Starting filter 'Tomcat WebSocket (JSR356) Filter'
""[01:41:58.317][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Starting filter 'characterEncodingFilter'
""[01:41:58.319][DEBUG][org.springframework.boot.web.servlet.filter.OrderedCharacterEncodingFilter.init:line242] - Filter 'characterEncodingFilter' configured for use
""[01:41:58.319][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Starting completed
""[01:41:58.321][DEBUG][org.apache.catalina.mapper.Mapper.log:line173] - Registered host [localhost]
""[01:41:58.322][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Register Wrapper [dispatcherServlet] in Context [] for service [StandardService[Tomcat]]
""[01:41:58.322][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Register Context [] for service [StandardService[Tomcat]]
""[01:41:58.322][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Register host [localhost] at domain [null] for service [StandardService[Tomcat]]
""[01:41:58.327][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dataSourceScriptDatabaseInitializer'
""[01:41:58.327][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.sql.init.DataSourceInitializationConfiguration'
""[01:41:58.328][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'dataSource'
""[01:41:58.328][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration$Hikari'
""[01:41:58.329][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
""[01:41:58.336][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dataSource' via factory method to bean named 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
""[01:41:58.340][DEBUG][com.zaxxer.hikari.HikariConfig.attemptFromContextLoader:line971] - Driver class com.mysql.cj.jdbc.Driver found in Thread context class loader org.springframework.boot.devtools.restart.classloader.RestartClassLoader@739e3cbf
""[01:41:58.356][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.sql.init-org.springframework.boot.autoconfigure.sql.init.SqlInitializationProperties'
""[01:41:58.358][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dataSourceScriptDatabaseInitializer' via factory method to bean named 'dataSource'
""[01:41:58.358][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'dataSourceScriptDatabaseInitializer' via factory method to bean named 'spring.sql.init-org.springframework.boot.autoconfigure.sql.init.SqlInitializationProperties'
""[01:41:58.362][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'inMemoryDatabaseShutdownExecutor'
""[01:41:58.362][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.DevToolsDataSourceAutoConfiguration'
""[01:41:58.363][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'inMemoryDatabaseShutdownExecutor' via factory method to bean named 'dataSource'
""[01:41:58.363][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'inMemoryDatabaseShutdownExecutor' via factory method to bean named 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
""[01:41:58.364][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'entityManagerFactory'
""[01:41:58.364][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration'
""[01:41:58.365][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jpa-org.springframework.boot.autoconfigure.orm.jpa.JpaProperties'
""[01:41:58.368][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jpa.hibernate-org.springframework.boot.autoconfigure.orm.jpa.HibernateProperties'
""[01:41:58.370][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'dataSource'
""[01:41:58.370][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'spring.jpa-org.springframework.boot.autoconfigure.orm.jpa.JpaProperties'
""[01:41:58.370][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@7a9bf677'
""[01:41:58.370][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration' via constructor to bean named 'spring.jpa.hibernate-org.springframework.boot.autoconfigure.orm.jpa.HibernateProperties'
""[01:41:58.372][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'hikariPoolDataSourceMetadataProvider'
""[01:41:58.372][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.metadata.DataSourcePoolMetadataProvidersConfiguration$HikariPoolDataSourceMetadataProviderConfiguration'
""[01:41:58.376][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'entityManagerFactoryBuilder'
""[01:41:58.377][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jpaVendorAdapter'
""[01:41:58.426][DEBUG][org.jboss.logging.logProvider:line152] - Logging Provider: org.jboss.logging.Log4j2LoggerProvider
""[01:41:58.429][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'entityManagerFactoryBuilder' via factory method to bean named 'jpaVendorAdapter'
""[01:41:58.431][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'entityManagerFactory' via factory method to bean named 'entityManagerFactoryBuilder'
""[01:41:58.441][DEBUG][org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection:line117] - Fetching JDBC Connection from DataSource
""[01:41:58.442][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1103] - HikariPool-1 - configuration:
""[01:41:58.444][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - allowPoolSuspension................................false
""[01:41:58.444][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - autoCommit................................true
""[01:41:58.445][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - catalog................................none
""[01:41:58.445][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - connectionInitSql................................none
""[01:41:58.445][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - connectionTestQuery................................none
""[01:41:58.445][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - connectionTimeout................................30000
""[01:41:58.445][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSource................................none
""[01:41:58.446][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSourceClassName................................none
""[01:41:58.446][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSourceJNDI................................none
""[01:41:58.446][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - dataSourceProperties................................{password=<masked>}
""[01:41:58.446][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - driverClassName................................"com.mysql.cj.jdbc.Driver"
""[01:41:58.446][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - exceptionOverrideClassName................................none
""[01:41:58.446][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - healthCheckProperties................................{}
""[01:41:58.447][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - healthCheckRegistry................................none
""[01:41:58.447][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - idleTimeout................................600000
""[01:41:58.450][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - initializationFailTimeout................................1
""[01:41:58.450][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - isolateInternalQueries................................false
""[01:41:58.450][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - jdbcUrl................................jdbc:mysql://localhost:3306/metadb?useSSL=false&serverTimezone=UTC&useLegacyDatetimeCode=false&allowPublicKeyRetrieval=true
""[01:41:58.450][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - keepaliveTime................................0
""[01:41:58.450][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - leakDetectionThreshold................................0
""[01:41:58.451][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - maxLifetime................................1800000
""[01:41:58.451][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - maximumPoolSize................................10
""[01:41:58.451][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - metricRegistry................................none
""[01:41:58.451][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - metricsTrackerFactory................................none
""[01:41:58.451][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - minimumIdle................................10
""[01:41:58.451][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - password................................<masked>
""[01:41:58.452][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - poolName................................"HikariPool-1"
""[01:41:58.452][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - readOnly................................false
""[01:41:58.452][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - registerMbeans................................false
""[01:41:58.452][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - scheduledExecutor................................none
""[01:41:58.452][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - schema................................none
""[01:41:58.452][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - threadFactory................................internal
""[01:41:58.452][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - transactionIsolation................................default
""[01:41:58.452][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - username................................"root"
""[01:41:58.453][DEBUG][com.zaxxer.hikari.HikariConfig.logConfiguration:line1135] - validationTimeout................................5000
""[01:41:58.453][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-1 - Starting...
""[01:41:58.556][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:41:58.556][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:41:58.557][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:41:58.557][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  1, name=org.springframework.boot:type=Admin,name=SpringApplication, attribute=Ready
""[01:41:58.557][DEBUG][sun.rmi.server.call.log:line236] - RMI TCP Connection(2)-127.0.0.1: [127.0.0.1] exception: 
"javax.management.InstanceNotFoundException: org.springframework.boot:type=Admin,name=SpringApplication
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1088)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:640)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1449)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1310)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1405)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:639)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at java.rmi/sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:360)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:200)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.rmi/sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:587)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:828)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:705)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:704)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
"[01:41:58.607][DEBUG][com.zaxxer.hikari.pool.HikariPool.checkFailFast:line565] - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@e418f5c
""[01:41:58.608][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-1 - Start completed.
""[01:41:58.644][DEBUG][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory:line361] - Building JPA container EntityManagerFactory for persistence unit 'default'
""[01:41:58.661][DEBUG][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line102] - PersistenceUnitInfo [
	name: default
	persistence provider classname: null
	classloader: org.springframework.boot.devtools.restart.classloader.RestartClassLoader@739e3cbf
	excludeUnlistedClasses: true
	JTA datasource: null
	Non JTA datasource: HikariDataSource (HikariPool-1)
	Transaction type: RESOURCE_LOCAL
	PU root URL: file:/C:/Users/jinsung/Documents/GitHub/RMS/demo/target/classes/
	Shared Cache Mode: UNSPECIFIED
	Validation Mode: AUTO
	Jar files URLs []
	Managed classes names [
		com.jinseong.demo.entity.Reservation]
	Mapping files names []
	Properties []
""[01:41:58.673][DEBUG][org.hibernate.integrator.internal.IntegratorServiceImpl.addIntegrator:line46] - Adding Integrator [org.hibernate.cfg.beanvalidation.BeanValidationIntegrator].
""[01:41:58.675][DEBUG][org.hibernate.integrator.internal.IntegratorServiceImpl.addIntegrator:line46] - Adding Integrator [org.hibernate.secure.spi.JaccIntegrator].
""[01:41:58.677][DEBUG][org.hibernate.integrator.internal.IntegratorServiceImpl.addIntegrator:line46] - Adding Integrator [org.hibernate.cache.internal.CollectionCacheInvalidator].
""[01:41:58.712][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-1 - Pool stats (total=1, active=0, idle=1, waiting=0)
""[01:41:58.722][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@5abc6c48
""[01:41:58.725][INFO ][org.hibernate.Version.logVersion:line44] - HHH000412: Hibernate ORM core version 5.6.15.Final
""[01:41:58.728][DEBUG][org.hibernate.cfg.Environment.<clinit>:line199] - HHH000206: hibernate.properties not found
""[01:41:58.732][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@1b816673
""[01:41:58.741][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@2a501b86
""[01:41:58.751][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@7bae993c
""[01:41:58.759][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@7dcf8bc6
""[01:41:58.769][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@7fe08623
""[01:41:58.779][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@2f96b8e3
""[01:41:58.787][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@2fb4fb3d
""[01:41:58.797][DEBUG][com.zaxxer.hikari.pool.HikariPool.call:line729] - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@69e7b6e
""[01:41:58.798][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-1 - After adding stats (total=10, active=0, idle=10, waiting=0)
""[01:41:58.889][DEBUG][org.hibernate.service.spi.ServiceBinding.setService:line68] - Overriding existing service binding [org.hibernate.secure.spi.JaccService]
""[01:41:58.902][DEBUG][org.hibernate.cache.internal.RegionFactoryInitiator.resolveRegionFactory:line118] - Cannot default RegionFactory based on registered strategies as `[]` RegionFactory strategies were registered
""[01:41:58.903][DEBUG][org.hibernate.cache.internal.RegionFactoryInitiator.initiateService:line49] - Cache region factory : org.hibernate.cache.internal.NoCachingRegionFactory
""[01:41:58.921][INFO ][org.hibernate.annotations.common.Version.<clinit>:line56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
""[01:41:58.957][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration boolean -> org.hibernate.type.BooleanType@1df2ea13
""[01:41:58.958][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration boolean -> org.hibernate.type.BooleanType@1df2ea13
""[01:41:58.958][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Boolean -> org.hibernate.type.BooleanType@1df2ea13
""[01:41:58.958][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration numeric_boolean -> org.hibernate.type.NumericBooleanType@2efdcaa6
""[01:41:58.959][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration true_false -> org.hibernate.type.TrueFalseType@66a8f362
""[01:41:58.959][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration yes_no -> org.hibernate.type.YesNoType@2eb67e05
""[01:41:58.960][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration byte -> org.hibernate.type.ByteType@6566a20c
""[01:41:58.961][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration byte -> org.hibernate.type.ByteType@6566a20c
""[01:41:58.961][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Byte -> org.hibernate.type.ByteType@6566a20c
""[01:41:58.962][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration character -> org.hibernate.type.CharacterType@55c25c10
""[01:41:58.962][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration char -> org.hibernate.type.CharacterType@55c25c10
""[01:41:58.962][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Character -> org.hibernate.type.CharacterType@55c25c10
""[01:41:58.963][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration short -> org.hibernate.type.ShortType@2361a14e
""[01:41:58.964][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration short -> org.hibernate.type.ShortType@2361a14e
""[01:41:58.964][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Short -> org.hibernate.type.ShortType@2361a14e
""[01:41:58.966][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration integer -> org.hibernate.type.IntegerType@7ed467bd
""[01:41:58.966][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration int -> org.hibernate.type.IntegerType@7ed467bd
""[01:41:58.966][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Integer -> org.hibernate.type.IntegerType@7ed467bd
""[01:41:58.967][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration long -> org.hibernate.type.LongType@614d2fae
""[01:41:58.967][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration long -> org.hibernate.type.LongType@614d2fae
""[01:41:58.967][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Long -> org.hibernate.type.LongType@614d2fae
""[01:41:58.968][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration float -> org.hibernate.type.FloatType@d21d12
""[01:41:58.968][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration float -> org.hibernate.type.FloatType@d21d12
""[01:41:58.968][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Float -> org.hibernate.type.FloatType@d21d12
""[01:41:58.969][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration double -> org.hibernate.type.DoubleType@426b0ddc
""[01:41:58.969][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration double -> org.hibernate.type.DoubleType@426b0ddc
""[01:41:58.969][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Double -> org.hibernate.type.DoubleType@426b0ddc
""[01:41:58.970][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration big_decimal -> org.hibernate.type.BigDecimalType@510f345
""[01:41:58.970][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.math.BigDecimal -> org.hibernate.type.BigDecimalType@510f345
""[01:41:58.971][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration big_integer -> org.hibernate.type.BigIntegerType@bd83c73
""[01:41:58.971][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.math.BigInteger -> org.hibernate.type.BigIntegerType@bd83c73
""[01:41:58.972][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration string -> org.hibernate.type.StringType@b89cdfb
""[01:41:58.972][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.String -> org.hibernate.type.StringType@b89cdfb
""[01:41:58.972][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration nstring -> org.hibernate.type.StringNVarcharType@1697baef
""[01:41:58.973][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration ncharacter -> org.hibernate.type.CharacterNCharType@7873b095
""[01:41:58.973][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration url -> org.hibernate.type.UrlType@3926a5e7
""[01:41:58.974][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.net.URL -> org.hibernate.type.UrlType@3926a5e7
""[01:41:58.974][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Duration -> org.hibernate.type.DurationType@31eb76f
""[01:41:58.974][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.Duration -> org.hibernate.type.DurationType@31eb76f
""[01:41:58.975][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Instant -> org.hibernate.type.InstantType@550c7df1
""[01:41:58.976][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.Instant -> org.hibernate.type.InstantType@550c7df1
""[01:41:58.976][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration LocalDateTime -> org.hibernate.type.LocalDateTimeType@c693633
""[01:41:58.977][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.LocalDateTime -> org.hibernate.type.LocalDateTimeType@c693633
""[01:41:58.977][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration LocalDate -> org.hibernate.type.LocalDateType@20596ce2
""[01:41:58.978][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.LocalDate -> org.hibernate.type.LocalDateType@20596ce2
""[01:41:58.979][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration LocalTime -> org.hibernate.type.LocalTimeType@a2c06e4
""[01:41:58.979][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.LocalTime -> org.hibernate.type.LocalTimeType@a2c06e4
""[01:41:58.980][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration OffsetDateTime -> org.hibernate.type.OffsetDateTimeType@3c934520
""[01:41:58.980][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.OffsetDateTime -> org.hibernate.type.OffsetDateTimeType@3c934520
""[01:41:58.981][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration OffsetTime -> org.hibernate.type.OffsetTimeType@250740c
""[01:41:58.981][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.OffsetTime -> org.hibernate.type.OffsetTimeType@250740c
""[01:41:58.982][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration ZonedDateTime -> org.hibernate.type.ZonedDateTimeType@482d7e0f
""[01:41:58.982][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.time.ZonedDateTime -> org.hibernate.type.ZonedDateTimeType@482d7e0f
""[01:41:58.983][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration date -> org.hibernate.type.DateType@452fc760
""[01:41:58.984][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Date -> org.hibernate.type.DateType@452fc760
""[01:41:58.984][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration time -> org.hibernate.type.TimeType@7c562e2a
""[01:41:58.985][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Time -> org.hibernate.type.TimeType@7c562e2a
""[01:41:58.985][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration timestamp -> org.hibernate.type.TimestampType@5081493b
""[01:41:58.985][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Timestamp -> org.hibernate.type.TimestampType@5081493b
""[01:41:58.986][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Date -> org.hibernate.type.TimestampType@5081493b
""[01:41:58.986][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration dbtimestamp -> org.hibernate.type.DbTimestampType@ba88001
""[01:41:58.987][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration calendar -> org.hibernate.type.CalendarType@9519c25
""[01:41:58.987][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Calendar -> org.hibernate.type.CalendarType@9519c25
""[01:41:58.987][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.GregorianCalendar -> org.hibernate.type.CalendarType@9519c25
""[01:41:58.988][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration calendar_date -> org.hibernate.type.CalendarDateType@1577fb3f
""[01:41:58.989][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration calendar_time -> org.hibernate.type.CalendarTimeType@3eba65c4
""[01:41:58.989][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration locale -> org.hibernate.type.LocaleType@151f0156
""[01:41:58.990][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Locale -> org.hibernate.type.LocaleType@151f0156
""[01:41:58.990][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration currency -> org.hibernate.type.CurrencyType@dffbaf9
""[01:41:58.990][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.Currency -> org.hibernate.type.CurrencyType@dffbaf9
""[01:41:58.991][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration timezone -> org.hibernate.type.TimeZoneType@331b418e
""[01:41:58.991][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.TimeZone -> org.hibernate.type.TimeZoneType@331b418e
""[01:41:58.992][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration class -> org.hibernate.type.ClassType@7baea92
""[01:41:58.992][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Class -> org.hibernate.type.ClassType@7baea92
""[01:41:58.993][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration uuid-binary -> org.hibernate.type.UUIDBinaryType@542f7827
""[01:41:58.993][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.util.UUID -> org.hibernate.type.UUIDBinaryType@542f7827
""[01:41:58.993][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration uuid-char -> org.hibernate.type.UUIDCharType@6b6f0227
""[01:41:58.994][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration binary -> org.hibernate.type.BinaryType@3fbf4d28
""[01:41:58.994][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration byte[] -> org.hibernate.type.BinaryType@3fbf4d28
""[01:41:58.994][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [B -> org.hibernate.type.BinaryType@3fbf4d28
""[01:41:58.995][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration wrapper-binary -> org.hibernate.type.WrapperBinaryType@ed7a1fa
""[01:41:58.996][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Byte[] -> org.hibernate.type.WrapperBinaryType@ed7a1fa
""[01:41:58.996][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [Ljava.lang.Byte; -> org.hibernate.type.WrapperBinaryType@ed7a1fa
""[01:41:58.997][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration row_version -> org.hibernate.type.RowVersionType@76bda8fa
""[01:41:58.997][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration image -> org.hibernate.type.ImageType@23e81d52
""[01:41:58.998][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration characters -> org.hibernate.type.CharArrayType@64a55d79
""[01:41:58.998][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration char[] -> org.hibernate.type.CharArrayType@64a55d79
""[01:41:58.998][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [C -> org.hibernate.type.CharArrayType@64a55d79
""[01:41:58.999][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration wrapper-characters -> org.hibernate.type.CharacterArrayType@5f66c678
""[01:41:58.999][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration [Ljava.lang.Character; -> org.hibernate.type.CharacterArrayType@5f66c678
""[01:41:58.999][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration Character[] -> org.hibernate.type.CharacterArrayType@5f66c678
""[01:41:58.999][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration text -> org.hibernate.type.TextType@2d7e6186
""[01:41:59.000][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration ntext -> org.hibernate.type.NTextType@447b45e7
""[01:41:59.001][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration blob -> org.hibernate.type.BlobType@10872aaa
""[01:41:59.001][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Blob -> org.hibernate.type.BlobType@10872aaa
""[01:41:59.001][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration materialized_blob -> org.hibernate.type.MaterializedBlobType@3cccee54
""[01:41:59.002][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration clob -> org.hibernate.type.ClobType@13c9471e
""[01:41:59.003][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.Clob -> org.hibernate.type.ClobType@13c9471e
""[01:41:59.004][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration nclob -> org.hibernate.type.NClobType@35df68f5
""[01:41:59.004][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.sql.NClob -> org.hibernate.type.NClobType@35df68f5
""[01:41:59.004][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration materialized_clob -> org.hibernate.type.MaterializedClobType@1c3c72bc
""[01:41:59.005][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration materialized_nclob -> org.hibernate.type.MaterializedNClobType@12443d54
""[01:41:59.006][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration serializable -> org.hibernate.type.SerializableType@1fba53c0
""[01:41:59.009][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration object -> org.hibernate.type.ObjectType@4fe2e99d
""[01:41:59.009][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration java.lang.Object -> org.hibernate.type.ObjectType@4fe2e99d
""[01:41:59.009][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_date -> org.hibernate.type.AdaptedImmutableType@4de7e608
""[01:41:59.009][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_time -> org.hibernate.type.AdaptedImmutableType@7743ff15
""[01:41:59.010][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_timestamp -> org.hibernate.type.AdaptedImmutableType@bcc8756
""[01:41:59.010][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_dbtimestamp -> org.hibernate.type.AdaptedImmutableType@141ba5f2
""[01:41:59.010][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_calendar -> org.hibernate.type.AdaptedImmutableType@663ed6df
""[01:41:59.011][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_calendar_date -> org.hibernate.type.AdaptedImmutableType@eed265a
""[01:41:59.011][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_binary -> org.hibernate.type.AdaptedImmutableType@6174f6e6
""[01:41:59.011][DEBUG][org.hibernate.type.BasicTypeRegistry.register:line157] - Adding type registration imm_serializable -> org.hibernate.type.AdaptedImmutableType@2889eb0f
""[01:41:59.025][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectJpaTempClassLoader:line259] - Injecting JPA temp ClassLoader [org.springframework.instrument.classloading.SimpleThrowawayClassLoader@5d61430e] into BootstrapContext; was [null]
""[01:41:59.025][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.injectTempClassLoader:line45] - ClassLoaderAccessImpl#injectTempClassLoader(org.springframework.instrument.classloading.SimpleThrowawayClassLoader@5d61430e) [was null]
""[01:41:59.025][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectScanEnvironment:line269] - Injecting ScanEnvironment [org.hibernate.jpa.boot.internal.StandardJpaScanEnvironmentImpl@4f9e6ace] into BootstrapContext; was [null]
""[01:41:59.026][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectScanOptions:line264] - Injecting ScanOptions [org.hibernate.boot.archive.scan.internal.StandardScanOptions@47d77e93] into BootstrapContext; was [org.hibernate.boot.archive.scan.internal.StandardScanOptions@4e20df04]
""[01:41:59.041][DEBUG][org.hibernate.boot.internal.BootstrapContextImpl.injectJpaTempClassLoader:line259] - Injecting JPA temp ClassLoader [null] into BootstrapContext; was [org.springframework.instrument.classloading.SimpleThrowawayClassLoader@5d61430e]
""[01:41:59.041][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.injectTempClassLoader:line45] - ClassLoaderAccessImpl#injectTempClassLoader(null) [was org.springframework.instrument.classloading.SimpleThrowawayClassLoader@5d61430e]
""[01:41:59.052][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [uuid2] -> [org.hibernate.id.UUIDGenerator]
""[01:41:59.052][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [guid] -> [org.hibernate.id.GUIDGenerator]
""[01:41:59.053][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [uuid] -> [org.hibernate.id.UUIDHexGenerator]
""[01:41:59.053][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [uuid.hex] -> [org.hibernate.id.UUIDHexGenerator]
""[01:41:59.054][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [assigned] -> [org.hibernate.id.Assigned]
""[01:41:59.055][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [identity] -> [org.hibernate.id.IdentityGenerator]
""[01:41:59.055][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [select] -> [org.hibernate.id.SelectGenerator]
""[01:41:59.056][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [sequence] -> [org.hibernate.id.enhanced.SequenceStyleGenerator]
""[01:41:59.057][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [seqhilo] -> [org.hibernate.id.SequenceHiLoGenerator]
""[01:41:59.058][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [increment] -> [org.hibernate.id.IncrementGenerator]
""[01:41:59.058][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [foreign] -> [org.hibernate.id.ForeignGenerator]
""[01:41:59.058][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [sequence-identity] -> [org.hibernate.id.SequenceIdentityGenerator]
""[01:41:59.059][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [enhanced-sequence] -> [org.hibernate.id.enhanced.SequenceStyleGenerator]
""[01:41:59.059][DEBUG][org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.register:line98] - Registering IdentifierGenerator strategy [enhanced-table] -> [org.hibernate.id.enhanced.TableGenerator]
""[01:41:59.065][DEBUG][org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.initiateService:line72] - Database ->
       name : MySQL
    version : 8.0.34
      major : 8
      minor : 0
""[01:41:59.065][DEBUG][org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.initiateService:line83] - Driver ->
       name : MySQL Connector/J
    version : mysql-connector-java-8.0.27 (Revision: e920b979015ae7117d60d72bcc8f077a839cd791)
      major : 8
      minor : 0
""[01:41:59.065][DEBUG][org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.debugf:line389] - JDBC version : 4.2
""[01:41:59.096][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:41:59.110][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:41:59.110][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:41:59.110][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:41:59.111][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  1, name=org.springframework.boot:type=Admin,name=SpringApplication, attribute=Ready
""[01:41:59.111][DEBUG][sun.rmi.server.call.log:line236] - RMI TCP Connection(2)-127.0.0.1: [127.0.0.1] exception: 
"javax.management.InstanceNotFoundException: org.springframework.boot:type=Admin,name=SpringApplication
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1088)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:640)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1449)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1310)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1405)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:639)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at java.rmi/sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:360)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:200)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.rmi/sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:587)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:828)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:705)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:704)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
"[01:41:59.112][DEBUG][org.hibernate.engine.jdbc.env.spi.IdentifierHelperBuilder.applyIdentifierCasing:line119] - JDBC driver metadata reported database stores quoted identifiers in more than one case
""[01:41:59.113][DEBUG][org.hibernate.engine.jdbc.env.spi.IdentifierHelperBuilder.build:line197] - IdentifierCaseStrategy for both quoted and unquoted identifiers was set to the same strategy [MIXED]; that will likely lead to problems in schema update and validation if using quoted identifiers
""[01:41:59.129][DEBUG][org.hibernate.type.spi.TypeConfiguration$Scope.scope:line149] - Scoping TypeConfiguration [org.hibernate.type.spi.TypeConfiguration@50a39a88] to MetadataBuildingContext [org.hibernate.boot.internal.MetadataBuildingContextRootImpl@d776f1f]
""[01:41:59.166][DEBUG][org.hibernate.boot.model.relational.Namespace.<init>:line51] - Created database namespace [logicalName=Name{catalog=null, schema=null}, physicalName=Name{catalog=null, schema=null}]
""[01:41:59.180][DEBUG][org.hibernate.cfg.AnnotationBinder.bindClass:line547] - Binding entity from annotated class: com.jinseong.demo.entity.Reservation
""[01:41:59.200][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3DiscriminatorColumn{logicalColumnName'DTYPE', discriminatorTypeName='string'}
""[01:41:59.206][DEBUG][org.hibernate.cfg.annotations.EntityBinder.bindEntity:line431] - Import with entity name Reservation
""[01:41:59.210][DEBUG][org.hibernate.cfg.annotations.EntityBinder.bindTable:line874] - Bind entity com.jinseong.demo.entity.Reservation on table reservation
""[01:41:59.229][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=reservation_id, insertable=true, updatable=true, unique=false}
""[01:41:59.232][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line60] - Not known whether passed class name [com.jinseong.demo.entity.Reservation] is safe
""[01:41:59.232][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line62] - No temp ClassLoader provided; using live ClassLoader for loading potentially unsafe class : com.jinseong.demo.entity.Reservation
""[01:41:59.233][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property id with lazy=false
""[01:41:59.234][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:id]
""[01:41:59.236][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for id
""[01:41:59.238][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property id
""[01:41:59.240][DEBUG][org.hibernate.cfg.BinderHelper.makeIdGenerator:line514] - #makeIdGenerator(org.hibernate.mapping.SimpleValue([org.hibernate.mapping.Column(reservation_id)]), id, identity, , ...)
""[01:41:59.242][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=count, insertable=true, updatable=true, unique=false}
""[01:41:59.242][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property count with lazy=false
""[01:41:59.242][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:count]
""[01:41:59.242][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for count
""[01:41:59.243][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property count
""[01:41:59.243][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=date, insertable=true, updatable=true, unique=false}
""[01:41:59.243][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property date with lazy=false
""[01:41:59.243][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:date]
""[01:41:59.243][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for date
""[01:41:59.244][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property date
""[01:41:59.244][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=name, insertable=true, updatable=true, unique=false}
""[01:41:59.244][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property name with lazy=false
""[01:41:59.244][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:name]
""[01:41:59.244][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for name
""[01:41:59.244][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property name
""[01:41:59.244][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=number, insertable=true, updatable=true, unique=false}
""[01:41:59.244][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property number with lazy=false
""[01:41:59.245][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:number]
""[01:41:59.245][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for number
""[01:41:59.245][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property number
""[01:41:59.245][DEBUG][org.hibernate.cfg.Ejb3Column.bind:line227] - Binding column: Ejb3Column{table=org.hibernate.mapping.Table(reservation), mappingColumn=time, insertable=true, updatable=true, unique=false}
""[01:41:59.245][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makePropertyAndValue:line175] - MetadataSourceProcessor property time with lazy=false
""[01:41:59.245][DEBUG][org.hibernate.cfg.AbstractPropertyHolder.resolveAttributeConverterDescriptor:line94] - Attempting to locate auto-apply AttributeConverter for property [com.jinseong.demo.entity.Reservation:time]
""[01:41:59.245][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.make:line410] - building SimpleValue for time
""[01:41:59.245][DEBUG][org.hibernate.cfg.annotations.PropertyBinder.makeProperty:line266] - Building property time
""[01:41:59.252][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for id
""[01:41:59.253][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for count
""[01:41:59.253][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for date
""[01:41:59.253][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for name
""[01:41:59.253][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for number
""[01:41:59.253][DEBUG][org.hibernate.cfg.annotations.SimpleValueBinder.fillSimpleValue:line455] - Starting fillSimpleValue for time
""[01:41:59.254][DEBUG][org.hibernate.mapping.PrimaryKey.addColumn:line36] - Forcing column [reservation_id] to be non-null as it is part of the primary key for table [reservation]
""[01:41:59.290][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line208] - Building session factory
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line68] - SessionFactory name : null
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line69] - Automatic flush during beforeCompletion(): enabled
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line70] - Automatic session close at end of transaction: disabled
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line72] - Statistics: disabled
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line74] - Deleted entity synthetic identifier rollback: disabled
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line75] - Default entity-mode: pojo
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line76] - Check Nullability in Core (should be disabled when Bean Validation is on): enabled
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line77] - Allow initialization of lazy state outside session : disabled
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line79] - Using BatchFetchStyle : LEGACY
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line80] - Default batch fetch size: -1
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line81] - Maximum outer join fetch depth: 2
""[01:41:59.291][DEBUG][org.hibernate.cfg.Settings.<init>:line82] - Default null ordering: NONE
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line83] - Order SQL updates by primary key: disabled
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line84] - Order SQL inserts for batching: disabled
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line86] - multi-tenancy strategy : NONE
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line88] - JTA Track by Thread: enabled
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line90] - Query language substitutions: {}
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line91] - Named query checking : enabled
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line93] - Second-level cache: disabled
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line94] - Second-level query cache: disabled
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line95] - Second-level query cache factory: null
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line96] - Second-level cache region prefix: null
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line97] - Optimize second-level cache for minimal puts: disabled
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line98] - Structured second-level cache entries: disabled
""[01:41:59.292][DEBUG][org.hibernate.cfg.Settings.<init>:line99] - Second-level cache direct-reference entries: disabled
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line100] - Automatic eviction of collection cache: disabled
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line102] - JDBC batch size: 15
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line103] - JDBC batch updates for versioned data: enabled
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line104] - Scrollable result sets: enabled
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line105] - Wrap result sets: disabled
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line106] - JDBC3 getGeneratedKeys(): enabled
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line107] - JDBC result set fetch size: null
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line108] - Connection release mode: ON_CLOSE
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line109] - Generate SQL with comments: disabled
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line111] - JPA compliance - query : disabled
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line112] - JPA compliance - closed-handling : disabled
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line113] - JPA compliance - lists : disabled
""[01:41:59.293][DEBUG][org.hibernate.cfg.Settings.<init>:line114] - JPA compliance - transactions : disabled
""[01:41:59.343][DEBUG][org.hibernate.service.internal.SessionFactoryServiceRegistryImpl.getService:line92] - EventListenerRegistry access via ServiceRegistry is deprecated.  Use `sessionFactory.getEventEngine().getListenerRegistry()` instead
""[01:41:59.343][DEBUG][org.hibernate.service.internal.SessionFactoryServiceRegistryImpl.getService:line92] - EventListenerRegistry access via ServiceRegistry is deprecated.  Use `sessionFactory.getEventEngine().getListenerRegistry()` instead
""[01:41:59.356][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line276] - Session factory constructed with filter configurations : {}
""[01:41:59.357][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line277] - Instantiating session factory with properties: {hibernate.id.new_generator_mappings=true, java.specification.version=17, sun.cpu.isalist=amd64, hibernate.resource.beans.container=org.springframework.orm.hibernate5.SpringBeanContainer@38bc5fa9, hibernate.connection.handling_mode=DELAYED_ACQUISITION_AND_HOLD, sun.jnu.encoding=MS949, hibernate.implicit_naming_strategy=org.springframework.boot.orm.jpa.hibernate.SpringImplicitNamingStrategy, java.class.path=C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-web\2.7.15-SNAPSHOT\spring-boot-starter-web-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter\2.7.15-SNAPSHOT\spring-boot-starter-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-logging\2.7.15-SNAPSHOT\spring-boot-starter-logging-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\ch\qos\logback\logback-classic\1.2.12\logback-classic-1.2.12.jar;C:\Users\jinsung\.m2\repository\ch\qos\logback\logback-core\1.2.12\logback-core-1.2.12.jar;C:\Users\jinsung\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.17.2\log4j-to-slf4j-2.17.2.jar;C:\Users\jinsung\.m2\repository\org\apache\logging\log4j\log4j-api\2.17.2\log4j-api-2.17.2.jar;C:\Users\jinsung\.m2\repository\org\slf4j\jul-to-slf4j\1.7.36\jul-to-slf4j-1.7.36.jar;C:\Users\jinsung\.m2\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;C:\Users\jinsung\.m2\repository\org\yaml\snakeyaml\1.30\snakeyaml-1.30.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-json\2.7.15-SNAPSHOT\spring-boot-starter-json-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.13.5\jackson-databind-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.13.5\jackson-annotations-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.13.5\jackson-core-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.13.5\jackson-datatype-jdk8-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.13.5\jackson-datatype-jsr310-2.13.5.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.13.5\jackson-module-parameter-names-2.13.5.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat\2.7.15-SNAPSHOT\spring-boot-starter-tomcat-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.78\tomcat-embed-core-9.0.78.jar;C:\Users\jinsung\.m2\repository\org\apache\tomcat\embed\tomcat-embed-el\9.0.78\tomcat-embed-el-9.0.78.jar;C:\Users\jinsung\.m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.78\tomcat-embed-websocket-9.0.78.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-web\5.3.29\spring-web-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-beans\5.3.29\spring-beans-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-webmvc\5.3.29\spring-webmvc-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-aop\5.3.29\spring-aop-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-expression\5.3.29\spring-expression-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-devtools\2.7.15-SNAPSHOT\spring-boot-devtools-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot\2.7.15-SNAPSHOT\spring-boot-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\2.7.15-SNAPSHOT\spring-boot-autoconfigure-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\projectlombok\lombok\1.18.28\lombok-1.18.28.jar;C:\Users\jinsung\.m2\repository\org\slf4j\slf4j-api\1.7.36\slf4j-api-1.7.36.jar;C:\Users\jinsung\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\2.3.3\jakarta.xml.bind-api-2.3.3.jar;C:\Users\jinsung\.m2\repository\jakarta\activation\jakarta.activation-api\1.2.2\jakarta.activation-api-1.2.2.jar;C:\Users\jinsung\.m2\repository\net\bytebuddy\byte-buddy\1.12.23\byte-buddy-1.12.23.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-core\5.3.29\spring-core-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-jcl\5.3.29\spring-jcl-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-thymeleaf\2.7.15-SNAPSHOT\spring-boot-starter-thymeleaf-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\thymeleaf\thymeleaf-spring5\3.0.15.RELEASE\thymeleaf-spring5-3.0.15.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\thymeleaf\thymeleaf\3.0.15.RELEASE\thymeleaf-3.0.15.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\attoparser\attoparser\2.0.5.RELEASE\attoparser-2.0.5.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\unbescape\unbescape\1.1.6.RELEASE\unbescape-1.1.6.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\thymeleaf\extras\thymeleaf-extras-java8time\3.0.4.RELEASE\thymeleaf-extras-java8time-3.0.4.RELEASE.jar;C:\Users\jinsung\.m2\repository\org\springframework\kafka\spring-kafka\2.8.11\spring-kafka-2.8.11.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-context\5.3.29\spring-context-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-messaging\5.3.29\spring-messaging-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-tx\5.3.29\spring-tx-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\retry\spring-retry\1.3.4\spring-retry-1.3.4.jar;C:\Users\jinsung\.m2\repository\org\apache\kafka\kafka-clients\3.1.2\kafka-clients-3.1.2.jar;C:\Users\jinsung\.m2\repository\com\github\luben\zstd-jni\1.5.0-4\zstd-jni-1.5.0-4.jar;C:\Users\jinsung\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\jinsung\.m2\repository\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\Users\jinsung\.m2\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-data-jpa\2.7.15-SNAPSHOT\spring-boot-starter-data-jpa-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-aop\2.7.15-SNAPSHOT\spring-boot-starter-aop-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\aspectj\aspectjweaver\1.9.7\aspectjweaver-1.9.7.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\2.7.15-SNAPSHOT\spring-boot-starter-jdbc-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\com\zaxxer\HikariCP\4.0.3\HikariCP-4.0.3.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-jdbc\5.3.29\spring-jdbc-5.3.29.jar;C:\Users\jinsung\.m2\repository\jakarta\transaction\jakarta.transaction-api\1.3.3\jakarta.transaction-api-1.3.3.jar;C:\Users\jinsung\.m2\repository\jakarta\persistence\jakarta.persistence-api\2.2.3\jakarta.persistence-api-2.2.3.jar;C:\Users\jinsung\.m2\repository\org\hibernate\hibernate-core\5.6.15.Final\hibernate-core-5.6.15.Final.jar;C:\Users\jinsung\.m2\repository\org\jboss\logging\jboss-logging\3.4.3.Final\jboss-logging-3.4.3.Final.jar;C:\Users\jinsung\.m2\repository\antlr\antlr\2.7.7\antlr-2.7.7.jar;C:\Users\jinsung\.m2\repository\org\jboss\jandex\2.4.2.Final\jandex-2.4.2.Final.jar;C:\Users\jinsung\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\jinsung\.m2\repository\org\hibernate\common\hibernate-commons-annotations\5.1.2.Final\hibernate-commons-annotations-5.1.2.Final.jar;C:\Users\jinsung\.m2\repository\org\glassfish\jaxb\jaxb-runtime\2.3.8\jaxb-runtime-2.3.8.jar;C:\Users\jinsung\.m2\repository\org\glassfish\jaxb\txw2\2.3.8\txw2-2.3.8.jar;C:\Users\jinsung\.m2\repository\com\sun\istack\istack-commons-runtime\3.0.12\istack-commons-runtime-3.0.12.jar;C:\Users\jinsung\.m2\repository\com\sun\activation\jakarta.activation\1.2.2\jakarta.activation-1.2.2.jar;C:\Users\jinsung\.m2\repository\org\springframework\data\spring-data-jpa\2.7.15-SNAPSHOT\spring-data-jpa-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\data\spring-data-commons\2.7.15-SNAPSHOT\spring-data-commons-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-orm\5.3.29\spring-orm-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-aspects\5.3.29\spring-aspects-5.3.29.jar;C:\Users\jinsung\.m2\repository\org\springframework\boot\spring-boot-starter-websocket\2.7.15-SNAPSHOT\spring-boot-starter-websocket-2.7.15-SNAPSHOT.jar;C:\Users\jinsung\.m2\repository\org\springframework\spring-websocket\5.3.29\spring-websocket-5.3.29.jar;C:\Users\jinsung\.m2\repository\mysql\mysql-connector-java\8.0.27\mysql-connector-java-8.0.27.jar;C:\Users\jinsung\.m2\repository\com\google\protobuf\protobuf-java\3.11.4\protobuf-java-3.11.4.jar, com.sun.management.jmxremote.authenticate=false, LOGBACK_ROLLINGPOLICY_FILE_NAME_PATTERN="C:/logging/shop/shop.%d{yyyy-MM-dd}.%i", java.vm.vendor=Eclipse Adoptium, sun.arch.data.model=64, user.variant=, java.vendor.url=https://adoptium.net/, catalina.useNaming=false, user.timezone=Asia/Seoul, jakarta.persistence.sharedCache.mode=UNSPECIFIED, java.vm.specification.version=17, os.name=Windows 10, javax.persistence.validation.mode=AUTO, jakarta.persistence.nonJtaDataSource=HikariDataSource (HikariPool-1), sun.java.launcher=SUN_STANDARD, user.country=KR, sun.boot.library.path=C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin, com.sun.management.jmxremote.ssl=false, sun.java.command=com.jinseong.demo.Application --spring.output.ansi.enabled=always, spring.application.admin.enabled=true, javax.persistence.nonJtaDataSource=HikariDataSource (HikariPool-1), hibernate.transaction.jta.platform=org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform@f122300, com.sun.management.jmxremote=, javax.persistence.sharedCache.mode=UNSPECIFIED, jdk.debug=release, sun.cpu.endian=little, spring.boot.project.name=demo, user.home=C:\Users\jinsung, user.language=ko, java.specification.vendor=Oracle Corporation, java.version.date=2023-01-17, java.home=C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre, file.separator=\, java.vm.compressedOopsMode=Zero based, line.separator=
, hibernate.persistenceUnitName=default, java.vm.specification.vendor=Oracle Corporation, java.specification.name=Java Platform API Specification, FILE_LOG_CHARSET=UTF-8, hibernate.transaction.coordinator_class=class org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorBuilderImpl, java.awt.headless=true, jakarta.persistence.validation.mode=AUTO, user.script=, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, java.runtime.version=17.0.6+10, user.name=jinsung, spring.jmx.enabled=true, path.separator=;, management.endpoints.jmx.exposure.include=*, os.version=10.0, java.runtime.name=OpenJDK Runtime Environment, file.encoding=UTF-8, FILE_LOG_PATTERN="[%d{HH:mm:ss.SSS}][%-5level][%logger.%method:line%line] - %msg%n", hibernate.ejb.persistenceUnitName=default, spring.beaninfo.ignore=true, java.vm.name=OpenJDK 64-Bit Server VM, java.vendor.version=Temurin-17.0.6+10, LOG_FILE=./logging/demo.log, java.vendor.url.bug=https://github.com/adoptium/adoptium-support/issues, java.io.tmpdir=C:\Users\jinsung\AppData\Local\Temp\, com.zaxxer.hikari.pool_number=1, catalina.home=C:\Users\jinsung\AppData\Local\Temp\tomcat.8080.9525644597910610098, com.sun.management.jmxremote.port=50899, java.version=17.0.6, hibernate.physical_naming_strategy=org.hibernate.boot.model.naming.CamelCaseToUnderscoresNamingStrategy, user.dir=C:\Users\jinsung\Documents\GitHub\RMS\demo, os.arch=amd64, java.vm.specification.name=Java Virtual Machine Specification, PID=28464, sun.os.patch.level=, CONSOLE_LOG_CHARSET=UTF-8, LOGBACK_ROLLINGPOLICY_MAX_HISTORY=30, catalina.base=C:\Users\jinsung\AppData\Local\Temp\tomcat.8080.9525644597910610098, hibernate.boot.CfgXmlAccessService.key=org.hibernate.boot.registry.StandardServiceRegistryBuilder$1@61949a46, native.encoding=MS949, java.library.path=C:\sts-4.18.0.RELEASE\plugins\org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729\jre\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin/server;C:/sts-4.18.0.RELEASE//plugins/org.eclipse.justj.openjdk.hotspot.jre.full.win32.x86_64_17.0.6.v20230204-1729/jre/bin;C:\Program Files (x86)\NAT Service;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Bandizip\;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\PuTTY\;C:\gradle\gradle-8.0.2\bin;C:\jdk-17\bin;C:\Users\jinsung\AppData\Local\Programs\Python\Python310;C:\Users\jinsung\AppData\Local\Programs\Python\Python310\Scripts;C:\Program Files\Docker\Docker\resources\bin;C:\apache-maven-3.9.3\bin;C:\Users\jinsung\AppData\Local\Microsoft\WindowsApps;C:\Users\jinsung\AppData\Roaming\npm;C:\Users\jinsung\AppData\Local\GitHubDesktop\bin;C:\Users\jinsung\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2022.3.3\bin;;C:\sts-4.18.0.RELEASE;;., java.vendor=Eclipse Adoptium, java.vm.info=mixed mode, emulated-client, java.vm.version=17.0.6+10, hibernate.bytecode.use_reflection_optimizer=false, java.rmi.server.randomIDs=true, java.rmi.server.hostname=localhost, sun.io.unicode.encoding=UnicodeLittle, hibernate.archive.scanner=org.hibernate.boot.archive.scan.internal.DisabledScanner, hibernate.connection.datasource=HikariDataSource (HikariPool-1), java.class.version=61.0}
""[01:41:59.371][DEBUG][org.hibernate.secure.spi.JaccIntegrator.doIntegration:line84] - Skipping JACC integration as it was not enabled
""[01:41:59.371][DEBUG][org.hibernate.internal.SessionFactoryImpl.<init>:line316] - Instantiated session factory
""[01:41:59.372][DEBUG][org.hibernate.type.spi.TypeConfiguration$Scope.scope:line154] - Scoping TypeConfiguration [org.hibernate.type.spi.TypeConfiguration@50a39a88] to SessionFactoryImpl [org.hibernate.internal.SessionFactoryImpl@3dcf9af2]
""[01:41:59.426][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line60] - Not known whether passed class name [com.jinseong.demo.entity.Reservation] is safe
""[01:41:59.426][DEBUG][org.hibernate.boot.internal.ClassLoaderAccessImpl.classForName:line62] - No temp ClassLoader provided; using live ClassLoader for loading potentially unsafe class : com.jinseong.demo.entity.Reservation
""[01:41:59.614][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:41:59.614][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:41:59.615][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:41:59.615][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  1, name=org.springframework.boot:type=Admin,name=SpringApplication, attribute=Ready
""[01:41:59.616][DEBUG][sun.rmi.server.call.log:line236] - RMI TCP Connection(2)-127.0.0.1: [127.0.0.1] exception: 
"javax.management.InstanceNotFoundException: org.springframework.boot:type=Admin,name=SpringApplication
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1088)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:640)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1449)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1310)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1405)
	at java.management.rmi/javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:639)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at java.rmi/sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:360)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:200)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.rmi/sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:587)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:828)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:705)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:399)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:704)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
"[01:41:59.624][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4031] - Static SQL for entity: com.jinseong.demo.entity.Reservation
""[01:41:59.624][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4036] -  Version select: select reservation_id from reservation where reservation_id =?
""[01:41:59.625][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4039] -  Snapshot select: select reservatio_.reservation_id, reservatio_.count as count2_0_, reservatio_.date as date3_0_, reservatio_.name as name4_0_, reservatio_.number as number5_0_, reservatio_.time as time6_0_ from reservation reservatio_ where reservatio_.reservation_id=?
""[01:41:59.625][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.debugf:line394] -  Insert 0: insert into reservation (count, date, name, number, time, reservation_id) values (?, ?, ?, ?, ?, ?)
""[01:41:59.625][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.debugf:line394] -  Update 0: update reservation set count=?, date=?, name=?, number=?, time=? where reservation_id=?
""[01:41:59.625][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.debugf:line394] -  Delete 0: delete from reservation where reservation_id=?
""[01:41:59.625][DEBUG][org.hibernate.persister.entity.AbstractEntityPersister.logStaticSQL:line4047] -  Identity insert: insert into reservation (count, date, name, number, time) values (?, ?, ?, ?, ?)
""[01:41:59.659][DEBUG][org.hibernate.loader.plan.build.internal.spaces.QuerySpacesImpl.registerQuerySpace:line174] - Adding QuerySpace : uid = <gen:0> -> org.hibernate.loader.plan.build.internal.spaces.EntityQuerySpaceImpl@70fc2e24]
""[01:41:59.660][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : count
""[01:41:59.660][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : date
""[01:41:59.660][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : name
""[01:41:59.660][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : number
""[01:41:59.661][DEBUG][org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitAttributeDefinition:line146] - Visiting attribute path : time
""[01:41:59.661][DEBUG][org.hibernate.loader.plan.build.internal.FetchStyleLoadPlanBuildingAssociationVisitationStrategy.buildLoadPlan:line160] - Building LoadPlan...
""[01:41:59.673][DEBUG][org.hibernate.loader.plan.exec.internal.LoadQueryJoinAndFetchProcessor.processQuerySpaceJoins:line102] - processing queryspace <gen:0>
""[01:41:59.678][DEBUG][org.hibernate.loader.plan.build.spi.LoadPlanTreePrinter.logTree:line55] - LoadPlan(entity=com.jinseong.demo.entity.Reservation)
    - Returns
       - EntityReturnImpl(entity=com.jinseong.demo.entity.Reservation, querySpaceUid=<gen:0>, path=com.jinseong.demo.entity.Reservation)
    - QuerySpaces
       - EntityQuerySpaceImpl(uid=<gen:0>, entity=com.jinseong.demo.entity.Reservation)
          - SQL table alias mapping - reservatio0_
          - alias suffix - 0_
          - suffixed key columns - {reservat1_0_0_}

""[01:41:59.680][DEBUG][org.hibernate.loader.entity.plan.EntityLoader.<init>:line129] - Static select for entity com.jinseong.demo.entity.Reservation [NONE]: select reservatio0_.reservation_id as reservat1_0_0_, reservatio0_.count as count2_0_0_, reservatio0_.date as date3_0_0_, reservatio0_.name as name4_0_0_, reservatio0_.number as number5_0_0_, reservatio0_.time as time6_0_0_ from reservation reservatio0_ where reservatio0_.reservation_id=?
""[01:41:59.708][DEBUG][org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.interpret:line556] - No schema actions specified
""[01:41:59.708][DEBUG][org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process:line69] - No actions specified; doing nothing
""[01:41:59.708][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:41:59.713][DEBUG][org.hibernate.service.internal.SessionFactoryServiceRegistryImpl.getService:line92] - EventListenerRegistry access via ServiceRegistry is deprecated.  Use `sessionFactory.getEventEngine().getListenerRegistry()` instead
""[01:41:59.716][DEBUG][org.hibernate.hql.internal.QueryTranslatorFactoryInitiator.initiateService:line45] - QueryTranslatorFactory: org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory@48c29a9a
""[01:41:59.721][DEBUG][org.hibernate.query.spi.NamedQueryRepository.checkNamedQueries:line171] - Checking 0 named HQL queries
""[01:41:59.721][DEBUG][org.hibernate.query.spi.NamedQueryRepository.checkNamedQueries:line185] - Checking 0 named SQL queries
""[01:41:59.722][DEBUG][org.hibernate.internal.SessionFactoryRegistry.<init>:line51] - Initializing SessionFactoryRegistry : org.hibernate.internal.SessionFactoryRegistry@34626a6e
""[01:41:59.723][DEBUG][org.hibernate.internal.SessionFactoryRegistry.addSessionFactory:line73] - Registering SessionFactory: d5b404c0-a1be-4c75-adae-00c2b513e9de (<unnamed>)
""[01:41:59.723][DEBUG][org.hibernate.internal.SessionFactoryRegistry.addSessionFactory:line80] - Not binding SessionFactory to JNDI, no JNDI name configured
""[01:41:59.723][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:41:59.734][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'application'
""[01:41:59.735][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webConfig'
""[01:41:59.736][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webSocketConfig'
""[01:41:59.738][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'socketHandler'
""[01:41:59.744][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mainController'
""[01:41:59.746][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaConsumerService'
""[01:41:59.754][DEBUG][org.springframework.kafka.annotation.KafkaListenerAnnotationBeanPostProcessor.debug:line313] - No retry topic configuration found for topics [reservation-topic]
""[01:41:59.756][DEBUG][org.springframework.kafka.annotation.KafkaListenerAnnotationBeanPostProcessor.debug:line313] - 1 @KafkaListener methods processed on bean 'kafkaConsumerService': {public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException=[@org.springframework.kafka.annotation.KafkaListener(topicPattern="", contentTypeConverter="", beanRef="__listener", containerFactory="", topics={"reservation-topic"}, groupId="my-consumer-group", batch="", clientIdPrefix="", topicPartitions={}, splitIterables=true, concurrency="", autoStartup="", filter="", containerGroup="", idIsGroup=true, errorHandler="", id="", properties={}, info="")]}
""[01:41:59.756][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.web.servlet.config.annotation.DelegatingWebMvcConfiguration'
""[01:41:59.765][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'openEntityManagerInViewInterceptorConfigurer'
""[01:41:59.766][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration'
""[01:41:59.766][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration' via constructor to bean named 'spring.jpa-org.springframework.boot.autoconfigure.orm.jpa.JpaProperties'
""[01:41:59.767][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'openEntityManagerInViewInterceptor'
""[01:41:59.767][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:41:59.773][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'openEntityManagerInViewInterceptorConfigurer' via factory method to bean named 'openEntityManagerInViewInterceptor'
""[01:41:59.774][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.web.config.SpringDataWebConfiguration'
""[01:41:59.775][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.data.web.config.SpringDataWebConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@797c8eb9'
""[01:41:59.778][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'requestMappingHandlerMapping'
""[01:41:59.779][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcContentNegotiationManager'
""[01:41:59.784][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcConversionService'
""[01:41:59.792][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcResourceUrlProvider'
""[01:41:59.797][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcContentNegotiationManager'
""[01:41:59.797][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:41:59.797][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:41:59.835][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.detectHandlerMethods:line295] - 
	c.j.d.c.MainController:
	{GET [/]}: index(Model)
""[01:41:59.841][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.detectHandlerMethods:line295] - 
	o.s.b.a.w.s.e.BasicErrorController:
	{ [/error]}: error(HttpServletRequest)
	{ [/error], produces [text/html]}: errorHtml(HttpServletRequest,HttpServletResponse)
""[01:41:59.844][DEBUG][org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping.handlerMethodsInitialized:line367] - 3 mappings in 'requestMappingHandlerMapping'
""[01:41:59.847][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcPatternParser'
""[01:41:59.847][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcUrlPathHelper'
""[01:41:59.848][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcPathMatcher'
""[01:41:59.848][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'viewControllerHandlerMapping'
""[01:41:59.849][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'viewControllerHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:41:59.849][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'viewControllerHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:41:59.849][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'beanNameHandlerMapping'
""[01:41:59.850][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'beanNameHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:41:59.850][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'beanNameHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:41:59.852][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.detectHandlers:line86] - 'beanNameHandlerMapping' {}
""[01:41:59.854][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'routerFunctionMapping'
""[01:41:59.855][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'routerFunctionMapping' via factory method to bean named 'mvcConversionService'
""[01:41:59.855][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'routerFunctionMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:41:59.863][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'resourceHandlerMapping'
""[01:41:59.863][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcContentNegotiationManager'
""[01:41:59.864][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcConversionService'
""[01:41:59.864][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
""[01:41:59.864][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'defaultServletHandlerMapping'
""[01:41:59.864][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'requestMappingHandlerAdapter'
""[01:41:59.865][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcValidator'
""[01:41:59.866][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcContentNegotiationManager'
""[01:41:59.866][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcConversionService'
""[01:41:59.866][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcValidator'
""[01:41:59.875][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'sortResolver'
""[01:41:59.877][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'sortCustomizer'
""[01:41:59.877][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration'
""[01:41:59.878][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.data.web-org.springframework.boot.autoconfigure.data.web.SpringDataWebProperties'
""[01:41:59.879][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration' via constructor to bean named 'spring.data.web-org.springframework.boot.autoconfigure.data.web.SpringDataWebProperties'
""[01:41:59.881][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'pageableResolver'
""[01:41:59.883][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'pageableCustomizer'
""[01:41:59.892][DEBUG][org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.initControllerAdviceCache:line625] - ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
""[01:41:59.919][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'handlerFunctionAdapter'
""[01:41:59.921][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcUriComponentsContributor'
""[01:41:59.921][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mvcUriComponentsContributor' via factory method to bean named 'mvcConversionService'
""[01:41:59.922][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mvcUriComponentsContributor' via factory method to bean named 'requestMappingHandlerAdapter'
""[01:41:59.923][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'httpRequestHandlerAdapter'
""[01:41:59.924][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'simpleControllerHandlerAdapter'
""[01:41:59.924][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'handlerExceptionResolver'
""[01:41:59.925][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'handlerExceptionResolver' via factory method to bean named 'mvcContentNegotiationManager'
""[01:41:59.928][DEBUG][org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver.initExceptionHandlerAdviceCache:line307] - ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
""[01:41:59.930][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mvcViewResolver'
""[01:41:59.930][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mvcViewResolver' via factory method to bean named 'mvcContentNegotiationManager'
""[01:41:59.934][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'localeResolver'
""[01:41:59.935][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'themeResolver'
""[01:41:59.936][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'flashMapManager'
""[01:41:59.938][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'viewNameTranslator'
""[01:41:59.939][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'viewResolver'
""[01:41:59.954][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.web.socket.config.annotation.DelegatingWebSocketConfiguration'
""[01:41:59.957][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'webSocketHandlerMapping'
""[01:41:59.958][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'defaultSockJsTaskScheduler'
""[01:41:59.961][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'webSocketHandlerMapping' via factory method to bean named 'defaultSockJsTaskScheduler'
""[01:41:59.972][DEBUG][_org.springframework.web.servlet.HandlerMapping.Mappings.logMappings:line177] - 'webSocketHandlerMapping' {/ws=org.springframework.web.socket.server.support.WebSocketHttpRequestHandler@4e3c88a9}
""[01:41:59.974][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration'
""[01:41:59.974][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration'
""[01:41:59.974][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.EnableConfigurationPropertiesRegistrar.methodValidationExcludeFilter'
""[01:41:59.975][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration'
""[01:41:59.976][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration'
""[01:41:59.976][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'taskExecutorBuilder'
""[01:41:59.977][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
""[01:41:59.979][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'taskExecutorBuilder' via factory method to bean named 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
""[01:41:59.981][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration'
""[01:41:59.982][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'error'
""[01:41:59.982][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'beanNameViewResolver'
""[01:41:59.983][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration'
""[01:41:59.983][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
""[01:41:59.991][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@797c8eb9'
""[01:41:59.991][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration' via constructor to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
""[01:41:59.992][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'conventionErrorViewResolver'
""[01:41:59.993][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'errorAttributes'
""[01:41:59.994][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'basicErrorController'
""[01:41:59.994][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'basicErrorController' via factory method to bean named 'errorAttributes'
""[01:41:59.995][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration'
""[01:41:59.996][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties'
""[01:41:59.997][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' via constructor to bean named 'spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties'
""[01:41:59.997][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mbeanExporter'
""[01:41:59.998][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'objectNamingStrategy'
""[01:42:00.000][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'objectNamingStrategy'
""[01:42:00.000][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@7a9bf677'
""[01:42:00.006][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mbeanServer'
""[01:42:00.009][DEBUG][org.springframework.jmx.support.JmxUtils.locateMBeanServer:line127] - Found MBeanServer: com.sun.jmx.mbeanserver.JmxMBeanServer@1f554b06
""[01:42:00.015][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration'
""[01:42:00.015][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'springApplicationAdminRegistrar'
""[01:42:00.016][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'springApplicationAdminRegistrar' via factory method to bean named 'environment'
""[01:42:00.018][DEBUG][org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin.afterPropertiesSet:line131] - Application Admin MBean registered with name 'org.springframework.boot:type=Admin,name=SpringApplication'
""[01:42:00.019][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$AspectJAutoProxyingConfiguration$CglibAutoProxyConfiguration'
""[01:42:00.019][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$AspectJAutoProxyingConfiguration'
""[01:42:00.019][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration'
""[01:42:00.020][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration'
""[01:42:00.020][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'applicationAvailability'
""[01:42:00.022][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$Jackson2ObjectMapperBuilderCustomizerConfiguration'
""[01:42:00.022][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'standardJacksonObjectMapperBuilderCustomizer'
""[01:42:00.023][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
""[01:42:00.026][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'standardJacksonObjectMapperBuilderCustomizer' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@797c8eb9'
""[01:42:00.026][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'standardJacksonObjectMapperBuilderCustomizer' via factory method to bean named 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
""[01:42:00.027][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperBuilderConfiguration'
""[01:42:00.027][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$ParameterNamesModuleConfiguration'
""[01:42:00.028][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'parameterNamesModule'
""[01:42:00.031][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperConfiguration'
""[01:42:00.032][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jacksonObjectMapper'
""[01:42:00.033][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@797c8eb9'
""[01:42:00.033][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'standardJacksonObjectMapperBuilderCustomizer'
""[01:42:00.034][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jsonComponentModule'
""[01:42:00.034][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration'
""[01:42:00.037][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jsonMixinModule'
""[01:42:00.038][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jsonMixinModule' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@797c8eb9'
""[01:42:00.045][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jacksonGeoModule'
""[01:42:00.046][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.web.config.SpringDataJacksonConfiguration'
""[01:42:00.051][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jacksonObjectMapper' via factory method to bean named 'jacksonObjectMapperBuilder'
""[01:42:00.074][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration'
""[01:42:00.074][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceJmxConfiguration$Hikari'
""[01:42:00.075][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jdbc.DataSourceJmxConfiguration$Hikari' via constructor to bean named 'dataSource'
""[01:42:00.075][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceJmxConfiguration'
""[01:42:00.076][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration$PooledDataSourceConfiguration'
""[01:42:00.076][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.metadata.DataSourcePoolMetadataProvidersConfiguration'
""[01:42:00.076][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration'
""[01:42:00.076][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionManager'
""[01:42:00.080][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'platformTransactionManagerCustomizers'
""[01:42:00.080][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration'
""[01:42:00.082][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.transaction-org.springframework.boot.autoconfigure.transaction.TransactionProperties'
""[01:42:00.087][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration'
""[01:42:00.087][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration'
""[01:42:00.088][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration'
""[01:42:00.088][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'lifecycleProcessor'
""[01:42:00.088][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties'
""[01:42:00.089][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'lifecycleProcessor' via factory method to bean named 'spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties'
""[01:42:00.091][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration'
""[01:42:00.091][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration'
""[01:42:00.091][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.jpa.util.JpaMetamodelCacheCleanup'
""[01:42:00.092][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.jpa.repository.support.JpaEvaluationContextExtension'
""[01:42:00.093][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'reservationRepository'
""[01:42:00.118][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:42:00.118][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:42:00.118][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:42:00.119][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  1, name=org.springframework.boot:type=Admin,name=SpringApplication, attribute=Ready
""[01:42:00.149][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jpaMappingContext'
""[01:42:00.149][DEBUG][org.springframework.data.jpa.repository.config.JpaMetamodelMappingContextFactoryBean.createInstance:line77] - Initializing JpaMetamodelMappingContext
""[01:42:00.165][DEBUG][org.springframework.data.jpa.repository.config.JpaMetamodelMappingContextFactoryBean.createInstance:line84] - Finished initializing JpaMetamodelMappingContext!
""[01:42:00.183][DEBUG][org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke:line306] - Creating new EntityManager for shared EntityManager invocation
""[01:42:00.233][DEBUG][org.hibernate.stat.internal.StatisticsInitiator.initiateServiceInternal:line101] - Statistics initialized [enabled=false]
""[01:42:00.239][DEBUG][org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke:line306] - Creating new EntityManager for shared EntityManager invocation
""[01:42:00.253][DEBUG][org.springframework.beans.CachedIntrospectionResults.forClass:line190] - Not strongly caching class [com.jinseong.demo.entity.Reservation] because it is not cache-safe
""[01:42:00.275][DEBUG][org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository:line280] - Initializing repository instance for com.jinseong.demo.repository.ReservationRepository
""[01:42:00.294][DEBUG][org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke:line306] - Creating new EntityManager for shared EntityManager invocation
""[01:42:00.334][DEBUG][org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository:line377] - Finished creation of repository instance for com.jinseong.demo.repository.ReservationRepository.
""[01:42:00.336][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration$StringHttpMessageConverterConfiguration'
""[01:42:00.336][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'stringHttpMessageConverter'
""[01:42:00.337][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'stringHttpMessageConverter' via factory method to bean named 'environment'
""[01:42:00.339][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.JacksonHttpMessageConvertersConfiguration$MappingJackson2HttpMessageConverterConfiguration'
""[01:42:00.339][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'mappingJackson2HttpMessageConverter'
""[01:42:00.340][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'mappingJackson2HttpMessageConverter' via factory method to bean named 'jacksonObjectMapper'
""[01:42:00.341][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.JacksonHttpMessageConvertersConfiguration'
""[01:42:00.341][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration'
""[01:42:00.341][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'messageConverters'
""[01:42:00.348][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.data.web.config.ProjectingArgumentResolverRegistrar'
""[01:42:00.348][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration'
""[01:42:00.350][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
""[01:42:00.351][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration' via constructor to bean named 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
""[01:42:00.352][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.JdbcTemplateConfiguration'
""[01:42:00.352][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'jdbcTemplate'
""[01:42:00.353][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.jdbc-org.springframework.boot.autoconfigure.jdbc.JdbcProperties'
""[01:42:00.353][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jdbcTemplate' via factory method to bean named 'dataSource'
""[01:42:00.353][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'jdbcTemplate' via factory method to bean named 'spring.jdbc-org.springframework.boot.autoconfigure.jdbc.JdbcProperties'
""[01:42:00.359][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.NamedParameterJdbcTemplateConfiguration'
""[01:42:00.359][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'namedParameterJdbcTemplate'
""[01:42:00.360][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'namedParameterJdbcTemplate' via factory method to bean named 'jdbcTemplate'
""[01:42:00.364][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration'
""[01:42:00.364][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration$EnableKafkaConfiguration'
""[01:42:00.364][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
""[01:42:00.365][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration'
""[01:42:00.369][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
""[01:42:00.378][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
""[01:42:00.390][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaTemplate'
""[01:42:00.391][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration'
""[01:42:00.391][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
""[01:42:00.392][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaProducerFactory'
""[01:42:00.403][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaProducerListener'
""[01:42:00.404][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'kafkaTemplate' via factory method to bean named 'kafkaProducerFactory'
""[01:42:00.404][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'kafkaTemplate' via factory method to bean named 'kafkaProducerListener'
""[01:42:00.415][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaListenerContainerFactoryConfigurer'
""[01:42:00.417][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaListenerContainerFactory'
""[01:42:00.417][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'kafkaListenerContainerFactory' via factory method to bean named 'kafkaListenerContainerFactoryConfigurer'
""[01:42:00.421][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaConsumerFactory'
""[01:42:00.437][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'kafkaAdmin'
""[01:42:00.442][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.sql.init.SqlInitializationAutoConfiguration'
""[01:42:00.443][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration'
""[01:42:00.444][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'taskSchedulerBuilder'
""[01:42:00.444][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
""[01:42:00.445][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'taskSchedulerBuilder' via factory method to bean named 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
""[01:42:00.447][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafJava8TimeDialect'
""[01:42:00.447][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'java8TimeDialect'
""[01:42:00.449][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafWebMvcConfiguration$ThymeleafViewResolverConfiguration'
""[01:42:00.449][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'thymeleafViewResolver'
""[01:42:00.450][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:42:00.452][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'templateEngine'
""[01:42:00.452][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.TemplateEngineConfigurations$DefaultTemplateEngineConfiguration'
""[01:42:00.453][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'templateEngine' via factory method to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:42:00.466][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'defaultTemplateResolver'
""[01:42:00.467][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration'
""[01:42:00.467][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration' via constructor to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:42:00.467][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@797c8eb9'
""[01:42:00.474][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'thymeleafViewResolver' via factory method to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
""[01:42:00.474][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'thymeleafViewResolver' via factory method to bean named 'templateEngine'
""[01:42:00.478][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafWebMvcConfiguration'
""[01:42:00.479][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration'
""[01:42:00.480][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration$JdbcTransactionManagerConfiguration'
""[01:42:00.481][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration'
""[01:42:00.482][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration$CglibAutoProxyConfiguration'
""[01:42:00.482][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration'
""[01:42:00.482][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$TransactionTemplateConfiguration'
""[01:42:00.482][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'transactionTemplate'
""[01:42:00.483][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'transactionTemplate' via factory method to bean named 'transactionManager'
""[01:42:00.484][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration'
""[01:42:00.485][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration'
""[01:42:00.485][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'multipartResolver'
""[01:42:00.486][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration'
""[01:42:00.486][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartConfiguration'
""[01:42:00.487][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'spring.devtools-org.springframework.boot.devtools.autoconfigure.DevToolsProperties'
""[01:42:00.488][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartConfiguration' via constructor to bean named 'spring.devtools-org.springframework.boot.devtools.autoconfigure.DevToolsProperties'
""[01:42:00.489][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'restartingClassPathChangedEventListener'
""[01:42:00.489][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'fileSystemWatcherFactory'
""[01:42:00.490][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'restartingClassPathChangedEventListener' via factory method to bean named 'fileSystemWatcherFactory'
""[01:42:00.491][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'classPathFileSystemWatcher'
""[01:42:00.491][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'classPathRestartStrategy'
""[01:42:00.492][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'classPathFileSystemWatcher' via factory method to bean named 'fileSystemWatcherFactory'
""[01:42:00.492][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'classPathFileSystemWatcher' via factory method to bean named 'classPathRestartStrategy'
""[01:42:00.513][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'conditionEvaluationDeltaLoggingListener'
""[01:42:00.513][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$LiveReloadConfiguration'
""[01:42:00.514][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'optionalLiveReloadServer'
""[01:42:00.515][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'liveReloadServer' via factory method to bean named 'spring.devtools-org.springframework.boot.devtools.autoconfigure.DevToolsProperties'
""[01:42:00.517][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'optionalLiveReloadServer' via factory method to bean named 'liveReloadServer'
""[01:42:00.517][DEBUG][org.springframework.boot.devtools.livereload.LiveReloadServer.start:line113] - Starting live reload server on port 35729
""[01:42:00.518][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:42:00.518][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'liveReloadServerEventListener'
""[01:42:00.519][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.createArgumentArray:line808] - Autowiring by type from bean name 'liveReloadServerEventListener' via factory method to bean named 'optionalLiveReloadServer'
""[01:42:00.519][DEBUG][org.springframework.beans.factory.support.DefaultListableBeanFactory.getSingleton:line225] - Creating shared instance of singleton bean 'org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration'
""[01:42:00.526][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.afterSingletonsInstantiated:line434] - Registering beans for JMX exposure on startup
""[01:42:00.526][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.registerBeans:line541] - Autodetecting user-defined JMX MBeans
""[01:42:00.527][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.autodetect:line896] - Bean with name 'dataSource' has been autodetected for JMX exposure
""[01:42:00.532][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.registerBeanInstance:line669] - Located MBean 'dataSource': registering with JMX server as MBean [com.zaxxer.hikari:name=dataSource,type=HikariDataSource]
""[01:42:00.568][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase -2147483647
""[01:42:00.569][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'springBootLoggingLifecycle'
""[01:42:00.569][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase 2147483547
""[01:42:00.616][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:42:00.622][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer.<init>:line695] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Initializing the Kafka consumer
""[01:42:00.623][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:42:00.623][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:42:00.623][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:42:00.624][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  1, name=org.springframework.boot:type=Admin,name=SpringApplication, attribute=Ready
""[01:42:00.714][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:42:00.716][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:42:00.716][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:42:00.716][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692290520714
""[01:42:00.718][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer.<init>:line815] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Kafka consumer initialized
""[01:42:00.719][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:42:00.729][DEBUG][org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler.initialize:line184] - Initializing ExecutorService
""[01:42:00.733][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
""[01:42:00.733][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase 2147483646
""[01:42:00.734][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:42:00.736][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendFindCoordinatorRequest:line821] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FindCoordinator request to broker localhost:9092 (id: -1 rack: null)
""[01:42:00.744][DEBUG][org.apache.tomcat.util.threads.LimitLatch.log:line173] - Counting up[http-nio-8080-Acceptor] latch=0
""[01:42:00.745][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:42:00.746][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'webServerStartStop'
""[01:42:00.746][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.start:line353] - Starting beans in phase 2147483647
""[01:42:00.746][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'webSocketHandlerMapping'
""[01:42:00.746][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.doStart:line185] - Successfully started bean 'webServerGracefulShutdown'
""[01:42:00.756][DEBUG][org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener.logAutoConfigurationReport:line126] - 


============================
CONDITIONS EVALUATION REPORT
============================


Positive matches:
-----------------

   AopAutoConfiguration matched:
      - @ConditionalOnProperty (spring.aop.auto=true) matched (OnPropertyCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration matched:
      - @ConditionalOnClass found required class 'org.aspectj.weaver.Advice' (OnClassCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration.CglibAutoProxyConfiguration matched:
      - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   ApplicationAvailabilityAutoConfiguration#applicationAvailability matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.availability.ApplicationAvailability; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)
      - @ConditionalOnMissingBean (types: io.r2dbc.spi.ConnectionFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceAutoConfiguration.PooledDataSourceConfiguration matched:
      - AnyNestedCondition 1 matched 1 did not; NestedCondition on DataSourceAutoConfiguration.PooledDataSourceCondition.PooledDataSourceAvailable PooledDataSource found supported DataSource; NestedCondition on DataSourceAutoConfiguration.PooledDataSourceCondition.ExplicitType @ConditionalOnProperty (spring.datasource.type) did not find property 'type' (DataSourceAutoConfiguration.PooledDataSourceCondition)
      - @ConditionalOnMissingBean (types: javax.sql.DataSource,javax.sql.XADataSource; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceConfiguration.Hikari matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)
      - @ConditionalOnProperty (spring.datasource.type=com.zaxxer.hikari.HikariDataSource) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: javax.sql.DataSource; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceInitializationConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.jdbc.datasource.init.DatabasePopulator' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource'; @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.sql.init.SqlDataSourceScriptDatabaseInitializer,org.springframework.boot.autoconfigure.sql.init.SqlR2dbcScriptDatabaseInitializer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceJmxConfiguration matched:
      - @ConditionalOnProperty (spring.jmx.enabled=true) matched (OnPropertyCondition)

   DataSourceJmxConfiguration.Hikari matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   DataSourcePoolMetadataProvidersConfiguration.HikariPoolDataSourceMetadataProviderConfiguration matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.jdbc.core.JdbcTemplate', 'org.springframework.transaction.TransactionManager' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration.JdbcTransactionManagerConfiguration matched:
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   DevToolsDataSourceAutoConfiguration matched:
      - Devtools devtools enabled. (OnEnabledDevToolsCondition)
      - DevTools DataSource Condition found auto-configured DataSource (DevToolsDataSourceAutoConfiguration.DevToolsDataSourceCondition)

   DevToolsDataSourceAutoConfiguration.DatabaseShutdownExecutorEntityManagerFactoryDependsOnPostProcessor matched:
      - @ConditionalOnClass found required class 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean' (OnClassCondition)
      - @ConditionalOnBean (types: org.springframework.orm.jpa.AbstractEntityManagerFactoryBean; SearchStrategy: all) found bean '&entityManagerFactory' (OnBeanCondition)

   DispatcherServletAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.servlet.DispatcherServlet' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   DispatcherServletAutoConfiguration.DispatcherServletConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRegistration' (OnClassCondition)
      - Default DispatcherServlet did not find dispatcher servlet beans (DispatcherServletAutoConfiguration.DefaultDispatcherServletCondition)

   DispatcherServletAutoConfiguration.DispatcherServletRegistrationConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRegistration' (OnClassCondition)
      - DispatcherServlet Registration did not find servlet registration bean (DispatcherServletAutoConfiguration.DispatcherServletRegistrationCondition)

   DispatcherServletAutoConfiguration.DispatcherServletRegistrationConfiguration#dispatcherServletRegistration matched:
      - @ConditionalOnBean (names: dispatcherServlet types: org.springframework.web.servlet.DispatcherServlet; SearchStrategy: all) found bean 'dispatcherServlet' (OnBeanCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration matched:
      - @ConditionalOnWebApplication (required) found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnWarDeployment the application is not deployed as a WAR file. (OnWarDeploymentCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.TomcatWebServerFactoryCustomizerConfiguration matched:
      - @ConditionalOnClass found required classes 'org.apache.catalina.startup.Tomcat', 'org.apache.coyote.UpgradeProtocol' (OnClassCondition)

   ErrorMvcAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.servlet.DispatcherServlet' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   ErrorMvcAutoConfiguration#basicErrorController matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.error.ErrorController; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration#errorAttributes matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.error.ErrorAttributes; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.DefaultErrorViewResolverConfiguration#conventionErrorViewResolver matched:
      - @ConditionalOnBean (types: org.springframework.web.servlet.DispatcherServlet; SearchStrategy: all) found bean 'dispatcherServlet'; @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.web.servlet.error.ErrorViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration matched:
      - @ConditionalOnProperty (server.error.whitelabel.enabled) matched (OnPropertyCondition)
      - ErrorTemplate Missing did not find error template view (ErrorMvcAutoConfiguration.ErrorTemplateMissingCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration#beanNameViewResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.servlet.view.BeanNameViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration#defaultErrorView matched:
      - @ConditionalOnMissingBean (names: error; SearchStrategy: all) did not find any beans (OnBeanCondition)

   GenericCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.GenericCacheConfiguration automatic cache type (CacheCondition)

   HibernateJpaAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean', 'javax.persistence.EntityManager', 'org.hibernate.engine.spi.SessionImplementor' (OnClassCondition)

   HibernateJpaConfiguration matched:
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   HttpEncodingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.filter.CharacterEncodingFilter' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (server.servlet.encoding.enabled) matched (OnPropertyCondition)

   HttpEncodingAutoConfiguration#characterEncodingFilter matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.filter.CharacterEncodingFilter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   HttpMessageConvertersAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.HttpMessageConverter' (OnClassCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication did not find reactive web application classes (HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition)

   HttpMessageConvertersAutoConfiguration#messageConverters matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.http.HttpMessageConverters; SearchStrategy: all) did not find any beans (OnBeanCondition)

   HttpMessageConvertersAutoConfiguration.StringHttpMessageConverterConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.StringHttpMessageConverter' (OnClassCondition)

   HttpMessageConvertersAutoConfiguration.StringHttpMessageConverterConfiguration#stringHttpMessageConverter matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.StringHttpMessageConverter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)

   JacksonAutoConfiguration.Jackson2ObjectMapperBuilderCustomizerConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration#jacksonObjectMapperBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.json.Jackson2ObjectMapperBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration#jacksonObjectMapper matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.module.paramnames.ParameterNamesModule' (OnClassCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration#parameterNamesModule matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.module.paramnames.ParameterNamesModule; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2HttpMessageConverterConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)
      - @ConditionalOnProperty (spring.mvc.converters.preferred-json-mapper=jackson) matched (OnPropertyCondition)
      - @ConditionalOnBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) found bean 'jacksonObjectMapper' (OnBeanCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2HttpMessageConverterConfiguration#mappingJackson2HttpMessageConverter matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.json.MappingJackson2HttpMessageConverter ignored: org.springframework.hateoas.server.mvc.TypeConstrainedMappingJackson2HttpMessageConverter,org.springframework.data.rest.webmvc.alps.AlpsJsonHttpMessageConverter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JdbcTemplateAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.core.JdbcTemplate' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a single bean 'dataSource' (OnBeanCondition)

   JdbcTemplateConfiguration matched:
      - @ConditionalOnMissingBean (types: org.springframework.jdbc.core.JdbcOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.jmx.export.MBeanExporter' (OnClassCondition)
      - @ConditionalOnProperty (spring.jmx.enabled=true) matched (OnPropertyCondition)

   JmxAutoConfiguration#mbeanExporter matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.MBeanExporter; SearchStrategy: current) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#mbeanServer matched:
      - @ConditionalOnMissingBean (types: javax.management.MBeanServer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#objectNamingStrategy matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.naming.ObjectNamingStrategy; SearchStrategy: current) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#entityManagerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean,javax.persistence.EntityManagerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#entityManagerFactoryBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.orm.jpa.EntityManagerFactoryBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#jpaVendorAdapter matched:
      - @ConditionalOnMissingBean (types: org.springframework.orm.jpa.JpaVendorAdapter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration#transactionManager matched:
      - @ConditionalOnMissingBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaBaseConfiguration.JpaWebConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.jpa.open-in-view=true) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: org.springframework.orm.jpa.support.OpenEntityManagerInViewInterceptor,org.springframework.orm.jpa.support.OpenEntityManagerInViewFilter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JpaRepositoriesAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.data.jpa.repository.JpaRepository' (OnClassCondition)
      - @ConditionalOnProperty (spring.data.jpa.repositories.enabled=true) matched (OnPropertyCondition)
      - @ConditionalOnBean (types: javax.sql.DataSource; SearchStrategy: all) found bean 'dataSource'; @ConditionalOnMissingBean (types: org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean,org.springframework.data.jpa.repository.config.JpaRepositoryConfigExtension; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JtaAutoConfiguration matched:
      - @ConditionalOnClass found required class 'javax.transaction.Transaction' (OnClassCondition)
      - @ConditionalOnProperty (spring.jta.enabled) matched (OnPropertyCondition)

   KafkaAnnotationDrivenConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.annotation.EnableKafka' (OnClassCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactory matched:
      - @ConditionalOnMissingBean (names: kafkaListenerContainerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactoryConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.kafka.ConcurrentKafkaListenerContainerFactoryConfigurer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration.EnableKafkaConfiguration matched:
      - @ConditionalOnMissingBean (names: org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.core.KafkaTemplate' (OnClassCondition)

   KafkaAutoConfiguration#kafkaAdmin matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaAdmin; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaConsumerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ConsumerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaProducerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ProducerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaProducerListener matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.support.ProducerListener; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaTemplate matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaTemplate; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LifecycleAutoConfiguration#defaultLifecycleProcessor matched:
      - @ConditionalOnMissingBean (names: lifecycleProcessor; SearchStrategy: current) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration matched:
      - Initialized Restarter Condition available and initialized (OnInitializedRestarterCondition)

   LocalDevToolsAutoConfiguration.LiveReloadConfiguration matched:
      - @ConditionalOnProperty (spring.devtools.livereload.enabled) matched (OnPropertyCondition)

   LocalDevToolsAutoConfiguration.LiveReloadConfiguration#liveReloadServer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.devtools.livereload.LiveReloadServer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration matched:
      - @ConditionalOnProperty (spring.devtools.restart.enabled) matched (OnPropertyCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration#classPathFileSystemWatcher matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.devtools.classpath.ClassPathFileSystemWatcher; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration#classPathRestartStrategy matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.devtools.classpath.ClassPathRestartStrategy; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LocalDevToolsAutoConfiguration.RestartConfiguration#conditionEvaluationDeltaLoggingListener matched:
      - @ConditionalOnProperty (spring.devtools.restart.log-condition-evaluation-delta) matched (OnPropertyCondition)

   MultipartAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.multipart.support.StandardServletMultipartResolver', 'javax.servlet.MultipartConfigElement' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.servlet.multipart.enabled) matched (OnPropertyCondition)

   MultipartAutoConfiguration#multipartConfigElement matched:
      - @ConditionalOnMissingBean (types: javax.servlet.MultipartConfigElement,org.springframework.web.multipart.commons.CommonsMultipartResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   MultipartAutoConfiguration#multipartResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.multipart.MultipartResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   NamedParameterJdbcTemplateConfiguration matched:
      - @ConditionalOnSingleCandidate (types: org.springframework.jdbc.core.JdbcTemplate; SearchStrategy: all) found a single bean 'jdbcTemplate'; @ConditionalOnMissingBean (types: org.springframework.jdbc.core.namedparam.NamedParameterJdbcOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   NoOpCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.NoOpCacheConfiguration automatic cache type (CacheCondition)

   PersistenceExceptionTranslationAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor' (OnClassCondition)

   PersistenceExceptionTranslationAutoConfiguration#persistenceExceptionTranslationPostProcessor matched:
      - @ConditionalOnProperty (spring.dao.exceptiontranslation.enabled) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   PropertyPlaceholderAutoConfiguration#propertySourcesPlaceholderConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.context.support.PropertySourcesPlaceholderConfigurer; SearchStrategy: current) did not find any beans (OnBeanCondition)

   RestTemplateAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.client.RestTemplate' (OnClassCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication did not find reactive web application classes (RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition)

   RestTemplateAutoConfiguration#restTemplateBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.client.RestTemplateBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   RestTemplateAutoConfiguration#restTemplateBuilderConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.web.client.RestTemplateBuilderConfigurer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ServletWebServerFactoryAutoConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRequest' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   ServletWebServerFactoryAutoConfiguration#tomcatServletWebServerFactoryCustomizer matched:
      - @ConditionalOnClass found required class 'org.apache.catalina.startup.Tomcat' (OnClassCondition)

   ServletWebServerFactoryConfiguration.EmbeddedTomcat matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.apache.catalina.startup.Tomcat', 'org.apache.coyote.UpgradeProtocol' (OnClassCondition)
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.server.ServletWebServerFactory; SearchStrategy: current) did not find any beans (OnBeanCondition)

   SimpleCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.SimpleCacheConfiguration automatic cache type (CacheCondition)

   SpringApplicationAdminJmxAutoConfiguration matched:
      - @ConditionalOnProperty (spring.application.admin.enabled=true) matched (OnPropertyCondition)

   SpringApplicationAdminJmxAutoConfiguration#springApplicationAdminRegistrar matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.data.web.PageableHandlerMethodArgumentResolver', 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnMissingBean (types: org.springframework.data.web.PageableHandlerMethodArgumentResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration#pageableCustomizer matched:
      - @ConditionalOnMissingBean (types: org.springframework.data.web.config.PageableHandlerMethodArgumentResolverCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration#sortCustomizer matched:
      - @ConditionalOnMissingBean (types: org.springframework.data.web.config.SortHandlerMethodArgumentResolverCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SqlInitializationAutoConfiguration matched:
      - @ConditionalOnProperty (spring.sql.init.enabled) matched (OnPropertyCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on SqlInitializationAutoConfiguration.SqlInitializationModeCondition.ModeIsNever @ConditionalOnProperty (spring.sql.init.mode=never) did not find property 'mode' (SqlInitializationAutoConfiguration.SqlInitializationModeCondition)

   TaskExecutionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor' (OnClassCondition)

   TaskExecutionAutoConfiguration#applicationTaskExecutor matched:
      - @ConditionalOnMissingBean (types: java.util.concurrent.Executor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskExecutionAutoConfiguration#taskExecutorBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskExecutorBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskSchedulingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler' (OnClassCondition)

   TaskSchedulingAutoConfiguration#taskSchedulerBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskSchedulerBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TemplateEngineConfigurations.DefaultTemplateEngineConfiguration#templateEngine matched:
      - @ConditionalOnMissingBean (types: org.thymeleaf.spring5.ISpringTemplateEngine; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.thymeleaf.templatemode.TemplateMode', 'org.thymeleaf.spring5.SpringTemplateEngine' (OnClassCondition)

   ThymeleafAutoConfiguration.DefaultTemplateResolverConfiguration matched:
      - @ConditionalOnMissingBean (names: defaultTemplateResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration.ThymeleafJava8TimeDialect matched:
      - @ConditionalOnClass found required class 'org.thymeleaf.extras.java8time.dialect.Java8TimeDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafJava8TimeDialect#java8TimeDialect matched:
      - @ConditionalOnMissingBean (types: org.thymeleaf.extras.java8time.dialect.Java8TimeDialect; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration matched:
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.thymeleaf.enabled) matched (OnPropertyCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration.ThymeleafViewResolverConfiguration#thymeleafViewResolver matched:
      - @ConditionalOnMissingBean (names: thymeleafViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.transaction.PlatformTransactionManager' (OnClassCondition)

   TransactionAutoConfiguration#platformTransactionManagerCustomizers matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.transaction.TransactionManagerCustomizers; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration matched:
      - @ConditionalOnBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) found bean 'transactionManager'; @ConditionalOnMissingBean (types: org.springframework.transaction.annotation.AbstractTransactionManagementConfiguration; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.CglibAutoProxyConfiguration matched:
      - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   TransactionAutoConfiguration.TransactionTemplateConfiguration matched:
      - @ConditionalOnSingleCandidate (types: org.springframework.transaction.PlatformTransactionManager; SearchStrategy: all) found a single bean 'transactionManager' (OnBeanCondition)

   TransactionAutoConfiguration.TransactionTemplateConfiguration#transactionTemplate matched:
      - @ConditionalOnMissingBean (types: org.springframework.transaction.support.TransactionOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebSocketMessagingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.socket.config.annotation.WebSocketMessageBrokerConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'javax.websocket.server.ServerContainer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration.TomcatWebSocketConfiguration matched:
      - @ConditionalOnClass found required classes 'org.apache.catalina.startup.Tomcat', 'org.apache.tomcat.websocket.server.WsSci' (OnClassCondition)

   WebSocketServletAutoConfiguration.TomcatWebSocketConfiguration#websocketServletWebServerCustomizer matched:
      - @ConditionalOnMissingBean (names: websocketServletWebServerCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)


Negative matches:
-----------------

   ActiveMQAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.ConnectionFactory' (OnClassCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)

   AopAutoConfiguration.ClassProxyingConfiguration:
      Did not match:
         - @ConditionalOnMissingClass found unwanted class 'org.aspectj.weaver.Advice' (OnClassCondition)

   ArtemisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.ConnectionFactory' (OnClassCondition)

   AtomikosJtaConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.atomikos.icatch.jta.UserTransactionManager' (OnClassCondition)

   BatchAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.batch.core.launch.JobLauncher' (OnClassCondition)

   Cache2kCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.cache2k.Cache2kBuilder' (OnClassCondition)

   CacheAutoConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.cache.interceptor.CacheAspectSupport; SearchStrategy: all) did not find any beans of type org.springframework.cache.interceptor.CacheAspectSupport (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.cache.CacheManager' (OnClassCondition)

   CacheAutoConfiguration.CacheManagerEntityManagerFactoryDependsOnPostProcessor:
      Did not match:
         - Ancestor org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean' (OnClassCondition)

   CaffeineCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.github.benmanes.caffeine.cache.Caffeine' (OnClassCondition)

   CassandraAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.cassandra.ReactiveSession' (OnClassCondition)

   CassandraRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   ClientHttpConnectorAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   CodecsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   CouchbaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   CouchbaseReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   DataSourceAutoConfiguration.EmbeddedDatabaseConfiguration:
      Did not match:
         - EmbeddedDataSource spring.datasource.url is set (DataSourceAutoConfiguration.EmbeddedDatabaseCondition)

   DataSourceConfiguration.Dbcp2:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.commons.dbcp2.BasicDataSource' (OnClassCondition)

   DataSourceConfiguration.Generic:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.type) did not find property 'spring.datasource.type' (OnPropertyCondition)

   DataSourceConfiguration.OracleUcp:
      Did not match:
         - @ConditionalOnClass did not find required classes 'oracle.ucp.jdbc.PoolDataSourceImpl', 'oracle.jdbc.OracleConnection' (OnClassCondition)

   DataSourceConfiguration.Tomcat:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSource' (OnClassCondition)

   DataSourceJmxConfiguration.TomcatDataSourceJmxConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSourceProxy' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.CommonsDbcp2PoolDataSourceMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.commons.dbcp2.BasicDataSource' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.OracleUcpPoolDataSourceMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'oracle.ucp.jdbc.PoolDataSource', 'oracle.jdbc.OracleConnection' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.TomcatDataSourcePoolMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSource' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration.JdbcTransactionManagerConfiguration#transactionManager:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) found beans of type 'org.springframework.transaction.TransactionManager' transactionManager (OnBeanCondition)

   DevToolsR2dbcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   DispatcherServletAutoConfiguration.DispatcherServletConfiguration#multipartResolver:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.web.multipart.MultipartResolver; SearchStrategy: all) did not find any beans of type org.springframework.web.multipart.MultipartResolver (OnBeanCondition)

   EhCacheCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'net.sf.ehcache.Cache' (OnClassCondition)

   ElasticsearchDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.core.ElasticsearchRestTemplate' (OnClassCondition)

   ElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.Client' (OnClassCondition)

   ElasticsearchRestClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.RestClientBuilder' (OnClassCondition)

   EmbeddedLdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.unboundid.ldap.listener.InMemoryDirectoryServer' (OnClassCondition)

   EmbeddedMongoAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.MongoClientSettings' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.JettyWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.util.Loader', 'org.eclipse.jetty.webapp.WebAppContext' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.NettyWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.netty.http.server.HttpServer' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.UndertowWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.undertow.Undertow', 'org.xnio.SslClientAuthMode' (OnClassCondition)

   ErrorWebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   FlywayAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.flywaydb.core.Flyway' (OnClassCondition)

   FreeMarkerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'freemarker.template.Configuration' (OnClassCondition)

   GraphQlAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlQueryByExampleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlQuerydslAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlRSocketAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlReactiveQueryByExampleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlReactiveQuerydslAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebFluxSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebMvcSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GroovyTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'groovy.text.markup.MarkupTemplateEngine' (OnClassCondition)

   GsonAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.google.gson.Gson' (OnClassCondition)

   GsonHttpMessageConvertersConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.google.gson.Gson' (OnClassCondition)

   H2ConsoleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.h2.server.web.WebServlet' (OnClassCondition)

   HazelcastAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastJpaDependencyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HttpHandlerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.DispatcherHandler' (OnClassCondition)

   HypermediaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.hateoas.EntityModel' (OnClassCondition)

   InfinispanCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.infinispan.spring.embedded.provider.SpringEmbeddedCacheManager' (OnClassCondition)

   InfluxDbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.influxdb.InfluxDB' (OnClassCondition)

   IntegrationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.integration.config.EnableIntegration' (OnClassCondition)

   JCacheCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.cache.Caching' (OnClassCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2XmlHttpMessageConverterConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.fasterxml.jackson.dataformat.xml.XmlMapper' (OnClassCondition)

   JdbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.jdbc.repository.config.AbstractJdbcConfiguration' (OnClassCondition)

   JerseyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.glassfish.jersey.server.spring.SpringComponentProvider' (OnClassCondition)

   JmsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.Message' (OnClassCondition)

   JndiConnectionFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jms.core.JmsTemplate' (OnClassCondition)

   JndiDataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.jndi-name) did not find property 'jndi-name' (OnPropertyCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)

   JndiJtaConfiguration:
      Did not match:
         - @ConditionalOnJndi JNDI environment is not available (OnJndiCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.transaction.jta.JtaTransactionManager' (OnClassCondition)

   JooqAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.jooq.DSLContext' (OnClassCondition)

   JpaRepositoriesAutoConfiguration#entityManagerFactoryBootstrapExecutorCustomizer:
      Did not match:
         - AnyNestedCondition 0 matched 2 did not; NestedCondition on JpaRepositoriesAutoConfiguration.BootstrapExecutorCondition.LazyBootstrapMode @ConditionalOnProperty (spring.data.jpa.repositories.bootstrap-mode=lazy) did not find property 'bootstrap-mode'; NestedCondition on JpaRepositoriesAutoConfiguration.BootstrapExecutorCondition.DeferredBootstrapMode @ConditionalOnProperty (spring.data.jpa.repositories.bootstrap-mode=deferred) did not find property 'bootstrap-mode' (JpaRepositoriesAutoConfiguration.BootstrapExecutorCondition)

   JsonbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.json.bind.Jsonb' (OnClassCondition)

   JsonbHttpMessageConvertersConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.json.bind.Jsonb' (OnClassCondition)

   KafkaAutoConfiguration#kafkaJaasInitializer:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.jaas.enabled) did not find property 'spring.kafka.jaas.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaRetryTopicConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.retry.topic.enabled) did not find property 'spring.kafka.retry.topic.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaTransactionManager:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.producer.transaction-id-prefix) did not find property 'spring.kafka.producer.transaction-id-prefix' (OnPropertyCondition)

   KafkaStreamsAnnotationDrivenConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.kafka.streams.StreamsBuilder' (OnClassCondition)

   LdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ldap.core.ContextSource' (OnClassCondition)

   LdapRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.ldap.repository.LdapRepository' (OnClassCondition)

   LiquibaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'liquibase.change.DatabaseChange' (OnClassCondition)

   MailSenderAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.mail.internet.MimeMessage' (OnClassCondition)

   MailSenderValidatorAutoConfiguration:
      Did not match:
         - @ConditionalOnSingleCandidate did not find required type 'org.springframework.mail.javamail.JavaMailSenderImpl' (OnBeanCondition)

   MessageSourceAutoConfiguration:
      Did not match:
         - ResourceBundle did not find bundle with basename messages (MessageSourceAutoConfiguration.ResourceBundleCondition)

   MongoAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MustacheAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.samskivert.mustache.Mustache' (OnClassCondition)

   Neo4jAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   NettyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.netty.util.NettyRuntime' (OnClassCondition)

   OAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.configuration.EnableWebSecurity' (OnClassCondition)

   OAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.oauth2.server.resource.BearerTokenAuthenticationToken' (OnClassCondition)

   ProjectInfoAutoConfiguration#buildProperties:
      Did not match:
         - @ConditionalOnResource did not find resource '${spring.info.build.location:classpath:META-INF/build-info.properties}' (OnResourceCondition)

   ProjectInfoAutoConfiguration#gitProperties:
      Did not match:
         - GitResource did not find git info at classpath:git.properties (ProjectInfoAutoConfiguration.GitResourceAvailableCondition)

   QuartzAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.quartz.Scheduler' (OnClassCondition)

   R2dbcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   R2dbcDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.r2dbc.core.R2dbcEntityTemplate' (OnClassCondition)

   R2dbcInitializationConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.r2dbc.spi.ConnectionFactory', 'org.springframework.r2dbc.connection.init.DatabasePopulator' (OnClassCondition)

   R2dbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   R2dbcTransactionManagerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.r2dbc.connection.R2dbcTransactionManager' (OnClassCondition)

   RSocketGraphQlClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   RSocketMessagingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RSocketRequesterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RSocketSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.rsocket.core.SecuritySocketAcceptorInterceptor' (OnClassCondition)

   RSocketServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.core.RSocketServer' (OnClassCondition)

   RSocketStrategiesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.netty.buffer.PooledByteBufAllocator' (OnClassCondition)

   RabbitAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.rabbitmq.client.Channel' (OnClassCondition)

   ReactiveElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.client.reactive.ReactiveElasticsearchClient' (OnClassCondition)

   ReactiveElasticsearchRestClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.netty.http.client.HttpClient' (OnClassCondition)

   ReactiveMultipartAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   ReactiveOAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   ReactiveOAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.reactive.EnableWebFluxSecurity' (OnClassCondition)

   ReactiveSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   ReactiveUserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.ReactiveAuthenticationManager' (OnClassCondition)

   ReactiveWebServerFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnWebApplication did not find reactive web application classes (OnWebApplicationCondition)

   RedisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.core.RedisOperations' (OnClassCondition)

   RedisCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.connection.RedisConnectionFactory' (OnClassCondition)

   RedisReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   RedisRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.repository.configuration.EnableRedisRepositories' (OnClassCondition)

   RemoteDevToolsAutoConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.devtools.remote.secret) did not find property 'secret' (OnPropertyCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.servlet.Filter', 'org.springframework.http.server.ServerHttpRequest' (OnClassCondition)

   RepositoryRestMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.rest.webmvc.config.RepositoryRestMvcConfiguration' (OnClassCondition)

   Saml2RelyingPartyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.saml2.provider.service.registration.RelyingPartyRegistrationRepository' (OnClassCondition)

   SecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.DefaultAuthenticationEventPublisher' (OnClassCondition)

   SecurityFilterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.http.SessionCreationPolicy' (OnClassCondition)

   SendGridAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.sendgrid.SendGrid' (OnClassCondition)

   ServletWebServerFactoryAutoConfiguration.ForwardedHeaderFilterConfiguration:
      Did not match:
         - @ConditionalOnProperty (server.forward-headers-strategy=framework) did not find property 'server.forward-headers-strategy' (OnPropertyCondition)

   ServletWebServerFactoryConfiguration.EmbeddedJetty:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.util.Loader', 'org.eclipse.jetty.webapp.WebAppContext' (OnClassCondition)

   ServletWebServerFactoryConfiguration.EmbeddedUndertow:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.undertow.Undertow', 'org.xnio.SslClientAuthMode' (OnClassCondition)

   SessionAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.session.Session' (OnClassCondition)

   SolrAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.solr.client.solrj.impl.CloudSolrClient' (OnClassCondition)

   TaskSchedulingAutoConfiguration#scheduledBeanLazyInitializationExcludeFilter:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   TaskSchedulingAutoConfiguration#taskScheduler:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   TemplateEngineConfigurations.ReactiveTemplateEngineConfiguration:
      Did not match:
         - did not find reactive web application classes (OnWebApplicationCondition)

   ThymeleafAutoConfiguration.DataAttributeDialectConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.github.mxab.thymeleaf.extras.dataattribute.dialect.DataAttributeDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafSecurityDialectConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.thymeleaf.extras.springsecurity5.dialect.SpringSecurityDialect', 'org.springframework.security.web.server.csrf.CsrfToken' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafWebFluxConfiguration:
      Did not match:
         - did not find reactive web application classes (OnWebApplicationCondition)

   ThymeleafAutoConfiguration.ThymeleafWebLayoutConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'nz.net.ultraq.thymeleaf.layoutdialect.LayoutDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration#resourceUrlEncodingFilter:
      Did not match:
         - @ConditionalOnEnabledResourceChain did not find class org.webjars.WebJarAssetLocator (OnEnabledResourceChainCondition)

   TransactionAutoConfiguration#transactionalOperator:
      Did not match:
         - @ConditionalOnSingleCandidate (types: org.springframework.transaction.ReactiveTransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)

   UserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.AuthenticationManager' (OnClassCondition)

   ValidationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.validation.executable.ExecutableValidator' (OnClassCondition)

   WebClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   WebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   WebMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport; SearchStrategy: all) found beans of type 'org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport' org.springframework.web.servlet.config.annotation.DelegatingWebMvcConfiguration (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.servlet.DispatcherServlet', 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
         - found 'session' scope (OnWebApplicationCondition)

   WebMvcAutoConfiguration.ResourceChainCustomizerConfiguration:
      Did not match:
         - @ConditionalOnEnabledResourceChain did not find class org.webjars.WebJarAssetLocator (OnEnabledResourceChainCondition)
         - Ancestor org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)

   WebServiceTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.oxm.Marshaller' (OnClassCondition)

   WebServicesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ws.transport.http.MessageDispatcherServlet' (OnClassCondition)

   WebSessionIdResolverAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Mono' (OnClassCondition)

   WebSocketMessagingAutoConfiguration.WebSocketMessageConverterConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.web.socket.config.annotation.DelegatingWebSocketMessageBrokerConfiguration,com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) did not find any beans of type org.springframework.web.socket.config.annotation.DelegatingWebSocketMessageBrokerConfiguration (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required classes 'com.fasterxml.jackson.databind.ObjectMapper', 'org.springframework.messaging.simp.config.AbstractMessageBrokerConfiguration' (OnClassCondition)

   WebSocketReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnWebApplication did not find reactive web application classes (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration.Jetty10WebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.websocket.javax.server.internal.JavaxWebSocketServerContainer', 'org.eclipse.jetty.websocket.server.JettyWebSocketServerContainer' (OnClassCondition)

   WebSocketServletAutoConfiguration.JettyWebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.eclipse.jetty.websocket.jsr356.server.deploy.WebSocketServerContainerInitializer' (OnClassCondition)

   WebSocketServletAutoConfiguration.UndertowWebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.undertow.websockets.jsr.Bootstrap' (OnClassCondition)

   XADataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.boot.jdbc.XADataSourceWrapper; SearchStrategy: all) did not find any beans of type org.springframework.boot.jdbc.XADataSourceWrapper (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'javax.transaction.TransactionManager', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)


Exclusions:
-----------

    None


Unconditional classes:
----------------------

    org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration

    org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration

    org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration

    org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration

    org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration



""[01:42:00.760][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 4.49 seconds (JVM running for 5.314)
""[01:42:00.761][DEBUG][org.springframework.boot.availability.ApplicationAvailabilityBean.onApplicationEvent:line77] - Application availability state LivenessState changed to CORRECT
""[01:42:00.762][DEBUG][org.springframework.boot.devtools.restart.Restarter.logTo:line252] - Creating new Restarter for thread Thread[main,5,main]
""[01:42:00.762][DEBUG][org.springframework.boot.devtools.restart.Restarter.logTo:line252] - Immediately restarting application
""[01:42:00.762][DEBUG][org.springframework.boot.devtools.restart.Restarter.logTo:line252] - Starting application com.jinseong.demo.Application with URLs [file:/C:/Users/jinsung/Documents/GitHub/RMS/demo/target/classes/]
""[01:42:00.763][DEBUG][org.springframework.boot.availability.ApplicationAvailabilityBean.onApplicationEvent:line77] - Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
""[01:42:00.943][DEBUG][org.apache.kafka.clients.ClientUtils.resolve:line113] - Resolved host localhost as 127.0.0.1
""[01:42:00.944][DEBUG][org.apache.kafka.clients.NetworkClient.initiateConnect:line989] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Initiating connection to node localhost:9092 (id: -1 rack: null) using address localhost/127.0.0.1
""[01:42:00.960][DEBUG][org.apache.kafka.common.network.Selector.pollSelectionKeys:line531] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
""[01:42:00.964][DEBUG][org.apache.kafka.clients.NetworkClient.handleConnections:line951] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Completed connection to node -1. Fetching API versions.
""[01:42:00.964][DEBUG][org.apache.kafka.clients.NetworkClient.handleInitiateApiVersionRequests:line965] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Initiating API versions fetch from node -1.
""[01:42:00.998][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-1, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.2')
""[01:42:01.042][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-1, correlationId=1): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=12), ApiVersion(apiKey=2, minVersion=0, maxVersion=6), ApiVersion(apiKey=3, minVersion=0, maxVersion=11), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=7), ApiVersion(apiKey=10, minVersion=0, maxVersion=3), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
""[01:42:01.083][DEBUG][org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse:line921] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node -1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 6 [usable: 6], Metadata(3): 0 to 11 [usable: 11], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
""[01:42:01.085][DEBUG][org.apache.kafka.clients.NetworkClient.maybeUpdate:line1143] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='reservation-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:9092 (id: -1 rack: null)
""[01:42:01.086][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=11, clientId=consumer-my-consumer-group-1, correlationId=2) and timeout 30000 to node -1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='reservation-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
""[01:42:01.087][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-my-consumer-group-1, correlationId=0) and timeout 30000 to node -1: FindCoordinatorRequestData(key='my-consumer-group', keyType=0, coordinatorKeys=[])
""[01:42:01.091][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=11, clientId=consumer-my-consumer-group-1, correlationId=2): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=1001, host='127.0.0.1', port=9092, rack=null)], clusterId='TgEACWKoRbSzp0Inn-GuTg', controllerId=1001, topics=[MetadataResponseTopic(errorCode=0, name='reservation-topic', topicId=8aoMqokpSXGOqjBL2y8aPw, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=1001, leaderEpoch=0, replicaNodes=[1001], isrNodes=[1001], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
""[01:42:01.095][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:42:01.097][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:42:01.097][DEBUG][org.apache.kafka.clients.Metadata.update:line291] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='TgEACWKoRbSzp0Inn-GuTg', nodes={1001=127.0.0.1:9092 (id: 1001 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=reservation-topic-0, leader=Optional[1001], leaderEpoch=Optional[0], replicas=1001, isr=1001, offlineReplicas=)], controller=127.0.0.1:9092 (id: 1001 rack: null)}
""[01:42:01.098][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FIND_COORDINATOR response from node -1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-my-consumer-group-1, correlationId=0): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=1001, host='127.0.0.1', port=9092, coordinators=[])
""[01:42:01.099][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line834] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FindCoordinator response ClientResponse(receivedTimeMs=1692290521097, latencyMs=165, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-my-consumer-group-1, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=1001, host='127.0.0.1', port=9092, coordinators=[]))
""[01:42:01.100][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:42:01.100][DEBUG][org.apache.kafka.clients.ClientUtils.resolve:line113] - Resolved host 127.0.0.1 as 127.0.0.1
""[01:42:01.100][DEBUG][org.apache.kafka.clients.NetworkClient.initiateConnect:line989] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Initiating connection to node 127.0.0.1:9092 (id: 2147482646 rack: null) using address /127.0.0.1
""[01:42:01.103][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare:line707] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Executing onJoinPrepare with generation -1 and memberId 
""[01:42:01.103][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.run:line1367] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Heartbeat thread started
""[01:42:01.103][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] (Re-)joining group
""[01:42:01.103][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.metadata:line219] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Joining group with current subscription: [reservation-topic]
""[01:42:01.108][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line547] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending JoinGroup (JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])) to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:42:01.109][DEBUG][org.apache.kafka.common.network.Selector.pollSelectionKeys:line531] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147482646
""[01:42:01.110][DEBUG][org.apache.kafka.clients.NetworkClient.handleConnections:line951] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Completed connection to node 2147482646. Fetching API versions.
""[01:42:01.110][DEBUG][org.apache.kafka.clients.NetworkClient.handleInitiateApiVersionRequests:line965] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Initiating API versions fetch from node 2147482646.
""[01:42:01.110][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-1, correlationId=4) and timeout 30000 to node 2147482646: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.2')
""[01:42:01.115][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received API_VERSIONS response from node 2147482646 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-1, correlationId=4): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=12), ApiVersion(apiKey=2, minVersion=0, maxVersion=6), ApiVersion(apiKey=3, minVersion=0, maxVersion=11), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=7), ApiVersion(apiKey=10, minVersion=0, maxVersion=3), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
""[01:42:01.116][DEBUG][org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse:line921] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 2147482646 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 6 [usable: 6], Metadata(3): 0 to 11 [usable: 11], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
""[01:42:01.116][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending JOIN_GROUP request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-1, correlationId=3) and timeout 305000 to node 2147482646: JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:42:01.120][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received JOIN_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-1, correlationId=3): JoinGroupResponseData(throttleTimeMs=0, errorCode=79, generationId=-1, protocolType=null, protocolName=null, leader='', memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', members=[])
""[01:42:01.120][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line654] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] JoinGroup failed due to non-fatal error: MEMBER_ID_REQUIRED Will set the member id as consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b and then rejoin. Sent generation was  Generation{generationId=-1, memberId='', protocol='null'}
""[01:42:01.120][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:42:01.120][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] (Re-)joining group
""[01:42:01.121][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.metadata:line219] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Joining group with current subscription: [reservation-topic]
""[01:42:01.121][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line547] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending JoinGroup (JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])) to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:42:01.121][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending JOIN_GROUP request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-1, correlationId=5) and timeout 305000 to node 2147482646: JoinGroupRequestData(groupId='my-consumer-group', sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null, protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0]), JoinGroupRequestProtocol(name='cooperative-sticky', metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 4, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:42:01.126][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:42:01.127][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received JOIN_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=JOIN_GROUP, apiVersion=7, clientId=consumer-my-consumer-group-1, correlationId=5): JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=56, protocolType='consumer', protocolName='range', leader='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', members=[JoinGroupResponseMember(memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null, metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:42:01.127][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:42:01.128][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line575] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=56, protocolType='consumer', protocolName='range', leader='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', members=[JoinGroupResponseMember(memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null, metadata=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, -1, -1, -1, -1, 0, 0, 0, 0])])
""[01:42:01.128][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:42:01.128][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.enable:line1335] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Enabling heartbeat thread
""[01:42:01.128][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', protocol='range'}
""[01:42:01.128][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  1, name=org.springframework.boot:type=Admin,name=SpringApplication, attribute=Ready
""[01:42:01.129][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line645] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Performing assignment using strategy range with subscriptions {consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b=Subscription(topics=[reservation-topic], ownedPartitions=[], groupInstanceId=null)}
""[01:42:01.132][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Finished assignment for group at generation 56: {consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b=Assignment(partitions=[reservation-topic-0])}
""[01:42:01.134][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinLeader:line716] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending leader SyncGroup to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) at generation Generation{generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', protocol='range'}: SyncGroupRequestData(groupId='my-consumer-group', generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null, protocolType='consumer', protocolName='range', assignments=[SyncGroupRequestAssignment(memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])])
""[01:42:01.135][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending SYNC_GROUP request with header RequestHeader(apiKey=SYNC_GROUP, apiVersion=5, clientId=consumer-my-consumer-group-1, correlationId=6) and timeout 30000 to node 2147482646: SyncGroupRequestData(groupId='my-consumer-group', generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null, protocolType='consumer', protocolName='range', assignments=[SyncGroupRequestAssignment(memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])])
""[01:42:01.141][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received SYNC_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=SYNC_GROUP, apiVersion=5, clientId=consumer-my-consumer-group-1, correlationId=6): SyncGroupResponseData(throttleTimeMs=0, errorCode=0, protocolType='consumer', protocolName='range', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])
""[01:42:01.141][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line745] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received successful SyncGroup response: SyncGroupResponseData(throttleTimeMs=0, errorCode=0, protocolType='consumer', protocolName='range', assignment=[0, 1, 0, 0, 0, 1, 0, 17, 114, 101, 115, 101, 114, 118, 97, 116, 105, 111, 110, 45, 116, 111, 112, 105, 99, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1])
""[01:42:01.141][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', protocol='range'}
""[01:42:01.142][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete:line353] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Executing onJoinComplete with generation 56 and memberId consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b
""[01:42:01.142][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:42:01.144][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:42:01.145][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetFetchRequest:line1337] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Fetching committed offsets for partitions: [reservation-topic-0]
""[01:42:01.147][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending OFFSET_FETCH request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-1, correlationId=7) and timeout 30000 to node 2147482646: OffsetFetchRequestData(groupId='my-consumer-group', topics=[OffsetFetchRequestTopic(name='reservation-topic', partitionIndexes=[0])], groups=[], requireStable=true)
""[01:42:01.151][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received OFFSET_FETCH response from node 2147482646 for request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-1, correlationId=7): OffsetFetchResponseData(throttleTimeMs=0, topics=[OffsetFetchResponseTopic(name='reservation-topic', partitions=[OffsetFetchResponsePartition(partitionIndex=0, committedOffset=34, committedLeaderEpoch=-1, metadata='', errorCode=0)])], errorCode=0, groups=[])
""[01:42:01.154][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetFetchRequest:line1337] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Fetching committed offsets for partitions: [reservation-topic-0]
""[01:42:01.155][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending OFFSET_FETCH request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-1, correlationId=8) and timeout 30000 to node 2147482646: OffsetFetchRequestData(groupId='my-consumer-group', topics=[OffsetFetchRequestTopic(name='reservation-topic', partitionIndexes=[0])], groups=[], requireStable=true)
""[01:42:01.158][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received OFFSET_FETCH response from node 2147482646 for request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-my-consumer-group-1, correlationId=8): OffsetFetchResponseData(throttleTimeMs=0, topics=[OffsetFetchResponseTopic(name='reservation-topic', partitions=[OffsetFetchResponsePartition(partitionIndex=0, committedOffset=34, committedLeaderEpoch=-1, metadata='', errorCode=0)])], errorCode=0, groups=[])
""[01:42:01.161][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:42:01.162][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:42:01.166][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:01.166][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 1001 with 1 partition(s).
""[01:42:01.167][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED FullFetchRequest(toSend=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:01.168][DEBUG][org.apache.kafka.clients.ClientUtils.resolve:line113] - Resolved host 127.0.0.1 as 127.0.0.1
""[01:42:01.168][DEBUG][org.apache.kafka.clients.NetworkClient.initiateConnect:line989] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Initiating connection to node 127.0.0.1:9092 (id: 1001 rack: null) using address /127.0.0.1
""[01:42:01.170][DEBUG][org.apache.kafka.common.network.Selector.pollSelectionKeys:line531] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1001
""[01:42:01.170][DEBUG][org.apache.kafka.clients.NetworkClient.handleConnections:line951] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Completed connection to node 1001. Fetching API versions.
""[01:42:01.170][DEBUG][org.apache.kafka.clients.NetworkClient.handleInitiateApiVersionRequests:line965] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Initiating API versions fetch from node 1001.
""[01:42:01.170][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-1, correlationId=10) and timeout 30000 to node 1001: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.2')
""[01:42:01.173][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received API_VERSIONS response from node 1001 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-1, correlationId=10): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=12), ApiVersion(apiKey=2, minVersion=0, maxVersion=6), ApiVersion(apiKey=3, minVersion=0, maxVersion=11), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=7), ApiVersion(apiKey=10, minVersion=0, maxVersion=3), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[])
""[01:42:01.173][DEBUG][org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse:line921] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 6 [usable: 6], Metadata(3): 0 to 11 [usable: 11], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
""[01:42:01.174][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=9) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=0, sessionEpoch=0, topics=[FetchTopic(topic='reservation-topic', topicId=8aoMqokpSXGOqjBL2y8aPw, partitions=[FetchPartition(partition=0, currentLeaderEpoch=0, fetchOffset=34, lastFetchedEpoch=-1, logStartOffset=-1, partitionMaxBytes=1048576)])], forgottenTopicsData=[], rackId='')
""[01:42:01.187][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=9): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[FetchableTopicResponse(topic='reservation-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, partitions=[PartitionData(partitionIndex=0, errorCode=0, highWatermark=42, lastStableOffset=42, logStartOffset=0, divergingEpoch=EpochEndOffset(epoch=-1, endOffset=-1), currentLeader=LeaderIdAndEpoch(leaderId=-1, leaderEpoch=-1), snapshotId=SnapshotId(endOffset=-1, epoch=-1), abortedTransactions=null, preferredReadReplica=-1, records=MemoryRecords(size=1176, buffer=java.nio.HeapByteBuffer[pos=0 lim=1176 cap=1179]))])])
""[01:42:01.189][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line561] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent a full fetch response that created a new incremental fetch session 1819239349 with 1 response partition(s)
""[01:42:01.190][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.onSuccess:line326] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Fetch READ_UNCOMMITTED at offset 34 for partition reservation-topic-0 returned fetch data PartitionData(partitionIndex=0, errorCode=0, highWatermark=42, lastStableOffset=42, logStartOffset=0, divergingEpoch=EpochEndOffset(epoch=-1, endOffset=-1), currentLeader=LeaderIdAndEpoch(leaderId=-1, leaderEpoch=-1), snapshotId=SnapshotId(endOffset=-1, epoch=-1), abortedTransactions=null, preferredReadReplica=-1, records=MemoryRecords(size=1176, buffer=java.nio.HeapByteBuffer[pos=0 lim=1176 cap=1179]))
""[01:42:01.206][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:01.206][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=1) for node 1001. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:01.206][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(reservation-topic-0), toForget=(), toReplace=(), implied=(), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:01.207][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=11) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=1, topics=[FetchTopic(topic='reservation-topic', topicId=8aoMqokpSXGOqjBL2y8aPw, partitions=[FetchPartition(partition=0, currentLeaderEpoch=0, fetchOffset=42, lastFetchedEpoch=-1, logStartOffset=-1, partitionMaxBytes=1048576)])], forgottenTopicsData=[], rackId='')
""[01:42:01.207][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 8 records
""[01:42:01.212][DEBUG][org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.debug:line191] - Processing [GenericMessage [payload=Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678, headers={kafka_offset=34, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@6e12500f, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedTopic=reservation-topic, kafka_receivedTimestamp=1692289964845, kafka_groupId=my-consumer-group}]]
""[01:42:01.214][DEBUG][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line22] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.215][DEBUG][com.jinseong.demo.handler.SocketHandler.broadcastMessage:line32] - ===broadcastMessage=== -> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.215][DEBUG][org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.debug:line191] - Processing [GenericMessage [payload=Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678, headers={kafka_offset=35, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@6e12500f, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedTopic=reservation-topic, kafka_receivedTimestamp=1692290013518, kafka_groupId=my-consumer-group}]]
""[01:42:01.215][DEBUG][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line22] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.215][DEBUG][com.jinseong.demo.handler.SocketHandler.broadcastMessage:line32] - ===broadcastMessage=== -> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.216][DEBUG][org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.debug:line191] - Processing [GenericMessage [payload=Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678, headers={kafka_offset=36, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@6e12500f, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedTopic=reservation-topic, kafka_receivedTimestamp=1692290014034, kafka_groupId=my-consumer-group}]]
""[01:42:01.216][DEBUG][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line22] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.216][DEBUG][com.jinseong.demo.handler.SocketHandler.broadcastMessage:line32] - ===broadcastMessage=== -> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.216][DEBUG][org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.debug:line191] - Processing [GenericMessage [payload=Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678, headers={kafka_offset=37, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@6e12500f, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedTopic=reservation-topic, kafka_receivedTimestamp=1692290048443, kafka_groupId=my-consumer-group}]]
""[01:42:01.217][DEBUG][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line22] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.217][DEBUG][com.jinseong.demo.handler.SocketHandler.broadcastMessage:line32] - ===broadcastMessage=== -> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.218][DEBUG][org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.debug:line191] - Processing [GenericMessage [payload=Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678, headers={kafka_offset=38, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@6e12500f, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedTopic=reservation-topic, kafka_receivedTimestamp=1692290155318, kafka_groupId=my-consumer-group}]]
""[01:42:01.218][DEBUG][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line22] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.218][DEBUG][com.jinseong.demo.handler.SocketHandler.broadcastMessage:line32] - ===broadcastMessage=== -> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.219][DEBUG][org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.debug:line191] - Processing [GenericMessage [payload=Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678, headers={kafka_offset=39, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@6e12500f, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedTopic=reservation-topic, kafka_receivedTimestamp=1692290155809, kafka_groupId=my-consumer-group}]]
""[01:42:01.224][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:42:01.224][DEBUG][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line22] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.225][DEBUG][com.jinseong.demo.handler.SocketHandler.broadcastMessage:line32] - ===broadcastMessage=== -> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.225][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:42:01.225][DEBUG][org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.debug:line191] - Processing [GenericMessage [payload=Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678, headers={kafka_offset=40, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@6e12500f, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedTopic=reservation-topic, kafka_receivedTimestamp=1692290497938, kafka_groupId=my-consumer-group}]]
""[01:42:01.225][DEBUG][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line22] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.225][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "[Ljava.rmi.server.ObjID;", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:01.225][DEBUG][com.jinseong.demo.handler.SocketHandler.broadcastMessage:line32] - ===broadcastMessage=== -> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.226][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.server.ObjID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:01.226][DEBUG][org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.debug:line191] - Processing [GenericMessage [payload=Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678, headers={kafka_offset=41, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@6e12500f, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedTopic=reservation-topic, kafka_receivedTimestamp=1692290497979, kafka_groupId=my-consumer-group}]]
""[01:42:01.226][DEBUG][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line22] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.226][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.server.UID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:01.226][DEBUG][com.jinseong.demo.handler.SocketHandler.broadcastMessage:line32] - ===broadcastMessage=== -> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:01.226][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.dgc.VMID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:01.226][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "[B", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:01.227][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {reservation-topic-0=OffsetAndMetadata{offset=42, leaderEpoch=null, metadata=''}}
""[01:42:01.228][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Committing: {reservation-topic-0=OffsetAndMetadata{offset=42, leaderEpoch=null, metadata=''}}
""[01:42:01.229][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-my-consumer-group-1, correlationId=12) and timeout 30000 to node 2147482646: OffsetCommitRequestData(groupId='my-consumer-group', generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null, retentionTimeMs=-1, topics=[OffsetCommitRequestTopic(name='reservation-topic', partitions=[OffsetCommitRequestPartition(partitionIndex=0, committedOffset=42, committedLeaderEpoch=-1, commitTimestamp=-1, committedMetadata='')])])
""[01:42:01.233][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received OFFSET_COMMIT response from node 2147482646 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-my-consumer-group-1, correlationId=12): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='reservation-topic', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
""[01:42:01.233][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1226] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Committed offset 42 for partition reservation-topic-0
""[01:42:01.710][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=11): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:01.710][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:01.711][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:01.711][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=2) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:01.711][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:01.711][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=13) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=2, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:02.215][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=13): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:02.216][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:02.216][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:02.216][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=3) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:02.216][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:02.216][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=14) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=3, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:02.720][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=14): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:02.720][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:02.720][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:02.721][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=4) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:02.721][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:02.722][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=15) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=4, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:03.224][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=15): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:03.225][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:03.225][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:03.226][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=5) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:03.226][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:03.226][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=16) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=5, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:03.730][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=16): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:03.730][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:03.731][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:03.731][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=6) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:03.731][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:03.731][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=17) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=6, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:04.134][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending Heartbeat request with generation 56 and member id consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:42:04.135][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=18) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null)
""[01:42:04.139][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=18): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:42:04.140][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received successful Heartbeat response
""[01:42:04.234][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=17): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:04.235][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:04.235][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:04.236][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=7) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:04.236][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:04.236][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=19) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=7, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:04.739][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=19): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:04.740][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:04.740][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:04.741][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=8) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:04.741][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:04.741][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=20) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=8, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:05.244][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=20): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:05.244][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:05.245][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:05.245][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=9) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:05.245][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:05.245][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=21) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=9, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:05.748][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=21): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:05.749][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:05.749][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:05.749][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=10) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:05.749][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:05.750][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=22) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=10, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:06.244][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 0 records
""[01:42:06.245][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:42:06.252][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=22): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:06.253][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:06.253][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:06.253][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=11) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:06.254][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:06.254][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=23) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=11, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:06.756][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=23): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:06.756][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:06.757][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:06.757][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=12) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:06.757][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:06.757][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=24) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=12, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:07.143][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending Heartbeat request with generation 56 and member id consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:42:07.143][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=25) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null)
""[01:42:07.146][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=25): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:42:07.147][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received successful Heartbeat response
""[01:42:07.260][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=24): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:07.261][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:07.261][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:07.261][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=13) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:07.261][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:07.261][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=26) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=13, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:07.764][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=26): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:07.765][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:07.766][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:07.766][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=14) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:07.766][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:07.767][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=27) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=14, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:08.269][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=27): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:08.270][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:08.270][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:08.270][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=15) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:08.270][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:08.270][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=28) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=15, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:08.774][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=28): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:08.775][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:08.775][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:08.775][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=16) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:08.775][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:08.776][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=29) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=16, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:09.278][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=29): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:09.278][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:09.278][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:09.279][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=17) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:09.279][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:09.279][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=30) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=17, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:09.781][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=30): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:09.783][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:09.783][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:09.783][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=18) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:09.784][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:09.784][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=31) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=18, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:10.158][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending Heartbeat request with generation 56 and member id consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:42:10.158][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=32) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null)
""[01:42:10.161][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=32): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:42:10.162][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received successful Heartbeat response
""[01:42:10.286][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=31): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:10.286][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:10.286][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=42, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:10.287][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=19) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:10.287][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:10.287][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=33) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=19, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:10.376][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=33): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[FetchableTopicResponse(topic='reservation-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, partitions=[PartitionData(partitionIndex=0, errorCode=0, highWatermark=43, lastStableOffset=43, logStartOffset=0, divergingEpoch=EpochEndOffset(epoch=-1, endOffset=-1), currentLeader=LeaderIdAndEpoch(leaderId=-1, leaderEpoch=-1), snapshotId=SnapshotId(endOffset=-1, epoch=-1), abortedTransactions=null, preferredReadReplica=-1, records=MemoryRecords(size=147, buffer=java.nio.HeapByteBuffer[pos=0 lim=147 cap=150]))])])
""[01:42:10.377][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 1 response partition(s)
""[01:42:10.377][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.onSuccess:line326] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Fetch READ_UNCOMMITTED at offset 42 for partition reservation-topic-0 returned fetch data PartitionData(partitionIndex=0, errorCode=0, highWatermark=43, lastStableOffset=43, logStartOffset=0, divergingEpoch=EpochEndOffset(epoch=-1, endOffset=-1), currentLeader=LeaderIdAndEpoch(leaderId=-1, leaderEpoch=-1), snapshotId=SnapshotId(endOffset=-1, epoch=-1), abortedTransactions=null, preferredReadReplica=-1, records=MemoryRecords(size=147, buffer=java.nio.HeapByteBuffer[pos=0 lim=147 cap=150]))
""[01:42:10.378][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=43, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:10.378][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=20) for node 1001. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:10.379][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(reservation-topic-0), toForget=(), toReplace=(), implied=(), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:10.379][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=34) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=20, topics=[FetchTopic(topic='reservation-topic', topicId=8aoMqokpSXGOqjBL2y8aPw, partitions=[FetchPartition(partition=0, currentLeaderEpoch=0, fetchOffset=43, lastFetchedEpoch=-1, logStartOffset=-1, partitionMaxBytes=1048576)])], forgottenTopicsData=[], rackId='')
""[01:42:10.380][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Received: 1 records
""[01:42:10.380][DEBUG][org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.debug:line191] - Processing [GenericMessage [payload=Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678, headers={kafka_offset=42, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@6e12500f, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedTopic=reservation-topic, kafka_receivedTimestamp=1692290530364, kafka_groupId=my-consumer-group}]]
""[01:42:10.380][DEBUG][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line22] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:10.381][DEBUG][com.jinseong.demo.handler.SocketHandler.broadcastMessage:line32] - ===broadcastMessage=== -> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:42:10.381][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {reservation-topic-0=OffsetAndMetadata{offset=43, leaderEpoch=null, metadata=''}}
""[01:42:10.381][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Committing: {reservation-topic-0=OffsetAndMetadata{offset=43, leaderEpoch=null, metadata=''}}
""[01:42:10.382][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-my-consumer-group-1, correlationId=35) and timeout 30000 to node 2147482646: OffsetCommitRequestData(groupId='my-consumer-group', generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null, retentionTimeMs=-1, topics=[OffsetCommitRequestTopic(name='reservation-topic', partitions=[OffsetCommitRequestPartition(partitionIndex=0, committedOffset=43, committedLeaderEpoch=-1, commitTimestamp=-1, committedMetadata='')])])
""[01:42:10.386][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received OFFSET_COMMIT response from node 2147482646 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-my-consumer-group-1, correlationId=35): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='reservation-topic', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
""[01:42:10.386][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1226] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Committed offset 43 for partition reservation-topic-0
""[01:42:10.882][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=34): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:10.883][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:10.883][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=43, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:10.883][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=21) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:10.884][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:10.884][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=36) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=21, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:11.386][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=36): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:11.386][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:11.386][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=43, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:11.387][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=22) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:11.387][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:11.387][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=37) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=22, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:11.890][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=37): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:11.891][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:11.891][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=43, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:11.891][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=23) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:11.891][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:11.892][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=38) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=23, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:12.395][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=38): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:12.395][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:12.396][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=43, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:12.396][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=24) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:12.397][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:12.397][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=39) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=24, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:12.899][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=39): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:12.900][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:12.901][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=43, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:12.901][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=25) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:12.901][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:12.901][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=40) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=25, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:13.173][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendHeartbeatRequest:line1106] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending Heartbeat request with generation 56 and member id consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:42:13.173][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending HEARTBEAT request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=41) and timeout 30000 to node 2147482646: HeartbeatRequestData(groupId='my-consumer-group', generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null)
""[01:42:13.176][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received HEARTBEAT response from node 2147482646 for request with header RequestHeader(apiKey=HEARTBEAT, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=41): HeartbeatResponseData(throttleTimeMs=0, errorCode=0)
""[01:42:13.176][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1129] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received successful Heartbeat response
""[01:42:13.404][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=40): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:13.405][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:13.405][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=43, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:13.405][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=26) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:13.405][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:13.405][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=42) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=26, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:13.908][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=42): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:13.909][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:13.909][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=43, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:13.909][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=27) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:13.909][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:13.910][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=43) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=27, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:14.413][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received FETCH response from node 1001 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=43): FetchResponseData(throttleTimeMs=0, errorCode=0, sessionId=1819239349, responses=[])
""[01:42:14.413][DEBUG][org.apache.kafka.clients.FetchSessionHandler.handleResponse:line584] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Node 1001 sent an incremental fetch response with throttleTimeMs = 0 for session 1819239349 with 0 response partition(s), 1 implied partition(s)
""[01:42:14.414][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests:line1245] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Added READ_UNCOMMITTED fetch request for partition reservation-topic-0 at position FetchPosition{offset=43, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}} to node 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:14.414][DEBUG][org.apache.kafka.clients.FetchSessionHandler.build:line351] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Built incremental fetch (sessionId=1819239349, epoch=28) for node 1001. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s), replaced 0 partition(s) out of 1 partition(s)
""[01:42:14.414][DEBUG][org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches:line274] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), toReplace=(), implied=(reservation-topic-0), canUseTopicIds=True) to broker 127.0.0.1:9092 (id: 1001 rack: null)
""[01:42:14.414][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-my-consumer-group-1, correlationId=44) and timeout 30000 to node 1001: FetchRequestData(clusterId=null, replicaId=-1, maxWaitMs=500, minBytes=1, maxBytes=52428800, isolationLevel=0, sessionId=1819239349, sessionEpoch=28, topics=[], forgottenTopicsData=[], rackId='')
""[01:42:14.775][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(1)-127.0.0.1: (port 50899) op = 82
""[01:42:14.775][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(1)-127.0.0.1: (port 50899) op = 80
""[01:42:14.776][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:42:14.777][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:42:14.777][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "[Ljava.rmi.server.ObjID;", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.778][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.server.ObjID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.778][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.server.UID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.778][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.dgc.Lease", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.779][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.dgc.VMID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.779][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "[B", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.780][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(1)-127.0.0.1: (port 50899) op = 82
""[01:42:14.780][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(1)-127.0.0.1: (port 50899) op = 84
""[01:42:14.780][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:42:14.781][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:42:14.782][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:42:14.782][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:42:14.782][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "[Ljava.rmi.server.ObjID;", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.782][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.server.ObjID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.783][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.server.UID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.783][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.dgc.Lease", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.783][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.dgc.VMID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.783][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "[B", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.784][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:42:14.784][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 84
""[01:42:14.785][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:42:14.785][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:42:14.786][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 82
""[01:42:14.786][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(2)-127.0.0.1: (port 50903) op = 80
""[01:42:14.786][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "javax.management.ObjectName", codebase = ""
""[01:42:14.787][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(2)-127.0.0.1: name = "java.rmi.MarshalledObject", codebase = ""
""[01:42:14.787][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  2 unwrapping params with MBean extended ClassLoader.
""[01:42:14.791][DEBUG][javax.management.remote.rmi.log:line230] - connectionId=rmi://127.0.0.1  2, name=org.springframework.boot:type=Admin,name=SpringApplication, operationName=shutdown, signature=null
""[01:42:14.791][INFO ][org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin.shutdown:line159] - Application shutdown requested.
""[01:42:14.791][DEBUG][org.springframework.boot.availability.ApplicationAvailabilityBean.onApplicationEvent:line77] - Application availability state ReadinessState changed from ACCEPTING_TRAFFIC to REFUSING_TRAFFIC
""[01:42:14.791][DEBUG][org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext.doClose:line1052] - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@797c8eb9, started on Fri Aug 18 01:41:56 KST 2023
""[01:42:14.792][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase 2147483647
""[01:42:14.793][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'webSocketHandlerMapping' completed its stop procedure
""[01:42:14.794][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'webServerGracefulShutdown' completed its stop procedure
""[01:42:14.794][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase 2147483646
""[01:42:14.805][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - About to unlock socket for:/[0:0:0:0:0:0:0:1]:8080
""[01:42:14.805][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - Socket unlock completed for:/[0:0:0:0:0:0:0:1]:8080
""[01:42:14.806][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:42:14.807][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Unregister host [localhost] at domain [null] for service [StandardService[Tomcat]]
""[01:42:14.807][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Unregister Context [] for service [StandardService[Tomcat]]
""[01:42:14.807][DEBUG][org.apache.catalina.mapper.MapperListener.log:line173] - Unregister Wrapper [dispatcherServlet] in Context [] for service [StandardService[Tomcat]]
""[01:42:14.808][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Stopping filters
""[01:42:14.808][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Stopping filter 'Tomcat WebSocket (JSR356) Filter'
""[01:42:14.808][DEBUG][org.apache.catalina.core.ApplicationFilterConfig.log:line173] - JMX de-registration complete for filter of type [org.apache.tomcat.websocket.server.WsFilter] and name [Tomcat WebSocket (JSR356) Filter]
""[01:42:14.808][DEBUG][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] -  Stopping filter 'characterEncodingFilter'
""[01:42:14.808][DEBUG][org.apache.catalina.core.ApplicationFilterConfig.log:line173] - JMX de-registration complete for filter of type [org.springframework.boot.web.servlet.filter.OrderedCharacterEncodingFilter] and name [characterEncodingFilter]
""[01:42:14.809][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Stopping
""[01:42:14.809][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - Unloading persisted sessions
""[01:42:14.809][DEBUG][org.apache.catalina.session.StandardManager.log:line173] - No persisted sessions to unload
""[01:42:14.809][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Sending application stop events
""[01:42:14.810][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Processing standard container shutdown
""[01:42:14.810][DEBUG][org.apache.catalina.loader.WebappLoader.log:line173] - Stopping this Loader
""[01:42:14.810][DEBUG][org.apache.catalina.loader.WebappClassLoaderBase.log:line173] - getResourceAsStream(org/apache/catalina/loader/JdbcLeakPrevention.class)
""[01:42:14.810][DEBUG][org.apache.catalina.loader.WebappClassLoaderBase.log:line173] -   Delegating to parent classloader org.springframework.boot.devtools.restart.classloader.RestartClassLoader@739e3cbf
""[01:42:14.811][DEBUG][org.apache.catalina.loader.WebappClassLoaderBase.log:line173] -   --> Returning stream from parent
""[01:42:14.813][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - resetContext Tomcat:j2eeType=WebModule,name=//localhost/,J2EEApplication=none,J2EEServer=none
""[01:42:14.813][DEBUG][org.apache.catalina.core.StandardContext.log:line173] - Stopping complete
""[01:42:14.814][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - Destroy initiated for 0.0.0.0/0.0.0.0:8080
""[01:42:14.815][DEBUG][org.apache.tomcat.util.net.NioEndpoint.log:line173] - Destroy completed for 0.0.0.0/0.0.0.0:8080
""[01:42:14.816][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'webServerStartStop' completed its stop procedure
""[01:42:14.816][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase 2147483547
""[01:42:14.817][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.wakeup:line189] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received user wakeup
""[01:42:14.817][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup:line512] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Raising WakeupException in response to user wakeup
""[01:42:14.818][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:42:14.818][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onLeavePrepare:line773] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Executing onLeavePrepare with generation Generation{generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', protocol='range'} and memberId consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b
""[01:42:14.818][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:42:14.819][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:42:14.819][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - Commit list: {}
""[01:42:14.819][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Member consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:42:14.820][DEBUG][org.apache.kafka.clients.NetworkClient.doSend:line521] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Sending LEAVE_GROUP request with header RequestHeader(apiKey=LEAVE_GROUP, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=45) and timeout 30000 to node 2147482646: LeaveGroupRequestData(groupId='my-consumer-group', memberId='', members=[MemberIdentity(memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null)])
""[01:42:14.820][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:42:14.820][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:42:14.820][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:42:14.820][DEBUG][org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler.shutdown:line224] - Shutting down ExecutorService
""[01:42:14.821][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.run:line1470] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Heartbeat thread has closed
""[01:42:14.821][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onLeavePrepare:line773] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Executing onLeavePrepare with generation Generation{generationId=-1, memberId='', protocol='null'} and memberId 
""[01:42:14.821][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:42:14.822][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:42:14.839][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(3)-127.0.0.1: accepted socket from [127.0.0.1:50931]
""[01:42:14.840][DEBUG][sun.rmi.transport.tcp.log:line228] - RMI TCP Connection(3)-127.0.0.1: (port 50903) op = 80
""[01:42:14.840][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(3)-127.0.0.1: name = "[Ljava.rmi.server.ObjID;", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.840][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(3)-127.0.0.1: name = "java.rmi.server.ObjID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.840][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(3)-127.0.0.1: name = "java.rmi.server.UID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.841][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(3)-127.0.0.1: name = "java.rmi.dgc.VMID", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.841][DEBUG][sun.rmi.loader.log:line228] - RMI TCP Connection(3)-127.0.0.1: name = "[B", codebase = "", defaultLoader = jdk.internal.loader.ClassLoaders$PlatformClassLoader@62bfb989
""[01:42:14.842][DEBUG][org.apache.kafka.clients.NetworkClient.handleCompletedReceives:line879] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Received LEAVE_GROUP response from node 2147482646 for request with header RequestHeader(apiKey=LEAVE_GROUP, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=45): LeaveGroupResponseData(throttleTimeMs=0, errorCode=0, members=[MemberResponse(memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null, errorCode=0)])
""[01:42:14.843][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line1095] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] LeaveGroup response with Generation{generationId=56, memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', protocol='range'} returned successfully: ClientResponse(receivedTimeMs=1692290534842, latencyMs=23, disconnected=false, requestHeader=RequestHeader(apiKey=LEAVE_GROUP, apiVersion=4, clientId=consumer-my-consumer-group-1, correlationId=45), responseBody=LeaveGroupResponseData(throttleTimeMs=0, errorCode=0, members=[MemberResponse(memberId='consumer-my-consumer-group-1-0c140e35-16e8-42ba-9a85-deb5c4332a1b', groupInstanceId=null, errorCode=0)]))
""[01:42:14.843][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:42:14.843][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:42:14.844][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:42:14.849][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-1 unregistered
""[01:42:14.850][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer.close:line2403] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Kafka consumer has been closed
""[01:42:14.850][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:42:14.851][DEBUG][org.springframework.kafka.listener.KafkaMessageListenerContainer.debug:line313] - KafkaMessageListenerContainer [id=org.springframework.kafka.KafkaListenerEndpointContainer#0-0, clientIndex=-0, topicPartitions=[]] stopped normally
""[01:42:14.851][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry' completed its stop procedure
""[01:42:14.851][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.stop:line366] - Stopping beans in phase -2147483647
""[01:42:14.851][DEBUG][org.springframework.context.support.DefaultLifecycleProcessor.lambda$doStop$3:line239] - Bean 'springBootLoggingLifecycle' completed its stop procedure
""[01:42:14.853][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.destroy:line452] - Unregistering JMX-exposed beans on shutdown
""[01:42:14.853][DEBUG][org.springframework.jmx.export.annotation.AnnotationMBeanExporter.unregisterBeans:line186] - Unregistering JMX-exposed beans
""[01:42:14.854][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:42:14.854][DEBUG][org.hibernate.internal.SessionFactoryImpl.close:line821] - HHH000031: Closing
""[01:42:14.854][DEBUG][org.hibernate.type.spi.TypeConfiguration$Scope.unsetSessionFactory:line345] - Un-scoping TypeConfiguration [org.hibernate.type.spi.TypeConfiguration$Scope@3350239b] from SessionFactory [org.hibernate.internal.SessionFactoryImpl@3dcf9af2]
""[01:42:14.854][DEBUG][org.hibernate.service.internal.AbstractServiceRegistryImpl.deRegisterChild:line428] - Implicitly destroying ServiceRegistry on de-registration of all child ServiceRegistries
""[01:42:14.855][DEBUG][org.hibernate.boot.registry.internal.BootstrapServiceRegistryImpl.deRegisterChild:line295] - Implicitly destroying Boot-strap registry on de-registration of all child ServiceRegistries
""[01:42:14.857][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-1 - Shutdown initiated...
""[01:42:14.857][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-1 - Before shutdown stats (total=10, active=0, idle=10, waiting=0)
""[01:42:14.858][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-1 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@e418f5c: (connection evicted)
""[01:42:14.864][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-1 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@5abc6c48: (connection evicted)
""[01:42:14.864][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-1 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@1b816673: (connection evicted)
""[01:42:14.864][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-1 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@2a501b86: (connection evicted)
""[01:42:14.864][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-1 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@7bae993c: (connection evicted)
""[01:42:14.864][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-1 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@7dcf8bc6: (connection evicted)
""[01:42:14.865][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-1 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@7fe08623: (connection evicted)
""[01:42:14.865][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-1 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@2f96b8e3: (connection evicted)
""[01:42:14.865][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-1 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@2fb4fb3d: (connection evicted)
""[01:42:14.865][DEBUG][com.zaxxer.hikari.pool.PoolBase.quietlyCloseConnection:line134] - HikariPool-1 - Closing connection com.mysql.cj.jdbc.ConnectionImpl@69e7b6e: (connection evicted)
""[01:42:14.866][DEBUG][com.zaxxer.hikari.pool.HikariPool.logPoolState:line421] - HikariPool-1 - After shutdown stats (total=0, active=0, idle=0, waiting=0)
""[01:42:14.866][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-1 - Shutdown completed.
""[01:43:09.216][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:43:09.218][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:43:09.266][INFO ][org.springframework.boot.devtools.env.DevToolsPropertyDefaultsPostProcessor.logTo:line255] - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
""[01:43:09.266][INFO ][org.springframework.boot.devtools.env.DevToolsPropertyDefaultsPostProcessor.logTo:line255] - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
""[01:43:09.886][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:43:09.950][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 53 ms. Found 1 JPA repository interfaces.
""[01:43:10.592][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:43:10.606][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:43:10.606][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:43:10.731][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:43:10.731][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 1464 ms
""[01:43:10.881][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-1 - Starting...
""[01:43:11.036][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-1 - Start completed.
""[01:43:11.086][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:43:11.145][INFO ][org.hibernate.Version.logVersion:line44] - HHH000412: Hibernate ORM core version 5.6.15.Final
""[01:43:11.342][INFO ][org.hibernate.annotations.common.Version.<clinit>:line56] - HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
""[01:43:11.495][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:43:12.042][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:43:12.054][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:43:12.093][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:43:12.753][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:43:12.854][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:43:12.951][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:43:12.954][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:43:12.954][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:43:12.955][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692290592951
""[01:43:12.959][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:43:12.987][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:43:12.998][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 4.199 seconds (JVM running for 5.016)
""[01:43:13.300][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:43:13.302][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:43:13.304][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:43:13.306][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] (Re-)joining group
""[01:43:13.324][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:43:13.325][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] (Re-)joining group
""[01:43:13.331][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=58, memberId='consumer-my-consumer-group-1-78ffd9d1-c514-4710-a513-47f038fa5ad1', protocol='range'}
""[01:43:13.334][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Finished assignment for group at generation 58: {consumer-my-consumer-group-1-78ffd9d1-c514-4710-a513-47f038fa5ad1=Assignment(partitions=[reservation-topic-0])}
""[01:43:13.342][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=58, memberId='consumer-my-consumer-group-1-78ffd9d1-c514-4710-a513-47f038fa5ad1', protocol='range'}
""[01:43:13.343][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:43:13.347][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:43:13.362][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=43, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:43:13.364][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:43:19.165][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line22] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:45:07.675][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:45:07.691][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:45:07.699][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:45:07.699][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:45:07.699][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Member consumer-my-consumer-group-1-78ffd9d1-c514-4710-a513-47f038fa5ad1 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:45:07.700][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:45:07.700][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:45:07.701][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:45:07.701][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:45:07.701][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-1, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:45:07.706][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:45:07.707][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:45:07.707][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:45:07.712][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-1 unregistered
""[01:45:07.713][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:45:07.716][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:45:07.720][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-1 - Shutdown initiated...
""[01:45:07.732][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-1 - Shutdown completed.
""[01:45:07.915][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:45:07.915][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:45:08.409][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:45:08.469][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 59 ms. Found 1 JPA repository interfaces.
""[01:45:08.777][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:45:08.778][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:45:08.778][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:45:08.841][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:45:08.842][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 922 ms
""[01:45:08.875][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-2 - Starting...
""[01:45:08.889][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-2 - Start completed.
""[01:45:08.899][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:45:08.908][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:45:08.946][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:45:08.947][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:45:08.967][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:45:09.161][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:45:09.173][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:45:09.181][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:45:09.182][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:45:09.182][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:45:09.182][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692290709182
""[01:45:09.182][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:45:09.188][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:45:09.191][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:45:09.192][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:45:09.192][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:45:09.193][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] (Re-)joining group
""[01:45:09.193][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.374 seconds (JVM running for 121.211)
""[01:45:09.196][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:45:09.199][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:45:09.202][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] (Re-)joining group
""[01:45:09.208][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=60, memberId='consumer-my-consumer-group-2-10d5a1cb-c9a8-426f-a1b4-3ba842cead81', protocol='range'}
""[01:45:09.209][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Finished assignment for group at generation 60: {consumer-my-consumer-group-2-10d5a1cb-c9a8-426f-a1b4-3ba842cead81=Assignment(partitions=[reservation-topic-0])}
""[01:45:09.214][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=60, memberId='consumer-my-consumer-group-2-10d5a1cb-c9a8-426f-a1b4-3ba842cead81', protocol='range'}
""[01:45:09.215][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:45:09.215][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:45:09.220][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=44, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:45:09.220][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:45:13.092][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:45:13.117][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:45:13.126][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:45:13.126][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:45:13.127][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Member consumer-my-consumer-group-2-10d5a1cb-c9a8-426f-a1b4-3ba842cead81 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:45:13.128][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:45:13.128][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:45:13.128][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:45:13.129][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:45:13.130][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-2, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:45:13.139][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:45:13.139][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:45:13.139][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:45:13.142][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-2 unregistered
""[01:45:13.143][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:45:13.145][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:45:13.147][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-2 - Shutdown initiated...
""[01:45:13.152][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-2 - Shutdown completed.
""[01:45:13.350][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:45:13.351][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:45:14.025][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:45:14.081][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 55 ms. Found 1 JPA repository interfaces.
""[01:45:14.196][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:45:14.197][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:45:14.198][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:45:14.266][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:45:14.267][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 910 ms
""[01:45:14.294][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-3 - Starting...
""[01:45:14.307][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-3 - Start completed.
""[01:45:14.317][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:45:14.330][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:45:14.356][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:45:14.356][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:45:14.378][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:45:14.557][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:45:14.566][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:45:14.571][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:45:14.571][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:45:14.571][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:45:14.571][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692290714571
""[01:45:14.571][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:45:14.576][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:45:14.579][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:45:14.580][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:45:14.580][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:45:14.581][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] (Re-)joining group
""[01:45:14.581][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.354 seconds (JVM running for 126.599)
""[01:45:14.583][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:45:14.586][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:45:14.586][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] (Re-)joining group
""[01:45:14.593][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=62, memberId='consumer-my-consumer-group-3-8531f142-0335-4316-8a65-b05088a3efa9', protocol='range'}
""[01:45:14.593][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Finished assignment for group at generation 62: {consumer-my-consumer-group-3-8531f142-0335-4316-8a65-b05088a3efa9=Assignment(partitions=[reservation-topic-0])}
""[01:45:14.598][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=62, memberId='consumer-my-consumer-group-3-8531f142-0335-4316-8a65-b05088a3efa9', protocol='range'}
""[01:45:14.598][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:45:14.599][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:45:14.603][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=44, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:45:14.603][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:47:07.566][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:47:07.580][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:47:07.584][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:47:07.585][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:47:07.585][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Member consumer-my-consumer-group-3-8531f142-0335-4316-8a65-b05088a3efa9 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:47:07.586][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:47:07.586][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:47:07.586][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:47:07.586][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:47:07.587][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-3, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:47:07.594][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:47:07.594][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:47:07.595][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:47:07.597][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-3 unregistered
""[01:47:07.597][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:47:07.599][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:47:07.600][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-3 - Shutdown initiated...
""[01:47:07.604][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-3 - Shutdown completed.
""[01:47:07.762][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:47:07.762][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:47:08.200][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:47:08.265][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 64 ms. Found 1 JPA repository interfaces.
""[01:47:08.520][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:47:08.522][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:47:08.522][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:47:08.605][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:47:08.606][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 840 ms
""[01:47:08.636][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-4 - Starting...
""[01:47:08.650][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-4 - Start completed.
""[01:47:08.661][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:47:08.670][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:47:08.698][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:47:08.698][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:47:08.713][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:47:08.915][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:47:08.925][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:47:08.930][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:47:08.930][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:47:08.931][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:47:08.931][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692290828930
""[01:47:08.931][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:47:08.938][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:47:08.940][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:47:08.941][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:47:08.941][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:47:08.941][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.26 seconds (JVM running for 240.959)
""[01:47:08.942][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] (Re-)joining group
""[01:47:08.943][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:47:08.947][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:47:08.947][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] (Re-)joining group
""[01:47:08.953][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=64, memberId='consumer-my-consumer-group-4-27f4cb97-d384-4a29-b11f-bcaf6dff9878', protocol='range'}
""[01:47:08.954][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Finished assignment for group at generation 64: {consumer-my-consumer-group-4-27f4cb97-d384-4a29-b11f-bcaf6dff9878=Assignment(partitions=[reservation-topic-0])}
""[01:47:08.959][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=64, memberId='consumer-my-consumer-group-4-27f4cb97-d384-4a29-b11f-bcaf6dff9878', protocol='range'}
""[01:47:08.959][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:47:08.959][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:47:08.966][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=44, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:47:08.967][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:47:22.115][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:47:22.131][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:47:22.135][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:47:22.136][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:47:22.136][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Member consumer-my-consumer-group-4-27f4cb97-d384-4a29-b11f-bcaf6dff9878 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:47:22.136][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:47:22.137][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:47:22.137][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:47:22.137][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:47:22.138][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-4, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:47:22.144][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:47:22.144][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:47:22.145][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:47:22.147][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-4 unregistered
""[01:47:22.147][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:47:22.148][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:47:22.149][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-4 - Shutdown initiated...
""[01:47:22.153][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-4 - Shutdown completed.
""[01:47:22.314][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:47:22.315][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:47:22.734][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:47:22.792][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 56 ms. Found 1 JPA repository interfaces.
""[01:47:23.118][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:47:23.120][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:47:23.120][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:47:23.238][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:47:23.238][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 918 ms
""[01:47:23.267][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-5 - Starting...
""[01:47:23.279][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-5 - Start completed.
""[01:47:23.287][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:47:23.298][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:47:23.323][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:47:23.323][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:47:23.340][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:47:23.527][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:47:23.536][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:47:23.540][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:47:23.540][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:47:23.541][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:47:23.541][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692290843540
""[01:47:23.541][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:47:23.545][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:47:23.548][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:47:23.549][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:47:23.549][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:47:23.550][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] (Re-)joining group
""[01:47:23.550][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.322 seconds (JVM running for 255.568)
""[01:47:23.551][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:47:23.554][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:47:23.555][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] (Re-)joining group
""[01:47:23.560][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=66, memberId='consumer-my-consumer-group-5-0e0a90cc-1126-4922-b09c-babbab0f27b9', protocol='range'}
""[01:47:23.560][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Finished assignment for group at generation 66: {consumer-my-consumer-group-5-0e0a90cc-1126-4922-b09c-babbab0f27b9=Assignment(partitions=[reservation-topic-0])}
""[01:47:23.566][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=66, memberId='consumer-my-consumer-group-5-0e0a90cc-1126-4922-b09c-babbab0f27b9', protocol='range'}
""[01:47:23.566][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:47:23.567][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:47:23.571][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=44, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:47:23.572][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:47:32.209][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 2 class path changes (0 additions, 0 deletions, 2 modifications)
""[01:47:32.226][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:47:32.236][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:47:32.237][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:47:32.237][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Member consumer-my-consumer-group-5-0e0a90cc-1126-4922-b09c-babbab0f27b9 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:47:32.238][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:47:32.238][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:47:32.238][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:47:32.239][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:47:32.240][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-5, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:47:32.248][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:47:32.249][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:47:32.249][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:47:32.252][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-5 unregistered
""[01:47:32.252][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:47:32.254][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:47:32.254][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-5 - Shutdown initiated...
""[01:47:32.257][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-5 - Shutdown completed.
""[01:47:32.434][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:47:32.435][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:47:33.137][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:47:33.157][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 19 ms. Found 1 JPA repository interfaces.
""[01:47:33.249][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:47:33.250][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:47:33.250][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:47:33.305][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:47:33.305][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 865 ms
""[01:47:33.332][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-6 - Starting...
""[01:47:33.347][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-6 - Start completed.
""[01:47:33.362][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:47:33.371][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:47:33.395][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:47:33.395][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:47:33.410][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:47:33.582][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:47:33.603][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:47:33.608][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:47:33.608][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:47:33.608][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:47:33.608][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692290853608
""[01:47:33.608][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:47:33.613][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:47:33.617][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:47:33.617][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:47:33.618][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:47:33.621][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.3 seconds (JVM running for 265.639)
""[01:47:33.622][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] (Re-)joining group
""[01:47:33.622][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:47:33.627][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:47:33.627][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] (Re-)joining group
""[01:47:33.634][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=68, memberId='consumer-my-consumer-group-6-fe3ce6b1-593b-42b3-aa96-829d5620928b', protocol='range'}
""[01:47:33.634][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Finished assignment for group at generation 68: {consumer-my-consumer-group-6-fe3ce6b1-593b-42b3-aa96-829d5620928b=Assignment(partitions=[reservation-topic-0])}
""[01:47:33.640][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=68, memberId='consumer-my-consumer-group-6-fe3ce6b1-593b-42b3-aa96-829d5620928b', protocol='range'}
""[01:47:33.641][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:47:33.641][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:47:33.644][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=44, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:47:33.645][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:47:41.420][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line23] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:47:41.426][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line38] - Reservation(id=null, name=, date=2023/08/14, time=13, count=2, number=01012345678)
""[01:48:17.128][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:48:17.145][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:48:17.151][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:48:17.152][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:48:17.153][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Member consumer-my-consumer-group-6-fe3ce6b1-593b-42b3-aa96-829d5620928b sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:48:17.153][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:48:17.153][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:48:17.154][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:48:17.154][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:48:17.154][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-6, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:48:17.160][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:48:17.160][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:48:17.160][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:48:17.162][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-6 unregistered
""[01:48:17.162][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:48:17.164][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:48:17.165][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-6 - Shutdown initiated...
""[01:48:17.170][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-6 - Shutdown completed.
""[01:48:17.319][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:48:17.319][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:48:17.922][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:48:17.963][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 40 ms. Found 1 JPA repository interfaces.
""[01:48:18.090][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:48:18.090][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:48:18.090][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:48:18.147][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:48:18.148][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 826 ms
""[01:48:18.178][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-7 - Starting...
""[01:48:18.194][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-7 - Start completed.
""[01:48:18.203][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:48:18.210][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:48:18.233][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:48:18.233][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:48:18.295][WARN ][org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration.openEntityManagerInViewInterceptor:line223] - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
""[01:48:18.431][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:48:18.441][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:48:18.445][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:48:18.446][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:48:18.446][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:48:18.446][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692290898446
""[01:48:18.446][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:48:18.451][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:48:18.453][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:48:18.453][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:48:18.453][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:48:18.454][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] (Re-)joining group
""[01:48:18.455][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.215 seconds (JVM running for 310.474)
""[01:48:18.457][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:48:18.459][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:48:18.459][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] (Re-)joining group
""[01:48:18.464][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=70, memberId='consumer-my-consumer-group-7-f2b49c8e-0946-45ab-80dc-2516bc290b8f', protocol='range'}
""[01:48:18.465][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Finished assignment for group at generation 70: {consumer-my-consumer-group-7-f2b49c8e-0946-45ab-80dc-2516bc290b8f=Assignment(partitions=[reservation-topic-0])}
""[01:48:18.469][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=70, memberId='consumer-my-consumer-group-7-f2b49c8e-0946-45ab-80dc-2516bc290b8f', protocol='range'}
""[01:48:18.470][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:48:18.470][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:48:18.474][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=45, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:48:18.474][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:48:34.188][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:48:34.279][WARN ][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line137] - SQL Error: 1146, SQLState: 42S02
""[01:48:34.279][ERROR][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line142] - Table 'metadb.reservation' doesn't exist
""[01:48:34.311][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.seek:line1585] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Seeking to offset 45 for partition reservation-topic-0
""[01:48:34.322][ERROR][org.springframework.kafka.listener.KafkaMessageListenerContainer.error:line149] - Error handler threw an exception
"org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:208) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:135) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2707) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2588) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257) ~[spring-kafka-2.8.11.jar:2.8.11]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2720) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2690) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 9 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:363) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
Caused by: org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:259) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:233) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:551) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:241) ~[spring-aop-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy141.save(Unknown Source) ~[na:na]
	at com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(KafkaConsumerService.java:41) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 11 common frames omitted
Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:200) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.dialect.identity.GetGeneratedKeysDelegate.executeAndExtract(GetGeneratedKeysDelegate.java:58) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:43) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3279) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3914) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.action.internal.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:84) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.execute(ActionQueue.java:645) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addResolvedEntityInsertAction(ActionQueue.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addInsertAction(ActionQueue.java:263) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addAction(ActionQueue.java:317) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.addInsertAction(AbstractSaveEventListener.java:329) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:286) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:192) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:122) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.entityIsTransient(DefaultPersistEventListener.java:185) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:128) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:55) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:756) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:742) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:315) ~[spring-orm-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy139.persist(Unknown Source) ~[na:na]
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:666) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:76) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.29.jar:5.3.29]
	... 30 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'metadb.reservation' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1098) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1046) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1371) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1031) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-4.0.3.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-4.0.3.jar:na]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	... 77 common frames omitted
"[01:48:34.803][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:48:34.810][WARN ][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line137] - SQL Error: 1146, SQLState: 42S02
""[01:48:34.811][ERROR][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line142] - Table 'metadb.reservation' doesn't exist
""[01:48:34.838][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.seek:line1585] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Seeking to offset 45 for partition reservation-topic-0
""[01:48:34.845][ERROR][org.springframework.kafka.listener.KafkaMessageListenerContainer.error:line149] - Error handler threw an exception
"org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:208) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:135) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2707) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2588) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257) ~[spring-kafka-2.8.11.jar:2.8.11]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2720) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2690) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 9 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:363) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
Caused by: org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:259) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:233) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:551) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:241) ~[spring-aop-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy141.save(Unknown Source) ~[na:na]
	at com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(KafkaConsumerService.java:41) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 11 common frames omitted
Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:200) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.dialect.identity.GetGeneratedKeysDelegate.executeAndExtract(GetGeneratedKeysDelegate.java:58) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:43) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3279) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3914) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.action.internal.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:84) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.execute(ActionQueue.java:645) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addResolvedEntityInsertAction(ActionQueue.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addInsertAction(ActionQueue.java:263) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addAction(ActionQueue.java:317) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.addInsertAction(AbstractSaveEventListener.java:329) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:286) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:192) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:122) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.entityIsTransient(DefaultPersistEventListener.java:185) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:128) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:55) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:756) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:742) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:315) ~[spring-orm-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy139.persist(Unknown Source) ~[na:na]
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:666) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:76) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.29.jar:5.3.29]
	... 30 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'metadb.reservation' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1098) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1046) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1371) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1031) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-4.0.3.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-4.0.3.jar:na]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	... 77 common frames omitted
"[01:48:35.308][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:48:35.312][WARN ][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line137] - SQL Error: 1146, SQLState: 42S02
""[01:48:35.313][ERROR][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line142] - Table 'metadb.reservation' doesn't exist
""[01:48:35.336][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.seek:line1585] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Seeking to offset 45 for partition reservation-topic-0
""[01:48:35.345][ERROR][org.springframework.kafka.listener.KafkaMessageListenerContainer.error:line149] - Error handler threw an exception
"org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:208) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:135) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2707) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2588) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257) ~[spring-kafka-2.8.11.jar:2.8.11]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2720) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2690) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 9 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:363) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
Caused by: org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:259) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:233) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:551) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:241) ~[spring-aop-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy141.save(Unknown Source) ~[na:na]
	at com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(KafkaConsumerService.java:41) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 11 common frames omitted
Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:200) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.dialect.identity.GetGeneratedKeysDelegate.executeAndExtract(GetGeneratedKeysDelegate.java:58) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:43) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3279) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3914) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.action.internal.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:84) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.execute(ActionQueue.java:645) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addResolvedEntityInsertAction(ActionQueue.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addInsertAction(ActionQueue.java:263) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addAction(ActionQueue.java:317) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.addInsertAction(AbstractSaveEventListener.java:329) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:286) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:192) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:122) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.entityIsTransient(DefaultPersistEventListener.java:185) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:128) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:55) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:756) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:742) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:315) ~[spring-orm-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy139.persist(Unknown Source) ~[na:na]
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:666) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:76) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.29.jar:5.3.29]
	... 30 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'metadb.reservation' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1098) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1046) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1371) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1031) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-4.0.3.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-4.0.3.jar:na]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	... 77 common frames omitted
"[01:48:35.812][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:48:35.817][WARN ][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line137] - SQL Error: 1146, SQLState: 42S02
""[01:48:35.818][ERROR][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line142] - Table 'metadb.reservation' doesn't exist
""[01:48:35.832][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.seek:line1585] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Seeking to offset 45 for partition reservation-topic-0
""[01:48:35.838][ERROR][org.springframework.kafka.listener.KafkaMessageListenerContainer.error:line149] - Error handler threw an exception
"org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:208) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:135) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2707) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2588) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257) ~[spring-kafka-2.8.11.jar:2.8.11]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2720) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2690) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 9 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:363) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
Caused by: org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:259) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:233) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:551) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:241) ~[spring-aop-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy141.save(Unknown Source) ~[na:na]
	at com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(KafkaConsumerService.java:41) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 11 common frames omitted
Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:200) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.dialect.identity.GetGeneratedKeysDelegate.executeAndExtract(GetGeneratedKeysDelegate.java:58) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:43) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3279) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3914) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.action.internal.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:84) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.execute(ActionQueue.java:645) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addResolvedEntityInsertAction(ActionQueue.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addInsertAction(ActionQueue.java:263) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addAction(ActionQueue.java:317) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.addInsertAction(AbstractSaveEventListener.java:329) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:286) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:192) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:122) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.entityIsTransient(DefaultPersistEventListener.java:185) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:128) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:55) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:756) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:742) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:315) ~[spring-orm-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy139.persist(Unknown Source) ~[na:na]
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:666) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:76) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.29.jar:5.3.29]
	... 30 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'metadb.reservation' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1098) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1046) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1371) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1031) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-4.0.3.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-4.0.3.jar:na]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	... 77 common frames omitted
"[01:48:36.318][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:48:36.322][WARN ][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line137] - SQL Error: 1146, SQLState: 42S02
""[01:48:36.322][ERROR][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line142] - Table 'metadb.reservation' doesn't exist
""[01:48:36.346][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.seek:line1585] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Seeking to offset 45 for partition reservation-topic-0
""[01:48:36.352][ERROR][org.springframework.kafka.listener.KafkaMessageListenerContainer.error:line149] - Error handler threw an exception
"org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:208) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:135) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2707) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2588) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257) ~[spring-kafka-2.8.11.jar:2.8.11]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2720) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2690) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 9 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:363) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
Caused by: org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:259) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:233) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:551) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:241) ~[spring-aop-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy141.save(Unknown Source) ~[na:na]
	at com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(KafkaConsumerService.java:41) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 11 common frames omitted
Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:200) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.dialect.identity.GetGeneratedKeysDelegate.executeAndExtract(GetGeneratedKeysDelegate.java:58) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:43) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3279) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3914) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.action.internal.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:84) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.execute(ActionQueue.java:645) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addResolvedEntityInsertAction(ActionQueue.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addInsertAction(ActionQueue.java:263) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addAction(ActionQueue.java:317) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.addInsertAction(AbstractSaveEventListener.java:329) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:286) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:192) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:122) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.entityIsTransient(DefaultPersistEventListener.java:185) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:128) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:55) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:756) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:742) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:315) ~[spring-orm-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy139.persist(Unknown Source) ~[na:na]
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:666) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:76) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.29.jar:5.3.29]
	... 30 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'metadb.reservation' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1098) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1046) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1371) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1031) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-4.0.3.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-4.0.3.jar:na]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	... 77 common frames omitted
"[01:48:36.823][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:48:36.828][WARN ][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line137] - SQL Error: 1146, SQLState: 42S02
""[01:48:36.828][ERROR][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line142] - Table 'metadb.reservation' doesn't exist
""[01:48:36.842][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.seek:line1585] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Seeking to offset 45 for partition reservation-topic-0
""[01:48:36.849][ERROR][org.springframework.kafka.listener.KafkaMessageListenerContainer.error:line149] - Error handler threw an exception
"org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:208) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:135) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2707) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2588) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257) ~[spring-kafka-2.8.11.jar:2.8.11]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2720) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2690) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 9 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:363) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
Caused by: org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:259) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:233) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:551) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:241) ~[spring-aop-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy141.save(Unknown Source) ~[na:na]
	at com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(KafkaConsumerService.java:41) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 11 common frames omitted
Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:200) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.dialect.identity.GetGeneratedKeysDelegate.executeAndExtract(GetGeneratedKeysDelegate.java:58) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:43) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3279) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3914) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.action.internal.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:84) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.execute(ActionQueue.java:645) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addResolvedEntityInsertAction(ActionQueue.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addInsertAction(ActionQueue.java:263) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addAction(ActionQueue.java:317) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.addInsertAction(AbstractSaveEventListener.java:329) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:286) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:192) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:122) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.entityIsTransient(DefaultPersistEventListener.java:185) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:128) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:55) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:756) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:742) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:315) ~[spring-orm-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy139.persist(Unknown Source) ~[na:na]
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:666) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:76) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.29.jar:5.3.29]
	... 30 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'metadb.reservation' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1098) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1046) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1371) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1031) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-4.0.3.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-4.0.3.jar:na]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	... 77 common frames omitted
"[01:48:37.329][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:48:37.334][WARN ][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line137] - SQL Error: 1146, SQLState: 42S02
""[01:48:37.334][ERROR][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line142] - Table 'metadb.reservation' doesn't exist
""[01:48:37.352][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.seek:line1585] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Seeking to offset 45 for partition reservation-topic-0
""[01:48:37.359][ERROR][org.springframework.kafka.listener.KafkaMessageListenerContainer.error:line149] - Error handler threw an exception
"org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:208) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:135) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2707) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2588) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257) ~[spring-kafka-2.8.11.jar:2.8.11]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2720) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2690) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 9 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:363) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
Caused by: org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:259) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:233) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:551) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:241) ~[spring-aop-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy141.save(Unknown Source) ~[na:na]
	at com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(KafkaConsumerService.java:41) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 11 common frames omitted
Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:200) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.dialect.identity.GetGeneratedKeysDelegate.executeAndExtract(GetGeneratedKeysDelegate.java:58) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:43) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3279) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3914) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.action.internal.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:84) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.execute(ActionQueue.java:645) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addResolvedEntityInsertAction(ActionQueue.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addInsertAction(ActionQueue.java:263) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addAction(ActionQueue.java:317) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.addInsertAction(AbstractSaveEventListener.java:329) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:286) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:192) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:122) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.entityIsTransient(DefaultPersistEventListener.java:185) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:128) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:55) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:756) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:742) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:315) ~[spring-orm-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy139.persist(Unknown Source) ~[na:na]
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:666) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:76) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.29.jar:5.3.29]
	... 30 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'metadb.reservation' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1098) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1046) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1371) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1031) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-4.0.3.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-4.0.3.jar:na]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	... 77 common frames omitted
"[01:48:37.834][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:48:37.838][WARN ][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line137] - SQL Error: 1146, SQLState: 42S02
""[01:48:37.839][ERROR][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line142] - Table 'metadb.reservation' doesn't exist
""[01:48:37.853][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.seek:line1585] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Seeking to offset 45 for partition reservation-topic-0
""[01:48:37.859][ERROR][org.springframework.kafka.listener.KafkaMessageListenerContainer.error:line149] - Error handler threw an exception
"org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:208) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:135) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2707) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2588) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257) ~[spring-kafka-2.8.11.jar:2.8.11]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2720) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2690) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 9 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:363) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
Caused by: org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:259) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:233) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:551) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:241) ~[spring-aop-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy141.save(Unknown Source) ~[na:na]
	at com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(KafkaConsumerService.java:41) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 11 common frames omitted
Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:200) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.dialect.identity.GetGeneratedKeysDelegate.executeAndExtract(GetGeneratedKeysDelegate.java:58) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:43) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3279) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3914) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.action.internal.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:84) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.execute(ActionQueue.java:645) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addResolvedEntityInsertAction(ActionQueue.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addInsertAction(ActionQueue.java:263) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addAction(ActionQueue.java:317) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.addInsertAction(AbstractSaveEventListener.java:329) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:286) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:192) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:122) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.entityIsTransient(DefaultPersistEventListener.java:185) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:128) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:55) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:756) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:742) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:315) ~[spring-orm-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy139.persist(Unknown Source) ~[na:na]
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:666) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:76) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.29.jar:5.3.29]
	... 30 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'metadb.reservation' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1098) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1046) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1371) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1031) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-4.0.3.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-4.0.3.jar:na]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	... 77 common frames omitted
"[01:48:38.339][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:48:38.342][WARN ][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line137] - SQL Error: 1146, SQLState: 42S02
""[01:48:38.343][ERROR][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line142] - Table 'metadb.reservation' doesn't exist
""[01:48:38.360][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.seek:line1585] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Seeking to offset 45 for partition reservation-topic-0
""[01:48:38.366][ERROR][org.springframework.kafka.listener.KafkaMessageListenerContainer.error:line149] - Error handler threw an exception
"org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:208) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:135) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2707) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2588) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257) ~[spring-kafka-2.8.11.jar:2.8.11]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2720) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2690) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 9 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:363) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
Caused by: org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:259) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:233) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:551) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:241) ~[spring-aop-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy141.save(Unknown Source) ~[na:na]
	at com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(KafkaConsumerService.java:41) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 11 common frames omitted
Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:200) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.dialect.identity.GetGeneratedKeysDelegate.executeAndExtract(GetGeneratedKeysDelegate.java:58) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:43) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3279) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3914) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.action.internal.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:84) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.execute(ActionQueue.java:645) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addResolvedEntityInsertAction(ActionQueue.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addInsertAction(ActionQueue.java:263) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addAction(ActionQueue.java:317) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.addInsertAction(AbstractSaveEventListener.java:329) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:286) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:192) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:122) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.entityIsTransient(DefaultPersistEventListener.java:185) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:128) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:55) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:756) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:742) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:315) ~[spring-orm-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy139.persist(Unknown Source) ~[na:na]
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:666) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:76) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.29.jar:5.3.29]
	... 30 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'metadb.reservation' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1098) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1046) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1371) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1031) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-4.0.3.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-4.0.3.jar:na]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	... 77 common frames omitted
"[01:48:38.844][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:48:38.848][WARN ][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line137] - SQL Error: 1146, SQLState: 42S02
""[01:48:38.848][ERROR][org.hibernate.engine.jdbc.spi.SqlExceptionHelper.logExceptions:line142] - Table 'metadb.reservation' doesn't exist
""[01:48:38.857][ERROR][org.springframework.kafka.listener.DefaultErrorHandler.error:line149] - Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for reservation-topic-0@45
"org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(java.lang.String) throws java.io.IOException' threw exception; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2720) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2690) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257) ~[spring-kafka-2.8.11.jar:2.8.11]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:363) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
Caused by: org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:259) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:233) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:551) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:241) ~[spring-aop-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy141.save(Unknown Source) ~[na:na]
	at com.jinseong.demo.service.KafkaConsumerService.receiveReservationData(KafkaConsumerService.java:41) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-5.3.29.jar:5.3.29]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-2.8.11.jar:2.8.11]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670) ~[spring-kafka-2.8.11.jar:2.8.11]
	... 11 common frames omitted
Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:200) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.dialect.identity.GetGeneratedKeysDelegate.executeAndExtract(GetGeneratedKeysDelegate.java:58) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:43) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3279) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3914) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.action.internal.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:84) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.execute(ActionQueue.java:645) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addResolvedEntityInsertAction(ActionQueue.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addInsertAction(ActionQueue.java:263) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.engine.spi.ActionQueue.addAction(ActionQueue.java:317) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.addInsertAction(AbstractSaveEventListener.java:329) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:286) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:192) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:122) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.entityIsTransient(DefaultPersistEventListener.java:185) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:128) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.internal.DefaultPersistEventListener.onPersist(DefaultPersistEventListener.java:55) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:756) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:742) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:315) ~[spring-orm-5.3.29.jar:5.3.29]
	at jdk.proxy10/jdk.proxy10.$Proxy139.persist(Unknown Source) ~[na:na]
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:666) ~[spring-data-jpa-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:76) ~[spring-data-commons-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.29.jar:5.3.29]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.29.jar:5.3.29]
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.29.jar:5.3.29]
	... 30 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'metadb.reservation' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1098) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1046) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1371) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1031) ~[mysql-connector-java-8.0.27.jar:8.0.27]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61) ~[HikariCP-4.0.3.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java) ~[HikariCP-4.0.3.jar:na]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	... 77 common frames omitted
"[01:50:35.116][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:50:35.133][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:50:35.137][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:50:35.137][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:50:35.138][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Member consumer-my-consumer-group-7-f2b49c8e-0946-45ab-80dc-2516bc290b8f sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:50:35.138][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:50:35.138][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:50:35.138][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:50:35.139][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:50:35.139][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-7, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:50:35.143][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:50:35.144][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:50:35.144][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:50:35.145][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-7 unregistered
""[01:50:35.145][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:50:35.146][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:50:35.147][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-7 - Shutdown initiated...
""[01:50:35.148][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-7 - Shutdown completed.
""[01:50:35.248][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:50:35.248][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:50:35.468][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:50:35.485][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 17 ms. Found 1 JPA repository interfaces.
""[01:50:35.563][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:50:35.564][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:50:35.564][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:50:35.612][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:50:35.612][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 361 ms
""[01:50:35.642][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:50:35.650][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-8 - Starting...
""[01:50:35.660][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-8 - Start completed.
""[01:50:35.660][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:50:35.857][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:50:35.857][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:50:36.015][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:50:36.025][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:50:36.028][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:50:36.029][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:50:36.029][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:50:36.029][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692291036029
""[01:50:36.029][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:50:36.036][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:50:36.038][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:50:36.038][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:50:36.038][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:50:36.039][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] (Re-)joining group
""[01:50:36.041][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 0.839 seconds (JVM running for 448.058)
""[01:50:36.042][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:50:36.043][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:50:36.043][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] (Re-)joining group
""[01:50:36.047][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=72, memberId='consumer-my-consumer-group-8-74d31bcb-3a88-4ea0-b9dd-dcc3e094fed0', protocol='range'}
""[01:50:36.048][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Finished assignment for group at generation 72: {consumer-my-consumer-group-8-74d31bcb-3a88-4ea0-b9dd-dcc3e094fed0=Assignment(partitions=[reservation-topic-0])}
""[01:50:36.053][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=72, memberId='consumer-my-consumer-group-8-74d31bcb-3a88-4ea0-b9dd-dcc3e094fed0', protocol='range'}
""[01:50:36.053][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:50:36.053][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:50:36.058][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=46, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:50:36.058][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:50:46.580][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:50:46.619][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - Reservation(id=1, name=, date=2023/08/14, time=13, count=2, number=01012345678)
""[01:51:06.947][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
""[01:51:06.948][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line525] - Initializing Servlet 'dispatcherServlet'
""[01:51:06.949][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line547] - Completed initialization in 0 ms
""[01:51:07.240][WARN ][org.springframework.web.servlet.PageNotFound.noHandlerFound:line1283] - No mapping for GET /favicon.ico
""[01:51:13.898][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:51:13.918][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - Reservation(id=2, name=, date=2023/08/14, time=13, count=2, number=01012345678)
""[01:51:20.040][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:51:20.055][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - Reservation(id=3, name=, date=2023/08/14, time=13, count=2, number=01012345678)
""[01:51:20.888][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:51:20.903][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - Reservation(id=4, name=, date=2023/08/14, time=13, count=2, number=01012345678)
""[01:52:26.155][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:52:26.175][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - Reservation(id=5, name=, date=2023/08/14, time=13, count=2, number=01012345678)
""[01:53:18.480][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 2 class path changes (0 additions, 0 deletions, 2 modifications)
""[01:53:18.492][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:53:18.493][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Destroying Spring FrameworkServlet 'dispatcherServlet'
""[01:53:18.497][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:53:18.497][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:53:18.497][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Member consumer-my-consumer-group-8-74d31bcb-3a88-4ea0-b9dd-dcc3e094fed0 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:53:18.498][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:53:18.498][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:53:18.498][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:53:18.499][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:53:18.499][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-8, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:53:18.506][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:53:18.506][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:53:18.506][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:53:18.508][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-8 unregistered
""[01:53:18.509][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:53:18.510][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:53:18.511][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-8 - Shutdown initiated...
""[01:53:18.514][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-8 - Shutdown completed.
""[01:53:18.701][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:53:18.702][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:53:19.199][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:53:19.222][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 22 ms. Found 1 JPA repository interfaces.
""[01:53:19.511][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:53:19.513][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:53:19.513][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:53:19.620][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:53:19.621][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 914 ms
""[01:53:19.694][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:53:19.705][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-9 - Starting...
""[01:53:19.718][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-9 - Start completed.
""[01:53:19.719][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:53:19.760][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:53:19.760][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:53:19.989][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:53:20.004][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:53:20.008][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:53:20.008][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:53:20.008][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:53:20.009][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692291200008
""[01:53:20.009][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:53:20.015][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:53:20.016][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:53:20.017][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:53:20.017][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:53:20.018][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] (Re-)joining group
""[01:53:20.020][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.415 seconds (JVM running for 612.037)
""[01:53:20.021][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:53:20.024][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:53:20.024][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] (Re-)joining group
""[01:53:20.029][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=74, memberId='consumer-my-consumer-group-9-9cb57401-0a63-43f5-a2e6-d6365e6da24a', protocol='range'}
""[01:53:20.030][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Finished assignment for group at generation 74: {consumer-my-consumer-group-9-9cb57401-0a63-43f5-a2e6-d6365e6da24a=Assignment(partitions=[reservation-topic-0])}
""[01:53:20.037][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=74, memberId='consumer-my-consumer-group-9-9cb57401-0a63-43f5-a2e6-d6365e6da24a', protocol='range'}
""[01:53:20.037][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:53:20.037][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:53:20.043][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=51, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:53:20.043][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:53:30.079][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:53:30.105][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=6, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[01:53:32.569][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
""[01:53:32.570][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line525] - Initializing Servlet 'dispatcherServlet'
""[01:53:32.571][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line547] - Completed initialization in 1 ms
""[01:53:39.492][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:53:39.508][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=7, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[01:54:57.924][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:54:57.943][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=8, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[01:55:18.323][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:55:18.336][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:55:18.336][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Destroying Spring FrameworkServlet 'dispatcherServlet'
""[01:55:18.340][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:55:18.341][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:55:18.341][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Member consumer-my-consumer-group-9-9cb57401-0a63-43f5-a2e6-d6365e6da24a sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:55:18.341][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:55:18.341][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:55:18.341][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:55:18.342][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:55:18.342][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-9, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:55:18.347][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:55:18.347][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:55:18.348][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:55:18.350][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-9 unregistered
""[01:55:18.350][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:55:18.352][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:55:18.354][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-9 - Shutdown initiated...
""[01:55:18.358][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-9 - Shutdown completed.
""[01:55:18.560][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:55:18.560][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:55:19.073][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:55:19.157][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 83 ms. Found 1 JPA repository interfaces.
""[01:55:19.453][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:55:19.454][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:55:19.454][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:55:19.512][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:55:19.512][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 947 ms
""[01:55:19.546][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:55:19.553][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-10 - Starting...
""[01:55:19.564][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-10 - Start completed.
""[01:55:19.564][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:55:19.606][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:55:19.607][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:55:19.798][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:55:19.808][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:55:19.812][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:55:19.813][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:55:19.813][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:55:19.813][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692291319813
""[01:55:19.813][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:55:19.818][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:55:19.821][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:55:19.822][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:55:19.822][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:55:19.823][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.359 seconds (JVM running for 731.841)
""[01:55:19.823][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] (Re-)joining group
""[01:55:19.825][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:55:19.828][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:55:19.828][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] (Re-)joining group
""[01:55:19.833][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=76, memberId='consumer-my-consumer-group-10-48a9fd68-e491-459b-9d93-149cbd2bbdd0', protocol='range'}
""[01:55:19.834][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Finished assignment for group at generation 76: {consumer-my-consumer-group-10-48a9fd68-e491-459b-9d93-149cbd2bbdd0=Assignment(partitions=[reservation-topic-0])}
""[01:55:19.840][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=76, memberId='consumer-my-consumer-group-10-48a9fd68-e491-459b-9d93-149cbd2bbdd0', protocol='range'}
""[01:55:19.841][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:55:19.841][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:55:19.844][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=54, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:55:19.845][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:55:23.457][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:55:23.488][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:55:23.493][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:55:23.494][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:55:23.494][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Member consumer-my-consumer-group-10-48a9fd68-e491-459b-9d93-149cbd2bbdd0 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:55:23.494][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:55:23.494][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:55:23.494][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:55:23.494][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:55:23.495][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-10, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:55:23.504][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:55:23.504][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:55:23.504][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:55:23.506][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-10 unregistered
""[01:55:23.507][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:55:23.508][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:55:23.510][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-10 - Shutdown initiated...
""[01:55:23.514][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-10 - Shutdown completed.
""[01:55:23.800][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:55:23.800][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:55:24.048][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:55:24.068][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 19 ms. Found 1 JPA repository interfaces.
""[01:55:24.168][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:55:24.169][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:55:24.169][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:55:24.231][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:55:24.231][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 428 ms
""[01:55:24.263][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:55:24.273][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-11 - Starting...
""[01:55:24.283][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-11 - Start completed.
""[01:55:24.283][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:55:24.313][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:55:24.313][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:55:24.493][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:55:24.504][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:55:24.508][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:55:24.508][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:55:24.508][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:55:24.508][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692291324508
""[01:55:24.509][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:55:24.514][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:55:24.516][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:55:24.516][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:55:24.517][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:55:24.518][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] (Re-)joining group
""[01:55:24.518][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 0.855 seconds (JVM running for 736.536)
""[01:55:24.519][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:55:24.522][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:55:24.523][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] (Re-)joining group
""[01:55:24.528][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=78, memberId='consumer-my-consumer-group-11-d580bf47-7f8f-421d-a3a0-455543bb8eb0', protocol='range'}
""[01:55:24.529][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Finished assignment for group at generation 78: {consumer-my-consumer-group-11-d580bf47-7f8f-421d-a3a0-455543bb8eb0=Assignment(partitions=[reservation-topic-0])}
""[01:55:24.534][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=78, memberId='consumer-my-consumer-group-11-d580bf47-7f8f-421d-a3a0-455543bb8eb0', protocol='range'}
""[01:55:24.535][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:55:24.535][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:55:24.541][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=54, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:55:24.541][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:55:28.019][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[01:55:28.034][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[01:55:28.042][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[01:55:28.043][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[01:55:28.043][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Member consumer-my-consumer-group-11-d580bf47-7f8f-421d-a3a0-455543bb8eb0 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[01:55:28.043][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:55:28.043][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:55:28.043][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[01:55:28.044][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[01:55:28.044][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-11, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[01:55:28.051][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[01:55:28.051][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[01:55:28.052][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[01:55:28.053][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-11 unregistered
""[01:55:28.054][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[01:55:28.055][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[01:55:28.056][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-11 - Shutdown initiated...
""[01:55:28.060][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-11 - Shutdown completed.
""[01:55:28.228][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[01:55:28.228][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[01:55:28.867][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[01:55:28.954][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 86 ms. Found 1 JPA repository interfaces.
""[01:55:29.096][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[01:55:29.097][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[01:55:29.097][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[01:55:29.152][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[01:55:29.153][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 921 ms
""[01:55:29.182][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[01:55:29.190][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-12 - Starting...
""[01:55:29.201][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-12 - Start completed.
""[01:55:29.201][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[01:55:29.233][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[01:55:29.234][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[01:55:29.423][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[01:55:29.432][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[01:55:29.436][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[01:55:29.436][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[01:55:29.436][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[01:55:29.436][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692291329436
""[01:55:29.436][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[01:55:29.441][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[01:55:29.443][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[01:55:29.444][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[01:55:29.444][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[01:55:29.445][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] (Re-)joining group
""[01:55:29.445][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.292 seconds (JVM running for 741.463)
""[01:55:29.446][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[01:55:29.449][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[01:55:29.450][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] (Re-)joining group
""[01:55:29.455][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=80, memberId='consumer-my-consumer-group-12-0df13c42-d830-4303-8274-5cd5ce6528d8', protocol='range'}
""[01:55:29.456][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Finished assignment for group at generation 80: {consumer-my-consumer-group-12-0df13c42-d830-4303-8274-5cd5ce6528d8=Assignment(partitions=[reservation-topic-0])}
""[01:55:29.461][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=80, memberId='consumer-my-consumer-group-12-0df13c42-d830-4303-8274-5cd5ce6528d8', protocol='range'}
""[01:55:29.462][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[01:55:29.462][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[01:55:29.466][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=54, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[01:55:29.466][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[01:55:35.472][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:55:35.492][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=9, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[01:55:36.665][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
""[01:55:36.666][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line525] - Initializing Servlet 'dispatcherServlet'
""[01:55:36.666][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line547] - Completed initialization in 0 ms
""[01:55:38.934][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:55:38.952][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=10, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[01:55:55.641][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:55:55.659][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=11, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[01:59:46.480][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[01:59:46.497][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=12, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[02:01:41.904][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:01:41.922][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=13, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[02:01:50.749][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:01:50.768][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=14, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[02:02:11.644][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:02:11.659][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=15, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[02:02:27.198][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:02:27.215][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=16, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[02:03:13.613][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:03:13.631][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=17, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[02:03:22.276][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:03:22.293][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=18, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[02:04:29.564][INFO ][org.apache.kafka.clients.NetworkClient.handleDisconnections:line935] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Node -1 disconnected.
""[02:04:50.127][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:04:50.143][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=19, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[02:06:03.330][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:06:03.347][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=20, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[02:07:36.818][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:07:36.837][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=21, name=, date=2023/08/14, time=13, count=2, number=01012345678
""[02:09:42.195][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:09:42.210][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:09:42.211][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Destroying Spring FrameworkServlet 'dispatcherServlet'
""[02:09:42.215][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:09:42.215][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:09:42.215][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Member consumer-my-consumer-group-12-0df13c42-d830-4303-8274-5cd5ce6528d8 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:09:42.215][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:09:42.216][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:09:42.216][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:09:42.216][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:09:42.216][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-12, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:09:42.222][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:09:42.223][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:09:42.223][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:09:42.224][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-12 unregistered
""[02:09:42.225][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:09:42.225][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:09:42.226][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-12 - Shutdown initiated...
""[02:09:42.229][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-12 - Shutdown completed.
""[02:09:42.406][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:09:42.406][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:09:43.022][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:09:43.042][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 19 ms. Found 1 JPA repository interfaces.
""[02:09:43.138][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:09:43.139][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:09:43.139][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:09:43.195][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:09:43.196][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 786 ms
""[02:09:43.237][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:09:43.247][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-13 - Starting...
""[02:09:43.258][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-13 - Start completed.
""[02:09:43.259][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:09:43.292][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:09:43.293][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:09:43.504][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:09:43.515][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:09:43.519][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:09:43.519][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:09:43.519][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:09:43.519][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692292183519
""[02:09:43.520][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:09:43.525][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:09:43.528][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:09:43.528][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:09:43.528][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:09:43.529][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.206 seconds (JVM running for 1595.547)
""[02:09:43.529][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] (Re-)joining group
""[02:09:43.531][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:09:43.534][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:09:43.534][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] (Re-)joining group
""[02:09:43.542][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=82, memberId='consumer-my-consumer-group-13-15742bf3-6d6c-49b5-a648-c227848520e5', protocol='range'}
""[02:09:43.543][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Finished assignment for group at generation 82: {consumer-my-consumer-group-13-15742bf3-6d6c-49b5-a648-c227848520e5=Assignment(partitions=[reservation-topic-0])}
""[02:09:43.548][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=82, memberId='consumer-my-consumer-group-13-15742bf3-6d6c-49b5-a648-c227848520e5', protocol='range'}
""[02:09:43.549][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:09:43.549][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:09:43.553][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=67, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:09:43.553][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:09:53.651][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:09:53.668][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:09:53.672][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:09:53.672][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:09:53.672][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Member consumer-my-consumer-group-13-15742bf3-6d6c-49b5-a648-c227848520e5 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:09:53.673][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:09:53.673][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:09:53.673][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:09:53.677][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:09:53.677][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-13, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:09:53.689][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:09:53.689][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:09:53.690][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:09:53.692][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-13 unregistered
""[02:09:53.692][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:09:53.694][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:09:53.695][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-13 - Shutdown initiated...
""[02:09:53.699][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-13 - Shutdown completed.
""[02:09:53.901][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:09:53.902][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:09:54.544][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:09:54.566][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 21 ms. Found 1 JPA repository interfaces.
""[02:09:54.661][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:09:54.662][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:09:54.662][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:09:54.721][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:09:54.721][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 810 ms
""[02:09:54.755][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:09:54.764][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-14 - Starting...
""[02:09:54.776][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-14 - Start completed.
""[02:09:54.777][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:09:54.807][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:09:54.807][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:09:54.988][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:09:54.997][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:09:55.001][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:09:55.001][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:09:55.001][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:09:55.001][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692292195001
""[02:09:55.001][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:09:55.006][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:09:55.008][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:09:55.009][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:09:55.009][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:09:55.010][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.214 seconds (JVM running for 1607.027)
""[02:09:55.010][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] (Re-)joining group
""[02:09:55.011][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:09:55.024][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:09:55.025][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] (Re-)joining group
""[02:09:55.031][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=84, memberId='consumer-my-consumer-group-14-2edd9e6e-a3d4-4dda-8cb4-1bc48e6ad950', protocol='range'}
""[02:09:55.031][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Finished assignment for group at generation 84: {consumer-my-consumer-group-14-2edd9e6e-a3d4-4dda-8cb4-1bc48e6ad950=Assignment(partitions=[reservation-topic-0])}
""[02:09:55.037][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=84, memberId='consumer-my-consumer-group-14-2edd9e6e-a3d4-4dda-8cb4-1bc48e6ad950', protocol='range'}
""[02:09:55.038][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:09:55.038][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:09:55.042][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=67, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:09:55.043][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:10:06.008][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
""[02:10:06.008][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line525] - Initializing Servlet 'dispatcherServlet'
""[02:10:06.009][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line547] - Completed initialization in 1 ms
""[02:10:12.941][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:10:12.963][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=22, name=Name, date=Date, time=Time, count=Count, number=Number
""[02:10:22.276][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:10:22.315][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:10:22.316][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Destroying Spring FrameworkServlet 'dispatcherServlet'
""[02:10:22.325][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:10:22.326][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:10:22.327][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Member consumer-my-consumer-group-14-2edd9e6e-a3d4-4dda-8cb4-1bc48e6ad950 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:10:22.327][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:10:22.327][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:10:22.327][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:10:22.328][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:10:22.328][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-14, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:10:22.334][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:10:22.334][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:10:22.335][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:10:22.338][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-14 unregistered
""[02:10:22.339][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:10:22.340][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:10:22.340][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-14 - Shutdown initiated...
""[02:10:22.344][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-14 - Shutdown completed.
""[02:10:22.621][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:10:22.621][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:10:22.889][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:10:22.913][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 24 ms. Found 1 JPA repository interfaces.
""[02:10:23.009][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:10:23.010][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:10:23.010][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:10:23.082][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:10:23.082][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 457 ms
""[02:10:23.113][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:10:23.122][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-15 - Starting...
""[02:10:23.134][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-15 - Start completed.
""[02:10:23.135][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:10:23.168][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:10:23.169][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:10:23.356][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:10:23.371][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:10:23.375][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:10:23.376][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:10:23.376][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:10:23.376][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692292223376
""[02:10:23.376][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:10:23.382][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:10:23.384][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:10:23.384][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:10:23.384][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:10:23.385][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] (Re-)joining group
""[02:10:23.386][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 0.9 seconds (JVM running for 1635.404)
""[02:10:23.388][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:10:23.390][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:10:23.390][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] (Re-)joining group
""[02:10:23.396][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=86, memberId='consumer-my-consumer-group-15-02805675-b326-44d4-972d-8ade3b1f2df9', protocol='range'}
""[02:10:23.396][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Finished assignment for group at generation 86: {consumer-my-consumer-group-15-02805675-b326-44d4-972d-8ade3b1f2df9=Assignment(partitions=[reservation-topic-0])}
""[02:10:23.406][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=86, memberId='consumer-my-consumer-group-15-02805675-b326-44d4-972d-8ade3b1f2df9', protocol='range'}
""[02:10:23.407][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:10:23.407][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:10:23.413][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=68, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:10:23.413][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:10:23.424][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:10:23.445][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=23, name=: , date=: 2023/08/14, time=: 13:00, count=: 2, number=: 01012345678
""[02:10:25.846][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
""[02:10:25.847][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line525] - Initializing Servlet 'dispatcherServlet'
""[02:10:25.848][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line547] - Completed initialization in 1 ms
""[02:10:27.685][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:10:27.702][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=24, name=: , date=: 2023/08/14, time=: 13:00, count=: 2, number=: 01012345678
""[02:10:44.894][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:10:44.907][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:10:44.907][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Destroying Spring FrameworkServlet 'dispatcherServlet'
""[02:10:44.914][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:10:44.914][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:10:44.914][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Member consumer-my-consumer-group-15-02805675-b326-44d4-972d-8ade3b1f2df9 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:10:44.914][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:10:44.915][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:10:44.915][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:10:44.916][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:10:44.916][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-15, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:10:44.922][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:10:44.922][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:10:44.922][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:10:44.924][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-15 unregistered
""[02:10:44.924][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:10:44.925][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:10:44.926][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-15 - Shutdown initiated...
""[02:10:44.929][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-15 - Shutdown completed.
""[02:10:45.145][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:10:45.146][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:10:45.588][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:10:45.624][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 36 ms. Found 1 JPA repository interfaces.
""[02:10:45.965][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:10:45.966][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:10:45.966][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:10:46.024][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:10:46.025][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 875 ms
""[02:10:46.056][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:10:46.065][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-16 - Starting...
""[02:10:46.077][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-16 - Start completed.
""[02:10:46.077][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:10:46.106][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:10:46.106][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:10:46.298][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:10:46.308][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:10:46.312][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:10:46.313][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:10:46.313][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:10:46.313][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692292246313
""[02:10:46.313][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:10:46.317][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:10:46.320][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:10:46.320][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:10:46.320][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:10:46.321][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] (Re-)joining group
""[02:10:46.322][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.267 seconds (JVM running for 1658.339)
""[02:10:46.323][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:10:46.326][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:10:46.326][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] (Re-)joining group
""[02:10:46.331][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=88, memberId='consumer-my-consumer-group-16-6c4b29e8-dc37-47c5-a3e8-413e1230f678', protocol='range'}
""[02:10:46.331][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Finished assignment for group at generation 88: {consumer-my-consumer-group-16-6c4b29e8-dc37-47c5-a3e8-413e1230f678=Assignment(partitions=[reservation-topic-0])}
""[02:10:46.336][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=88, memberId='consumer-my-consumer-group-16-6c4b29e8-dc37-47c5-a3e8-413e1230f678', protocol='range'}
""[02:10:46.336][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:10:46.336][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:10:46.340][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=70, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:10:46.340][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:11:06.215][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
""[02:11:06.215][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line525] - Initializing Servlet 'dispatcherServlet'
""[02:11:06.216][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line547] - Completed initialization in 0 ms
""[02:11:10.224][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:10.245][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=25, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:17.032][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:17.049][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=26, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:18.204][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:18.220][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=27, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:19.336][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:19.355][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=28, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:20.402][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:20.419][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=29, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:21.903][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:21.920][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=30, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:22.938][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:22.955][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=31, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:46.661][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:46.678][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=32, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:51.997][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:52.011][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=33, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:54.457][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:54.473][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=34, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:55.440][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:55.454][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=35, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:56.328][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:56.344][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=36, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:57.153][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:57.170][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=37, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:11:57.935][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:11:57.951][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=38, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:12:24.056][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:12:24.075][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=39, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:12:24.851][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:12:24.867][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=40, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:12:25.569][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:12:25.584][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=41, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:12:26.341][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:12:26.359][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=42, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:12:26.966][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:12:26.982][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=43, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:12:27.666][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:12:27.682][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=44, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:16:18.615][WARN ][org.springframework.web.servlet.PageNotFound.noHandlerFound:line1283] - No mapping for GET /manageReservation
""[02:16:38.239][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:16:38.256][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=45, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:17:16.003][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:17:16.018][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=46, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:19:02.845][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:19:02.859][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=47, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:19:46.553][INFO ][org.apache.kafka.clients.NetworkClient.handleDisconnections:line935] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Node -1 disconnected.
""[02:21:39.823][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:21:39.844][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=48, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:21:49.685][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:21:49.704][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=49, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:21:50.498][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:21:50.515][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=50, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:21:51.115][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:21:51.132][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=51, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:21:51.789][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:21:51.805][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=52, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:21:53.105][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:21:53.121][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=53, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:21:53.557][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:21:53.571][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=54, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:21:53.982][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:21:53.996][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=55, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:21:54.385][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:21:54.399][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=56, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:21:54.717][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line27] - message --> Name: , Date: 2023/08/14, Time: 13:00, Count: 2,Number : 01012345678
""[02:21:54.732][INFO ][com.jinseong.demo.service.KafkaConsumerService.receiveReservationData:line43] - id=57, name=, date=2023/08/14, time=13:00, count=2, number=01012345678
""[02:23:25.661][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 3 class path changes (0 additions, 0 deletions, 3 modifications)
""[02:23:25.678][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:23:25.678][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Destroying Spring FrameworkServlet 'dispatcherServlet'
""[02:23:25.684][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:23:25.684][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:23:25.684][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Member consumer-my-consumer-group-16-6c4b29e8-dc37-47c5-a3e8-413e1230f678 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:23:25.684][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:23:25.685][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:23:25.685][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:23:25.685][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:23:25.685][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-16, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:23:25.692][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:23:25.692][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:23:25.692][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:23:25.694][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-16 unregistered
""[02:23:25.694][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:23:25.695][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:23:25.696][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-16 - Shutdown initiated...
""[02:23:25.699][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-16 - Shutdown completed.
""[02:23:25.857][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:23:25.858][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:23:26.508][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:23:26.539][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 30 ms. Found 1 JPA repository interfaces.
""[02:23:26.656][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:23:26.657][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:23:26.657][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:23:26.712][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:23:26.713][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 852 ms
""[02:23:26.749][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:23:26.758][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-17 - Starting...
""[02:23:26.769][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-17 - Start completed.
""[02:23:26.770][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:23:26.773][WARN ][org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext.refresh:line591] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'entityManagerFactory' defined in class path resource [org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaConfiguration.class]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: privae
""[02:23:26.773][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-17 - Shutdown initiated...
""[02:23:26.774][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-17 - Shutdown completed.
""[02:23:26.775][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:23:26.781][INFO ][org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener.logMessage:line136] - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
""[02:23:26.814][ERROR][org.springframework.boot.SpringApplication.reportFailure:line821] - Application run failed
"org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'entityManagerFactory' defined in class path resource [org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaConfiguration.class]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: privae
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1157) ~[spring-context-5.3.29.jar:5.3.29]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:911) ~[spring-context-5.3.29.jar:5.3.29]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) ~[spring-context-5.3.29.jar:5.3.29]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:731) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1303) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1292) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at com.jinseong.demo.Application.main(Application.java:10) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:50) ~[spring-boot-devtools-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
Caused by: java.lang.NoClassDefFoundError: privae
	at java.base/java.lang.Class.getDeclaredMethods0(Native Method) ~[na:na]
	at java.base/java.lang.Class.privateGetDeclaredMethods(Class.java:3402) ~[na:na]
	at java.base/java.lang.Class.getDeclaredMethods(Class.java:2504) ~[na:na]
	at org.hibernate.annotations.common.reflection.java.JavaXClass.getDeclaredMethodProperties(JavaXClass.java:97) ~[hibernate-commons-annotations-5.1.2.Final.jar:5.1.2.Final]
	at org.hibernate.annotations.common.reflection.java.JavaXClass.getDeclaredProperties(JavaXClass.java:116) ~[hibernate-commons-annotations-5.1.2.Final.jar:5.1.2.Final]
	at org.hibernate.annotations.common.reflection.java.JavaXClass.getDeclaredProperties(JavaXClass.java:108) ~[hibernate-commons-annotations-5.1.2.Final.jar:5.1.2.Final]
	at org.hibernate.cfg.InheritanceState.determineDefaultAccessType(InheritanceState.java:252) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.cfg.InheritanceState.getElementsToProcess(InheritanceState.java:211) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.cfg.AnnotationBinder.bindClass(AnnotationBinder.java:772) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.boot.model.source.internal.annotations.AnnotationMetadataSourceProcessorImpl.processEntityHierarchies(AnnotationMetadataSourceProcessorImpl.java:225) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.boot.model.process.spi.MetadataBuildingProcess$1.processEntityHierarchies(MetadataBuildingProcess.java:239) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.boot.model.process.spi.MetadataBuildingProcess.complete(MetadataBuildingProcess.java:282) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.metadata(EntityManagerFactoryBuilderImpl.java:1460) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:1494) ~[hibernate-core-5.6.15.Final.jar:5.6.15.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:58) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:409) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:396) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800) ~[spring-beans-5.3.29.jar:5.3.29]
	... 21 common frames omitted
Caused by: java.lang.ClassNotFoundException: privae
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641) ~[na:na]
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188) ~[na:na]
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520) ~[na:na]
	at java.base/java.lang.Class.forName0(Native Method) ~[na:na]
	at java.base/java.lang.Class.forName(Class.java:467) ~[na:na]
	at org.springframework.boot.devtools.restart.classloader.RestartClassLoader.loadClass(RestartClassLoader.java:145) ~[spring-boot-devtools-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520) ~[na:na]
	... 42 common frames omitted
"[02:23:30.927][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:23:30.927][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:23:31.331][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:23:31.357][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 24 ms. Found 1 JPA repository interfaces.
""[02:23:31.539][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:23:31.543][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:23:31.543][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:23:31.669][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:23:31.670][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 737 ms
""[02:23:31.736][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:23:31.764][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-18 - Starting...
""[02:23:31.789][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-18 - Start completed.
""[02:23:31.789][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:23:31.893][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:23:31.894][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:23:32.115][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:23:32.126][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:23:32.130][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:23:32.131][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:23:32.131][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:23:32.131][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692293012131
""[02:23:32.131][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:23:32.136][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:23:32.138][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:23:32.139][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:23:32.139][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:23:32.140][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] (Re-)joining group
""[02:23:32.140][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.303 seconds (JVM running for 2424.158)
""[02:23:32.141][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:23:32.144][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:23:32.144][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] (Re-)joining group
""[02:23:32.148][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=90, memberId='consumer-my-consumer-group-17-6790a717-2799-410b-a744-3a0cb2848900', protocol='range'}
""[02:23:32.149][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Finished assignment for group at generation 90: {consumer-my-consumer-group-17-6790a717-2799-410b-a744-3a0cb2848900=Assignment(partitions=[reservation-topic-0])}
""[02:23:32.154][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=90, memberId='consumer-my-consumer-group-17-6790a717-2799-410b-a744-3a0cb2848900', protocol='range'}
""[02:23:32.154][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:23:32.154][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:23:32.158][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=103, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:23:32.159][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:23:56.696][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:23:56.714][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:23:56.720][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:23:56.720][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:23:56.721][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Member consumer-my-consumer-group-17-6790a717-2799-410b-a744-3a0cb2848900 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:23:56.721][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:23:56.721][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:23:56.721][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:23:56.722][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:23:56.722][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-17, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:23:56.728][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:23:56.728][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:23:56.728][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:23:56.730][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-17 unregistered
""[02:23:56.731][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:23:56.732][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:23:56.733][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-18 - Shutdown initiated...
""[02:23:56.735][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-18 - Shutdown completed.
""[02:23:56.928][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:23:56.929][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:23:57.466][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:23:57.539][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 72 ms. Found 1 JPA repository interfaces.
""[02:23:57.690][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:23:57.691][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:23:57.691][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:23:57.753][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:23:57.753][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 819 ms
""[02:23:57.786][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:23:57.793][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-19 - Starting...
""[02:23:57.804][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-19 - Start completed.
""[02:23:57.804][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:23:57.844][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:23:57.844][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:23:58.041][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:23:58.053][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:23:58.057][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:23:58.057][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:23:58.057][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:23:58.057][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692293038057
""[02:23:58.057][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:23:58.061][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:23:58.063][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:23:58.065][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:23:58.065][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:23:58.065][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.239 seconds (JVM running for 2450.082)
""[02:23:58.066][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] (Re-)joining group
""[02:23:58.066][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:23:58.069][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:23:58.069][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] (Re-)joining group
""[02:23:58.074][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=92, memberId='consumer-my-consumer-group-18-14a65077-ec0e-42fb-9c70-b199bfcad982', protocol='range'}
""[02:23:58.075][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Finished assignment for group at generation 92: {consumer-my-consumer-group-18-14a65077-ec0e-42fb-9c70-b199bfcad982=Assignment(partitions=[reservation-topic-0])}
""[02:23:58.080][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=92, memberId='consumer-my-consumer-group-18-14a65077-ec0e-42fb-9c70-b199bfcad982', protocol='range'}
""[02:23:58.080][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:23:58.080][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:23:58.085][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=103, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:23:58.086][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:26:58.388][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
""[02:26:58.388][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line525] - Initializing Servlet 'dispatcherServlet'
""[02:26:58.389][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line547] - Completed initialization in 0 ms
""[02:26:59.557][WARN ][org.springframework.web.servlet.PageNotFound.noHandlerFound:line1283] - No mapping for GET /manageReservation
""[02:27:28.365][WARN ][org.springframework.web.servlet.PageNotFound.noHandlerFound:line1283] - No mapping for GET /manageReservation
""[02:27:29.267][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:27:29.281][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:27:29.282][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Destroying Spring FrameworkServlet 'dispatcherServlet'
""[02:27:29.286][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:27:29.286][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:27:29.286][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Member consumer-my-consumer-group-18-14a65077-ec0e-42fb-9c70-b199bfcad982 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:27:29.287][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:27:29.287][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:27:29.287][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:27:29.287][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:27:29.287][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-18, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:27:29.291][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:27:29.291][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:27:29.292][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:27:29.293][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-18 unregistered
""[02:27:29.294][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:27:29.294][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:27:29.295][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-19 - Shutdown initiated...
""[02:27:29.296][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-19 - Shutdown completed.
""[02:27:29.470][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:27:29.471][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:27:30.058][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:27:30.080][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 22 ms. Found 1 JPA repository interfaces.
""[02:27:30.191][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:27:30.191][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:27:30.192][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:27:30.248][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:27:30.248][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 774 ms
""[02:27:30.286][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:27:30.296][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-20 - Starting...
""[02:27:30.310][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-20 - Start completed.
""[02:27:30.310][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:27:30.345][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:27:30.345][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:27:30.588][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:27:30.598][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:27:30.606][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:27:30.607][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:27:30.607][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:27:30.607][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692293250607
""[02:27:30.607][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:27:30.612][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:27:30.614][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:27:30.615][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:27:30.615][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:27:30.616][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] (Re-)joining group
""[02:27:30.617][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.23 seconds (JVM running for 2662.634)
""[02:27:30.618][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:27:30.620][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:27:30.620][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] (Re-)joining group
""[02:27:30.624][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=94, memberId='consumer-my-consumer-group-19-af4f471c-4b8b-4a40-8633-43562adf38a5', protocol='range'}
""[02:27:30.625][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Finished assignment for group at generation 94: {consumer-my-consumer-group-19-af4f471c-4b8b-4a40-8633-43562adf38a5=Assignment(partitions=[reservation-topic-0])}
""[02:27:30.630][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=94, memberId='consumer-my-consumer-group-19-af4f471c-4b8b-4a40-8633-43562adf38a5', protocol='range'}
""[02:27:30.630][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:27:30.630][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:27:30.635][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=103, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:27:30.635][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:27:32.180][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Initializing Spring DispatcherServlet 'dispatcherServlet'
""[02:27:32.181][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line525] - Initializing Servlet 'dispatcherServlet'
""[02:27:32.182][INFO ][org.springframework.web.servlet.DispatcherServlet.initServletBean:line547] - Completed initialization in 1 ms
""[02:29:11.203][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (1 addition, 0 deletions, 0 modifications)
""[02:29:11.215][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:29:11.215][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Destroying Spring FrameworkServlet 'dispatcherServlet'
""[02:29:11.220][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:29:11.220][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:29:11.220][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Member consumer-my-consumer-group-19-af4f471c-4b8b-4a40-8633-43562adf38a5 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:29:11.220][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:29:11.220][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:29:11.220][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:29:11.220][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:29:11.220][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-19, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:29:11.225][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:29:11.225][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:29:11.226][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:29:11.227][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-19 unregistered
""[02:29:11.227][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:29:11.228][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:29:11.228][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-20 - Shutdown initiated...
""[02:29:11.230][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-20 - Shutdown completed.
""[02:29:11.364][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:29:11.364][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:29:11.770][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:29:11.832][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 61 ms. Found 1 JPA repository interfaces.
""[02:29:11.951][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:29:11.952][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:29:11.953][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:29:12.059][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:29:12.059][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 690 ms
""[02:29:12.125][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:29:12.155][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-21 - Starting...
""[02:29:12.173][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-21 - Start completed.
""[02:29:12.173][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:29:12.275][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:29:12.276][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:29:12.537][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:29:12.548][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:29:12.552][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:29:12.552][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:29:12.552][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:29:12.553][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692293352552
""[02:29:12.553][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:29:12.557][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:29:12.559][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:29:12.560][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:29:12.560][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:29:12.561][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] (Re-)joining group
""[02:29:12.562][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.259 seconds (JVM running for 2764.579)
""[02:29:12.563][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:29:12.565][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:29:12.566][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] (Re-)joining group
""[02:29:12.570][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=96, memberId='consumer-my-consumer-group-20-62807a0a-9f8c-480e-9513-6994b083b5f4', protocol='range'}
""[02:29:12.571][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Finished assignment for group at generation 96: {consumer-my-consumer-group-20-62807a0a-9f8c-480e-9513-6994b083b5f4=Assignment(partitions=[reservation-topic-0])}
""[02:29:12.576][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=96, memberId='consumer-my-consumer-group-20-62807a0a-9f8c-480e-9513-6994b083b5f4', protocol='range'}
""[02:29:12.577][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:29:12.577][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:29:12.580][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=103, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:29:12.581][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:29:30.520][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:29:30.537][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:29:30.543][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:29:30.544][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:29:30.544][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Member consumer-my-consumer-group-20-62807a0a-9f8c-480e-9513-6994b083b5f4 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:29:30.544][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:29:30.544][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:29:30.545][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:29:30.545][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:29:30.545][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-20, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:29:30.550][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:29:30.550][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:29:30.550][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:29:30.552][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-20 unregistered
""[02:29:30.552][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:29:30.554][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:29:30.555][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-21 - Shutdown initiated...
""[02:29:30.558][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-21 - Shutdown completed.
""[02:29:30.767][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:29:30.768][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:29:31.257][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:29:31.299][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 40 ms. Found 1 JPA repository interfaces.
""[02:29:31.554][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:29:31.554][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:29:31.554][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:29:31.610][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:29:31.610][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 838 ms
""[02:29:31.642][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:29:31.651][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-22 - Starting...
""[02:29:31.665][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-22 - Start completed.
""[02:29:31.666][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:29:31.702][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:29:31.703][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:29:31.893][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:29:31.904][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:29:31.908][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:29:31.908][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:29:31.908][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:29:31.908][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692293371908
""[02:29:31.909][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:29:31.915][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:29:31.916][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:29:31.917][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:29:31.917][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:29:31.918][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] (Re-)joining group
""[02:29:31.920][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.263 seconds (JVM running for 2783.938)
""[02:29:31.922][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:29:31.922][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:29:31.923][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] (Re-)joining group
""[02:29:31.928][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=98, memberId='consumer-my-consumer-group-21-762c8d77-7d3e-48b5-8ac8-cb8b04eb9fd1', protocol='range'}
""[02:29:31.928][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Finished assignment for group at generation 98: {consumer-my-consumer-group-21-762c8d77-7d3e-48b5-8ac8-cb8b04eb9fd1=Assignment(partitions=[reservation-topic-0])}
""[02:29:31.933][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=98, memberId='consumer-my-consumer-group-21-762c8d77-7d3e-48b5-8ac8-cb8b04eb9fd1', protocol='range'}
""[02:29:31.933][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:29:31.933][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:29:31.939][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=103, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:29:31.939][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:29:35.496][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:29:35.530][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:29:35.535][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:29:35.535][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:29:35.536][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Member consumer-my-consumer-group-21-762c8d77-7d3e-48b5-8ac8-cb8b04eb9fd1 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:29:35.536][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:29:35.536][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:29:35.536][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:29:35.536][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:29:35.536][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-21, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:29:35.543][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:29:35.543][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:29:35.543][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:29:35.545][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-21 unregistered
""[02:29:35.545][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:29:35.546][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:29:35.547][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-22 - Shutdown initiated...
""[02:29:35.550][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-22 - Shutdown completed.
""[02:29:35.764][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:29:35.764][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:29:36.707][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:29:36.733][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 24 ms. Found 1 JPA repository interfaces.
""[02:29:36.840][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:29:36.841][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:29:36.841][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:29:36.918][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:29:36.918][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 1149 ms
""[02:29:36.967][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:29:36.978][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-23 - Starting...
""[02:29:36.991][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-23 - Start completed.
""[02:29:36.992][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:29:37.029][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:29:37.029][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:29:37.244][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:29:37.258][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:29:37.263][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:29:37.263][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:29:37.263][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:29:37.263][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692293377263
""[02:29:37.263][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:29:37.270][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:29:37.272][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:29:37.273][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:29:37.273][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:29:37.274][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] (Re-)joining group
""[02:29:37.274][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.62 seconds (JVM running for 2789.292)
""[02:29:37.277][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:29:37.279][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:29:37.279][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] (Re-)joining group
""[02:29:37.284][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=100, memberId='consumer-my-consumer-group-22-be62774f-7b21-4173-93e5-ddd6ef5493d4', protocol='range'}
""[02:29:37.286][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Finished assignment for group at generation 100: {consumer-my-consumer-group-22-be62774f-7b21-4173-93e5-ddd6ef5493d4=Assignment(partitions=[reservation-topic-0])}
""[02:29:37.291][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=100, memberId='consumer-my-consumer-group-22-be62774f-7b21-4173-93e5-ddd6ef5493d4', protocol='range'}
""[02:29:37.291][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:29:37.292][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:29:37.297][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=103, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:29:37.297][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:29:38.724][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:29:38.736][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:29:38.741][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:29:38.741][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:29:38.741][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Member consumer-my-consumer-group-22-be62774f-7b21-4173-93e5-ddd6ef5493d4 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:29:38.741][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:29:38.741][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:29:38.741][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:29:38.741][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:29:38.741][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-22, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:29:38.746][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:29:38.746][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:29:38.746][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:29:38.747][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-22 unregistered
""[02:29:38.748][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:29:38.748][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:29:38.749][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-23 - Shutdown initiated...
""[02:29:38.751][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-23 - Shutdown completed.
""[02:29:38.866][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:29:38.866][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:29:39.108][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:29:39.130][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 21 ms. Found 1 JPA repository interfaces.
""[02:29:39.215][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:29:39.216][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:29:39.216][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:29:39.285][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:29:39.286][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 417 ms
""[02:29:39.327][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:29:39.361][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-24 - Starting...
""[02:29:39.377][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-24 - Start completed.
""[02:29:39.378][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:29:39.426][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:29:39.426][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:29:39.727][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:29:39.740][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:29:39.753][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:29:39.753][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:29:39.753][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:29:39.753][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692293379753
""[02:29:39.754][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:29:39.762][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:29:39.764][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:29:39.765][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:29:39.765][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:29:39.766][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] (Re-)joining group
""[02:29:39.769][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 0.947 seconds (JVM running for 2791.787)
""[02:29:39.771][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:29:39.776][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:29:39.776][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] (Re-)joining group
""[02:29:39.781][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=102, memberId='consumer-my-consumer-group-23-8ad0fb9f-7371-4cdd-9550-810c9a0dbd87', protocol='range'}
""[02:29:39.782][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Finished assignment for group at generation 102: {consumer-my-consumer-group-23-8ad0fb9f-7371-4cdd-9550-810c9a0dbd87=Assignment(partitions=[reservation-topic-0])}
""[02:29:39.787][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=102, memberId='consumer-my-consumer-group-23-8ad0fb9f-7371-4cdd-9550-810c9a0dbd87', protocol='range'}
""[02:29:39.788][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:29:39.788][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:29:39.793][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=103, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:29:39.794][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:30:04.959][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:30:04.970][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:30:04.973][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:30:04.974][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:30:04.974][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Member consumer-my-consumer-group-23-8ad0fb9f-7371-4cdd-9550-810c9a0dbd87 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:30:04.974][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:30:04.974][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:30:04.974][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:30:04.974][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:30:04.974][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-23, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:30:04.981][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:30:04.981][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:30:04.981][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:30:04.983][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-23 unregistered
""[02:30:04.983][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:30:04.985][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:30:04.985][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-24 - Shutdown initiated...
""[02:30:04.988][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-24 - Shutdown completed.
""[02:30:05.149][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:30:05.150][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:30:05.604][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:30:05.631][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 26 ms. Found 1 JPA repository interfaces.
""[02:30:05.977][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:30:05.980][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:30:05.980][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:30:06.050][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-1].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:30:06.051][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 895 ms
""[02:30:06.100][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:30:06.108][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-25 - Starting...
""[02:30:06.122][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-25 - Start completed.
""[02:30:06.122][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:30:06.159][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:30:06.159][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:30:06.227][WARN ][org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext.refresh:line591] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'reservationService': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.jinseong.demo.service.ReservationService] from ClassLoader [org.springframework.boot.devtools.restart.classloader.RestartClassLoader@66bd4ae7]
""[02:30:06.227][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:30:06.228][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-25 - Shutdown initiated...
""[02:30:06.229][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-25 - Shutdown completed.
""[02:30:06.229][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:30:06.235][INFO ][org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener.logMessage:line136] - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
""[02:30:06.245][ERROR][org.springframework.boot.SpringApplication.reportFailure:line821] - Application run failed
"org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'reservationService': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.jinseong.demo.service.ReservationService] from ClassLoader [org.springframework.boot.devtools.restart.classloader.RestartClassLoader@66bd4ae7]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:289) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1302) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1219) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955) ~[spring-beans-5.3.29.jar:5.3.29]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:921) ~[spring-context-5.3.29.jar:5.3.29]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) ~[spring-context-5.3.29.jar:5.3.29]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:731) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:307) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1303) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1292) ~[spring-boot-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at com.jinseong.demo.Application.main(Application.java:10) ~[classes/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:50) ~[spring-boot-devtools-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
Caused by: java.lang.IllegalStateException: Failed to introspect Class [com.jinseong.demo.service.ReservationService] from ClassLoader [org.springframework.boot.devtools.restart.classloader.RestartClassLoader@66bd4ae7]
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:485) ~[spring-core-5.3.29.jar:5.3.29]
	at org.springframework.util.ReflectionUtils.doWithLocalMethods(ReflectionUtils.java:321) ~[spring-core-5.3.29.jar:5.3.29]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:267) ~[spring-beans-5.3.29.jar:5.3.29]
	... 23 common frames omitted
Caused by: java.lang.NoClassDefFoundError: List
	at java.base/java.lang.Class.getDeclaredMethods0(Native Method) ~[na:na]
	at java.base/java.lang.Class.privateGetDeclaredMethods(Class.java:3402) ~[na:na]
	at java.base/java.lang.Class.getDeclaredMethods(Class.java:2504) ~[na:na]
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:467) ~[spring-core-5.3.29.jar:5.3.29]
	... 25 common frames omitted
Caused by: java.lang.ClassNotFoundException: List
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641) ~[na:na]
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188) ~[na:na]
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520) ~[na:na]
	at java.base/java.lang.Class.forName0(Native Method) ~[na:na]
	at java.base/java.lang.Class.forName(Class.java:467) ~[na:na]
	at org.springframework.boot.devtools.restart.classloader.RestartClassLoader.loadClass(RestartClassLoader.java:145) ~[spring-boot-devtools-2.7.15-SNAPSHOT.jar:2.7.15-SNAPSHOT]
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520) ~[na:na]
	... 29 common frames omitted
"[02:30:13.427][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:30:13.427][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:30:13.947][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:30:14.020][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 72 ms. Found 1 JPA repository interfaces.
""[02:30:14.123][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:30:14.124][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:30:14.124][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:30:14.193][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-2].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:30:14.194][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 764 ms
""[02:30:14.225][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:30:14.233][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-26 - Starting...
""[02:30:14.245][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-26 - Start completed.
""[02:30:14.246][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:30:14.272][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:30:14.272][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:30:14.461][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:30:14.471][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:30:14.475][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:30:14.475][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:30:14.476][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:30:14.476][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692293414475
""[02:30:14.476][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:30:14.480][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:30:14.482][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:30:14.483][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:30:14.483][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:30:14.484][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] (Re-)joining group
""[02:30:14.484][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 1.134 seconds (JVM running for 2826.502)
""[02:30:14.486][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:30:14.488][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:30:14.489][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] (Re-)joining group
""[02:30:14.493][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=104, memberId='consumer-my-consumer-group-24-30ee45ab-3a93-4faa-a157-86954ac5ef7c', protocol='range'}
""[02:30:14.493][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Finished assignment for group at generation 104: {consumer-my-consumer-group-24-30ee45ab-3a93-4faa-a157-86954ac5ef7c=Assignment(partitions=[reservation-topic-0])}
""[02:30:14.498][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=104, memberId='consumer-my-consumer-group-24-30ee45ab-3a93-4faa-a157-86954ac5ef7c', protocol='range'}
""[02:30:14.498][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:30:14.498][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:30:14.502][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=103, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:30:14.503][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:30:25.304][INFO ][org.springframework.boot.devtools.autoconfigure.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener.onApplicationEvent:line211] - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
""[02:30:25.318][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:30:25.322][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:30:25.322][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:30:25.322][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Member consumer-my-consumer-group-24-30ee45ab-3a93-4faa-a157-86954ac5ef7c sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:30:25.322][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:30:25.322][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:30:25.323][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:30:25.323][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:30:25.323][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-24, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:30:25.327][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:30:25.328][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:30:25.328][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:30:25.329][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-24 unregistered
""[02:30:25.329][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:30:25.331][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:30:25.331][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-26 - Shutdown initiated...
""[02:30:25.333][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-26 - Shutdown completed.
""[02:30:25.615][INFO ][com.jinseong.demo.Application.logStarting:line55] - Starting Application using Java 17.0.6 on DESKTOP-CLF8N3P with PID 24824 (C:\Users\jinsung\Documents\GitHub\RMS\demo\target\classes started by jinsung in C:\Users\jinsung\Documents\GitHub\RMS\demo)
""[02:30:25.615][INFO ][com.jinseong.demo.Application.logStartupProfileInfo:line631] - No active profile set, falling back to 1 default profile: "default"
""[02:30:25.967][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line132] - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
""[02:30:25.987][INFO ][org.springframework.data.repository.config.RepositoryConfigurationDelegate.registerRepositoriesIn:line201] - Finished Spring Data repository scanning in 20 ms. Found 1 JPA repository interfaces.
""[02:30:26.072][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize:line108] - Tomcat initialized with port(s): 8080 (http)
""[02:30:26.072][INFO ][org.apache.catalina.core.StandardService.log:line173] - Starting service [Tomcat]
""[02:30:26.072][INFO ][org.apache.catalina.core.StandardEngine.log:line173] - Starting Servlet engine: [Apache Tomcat/9.0.78]
""[02:30:26.135][INFO ][org.apache.catalina.core.ContainerBase.[Tomcat-2].[localhost].[/].log:line173] - Initializing Spring embedded WebApplicationContext
""[02:30:26.135][INFO ][org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.prepareWebApplicationContext:line292] - Root WebApplicationContext: initialization completed in 512 ms
""[02:30:26.169][INFO ][org.hibernate.jpa.internal.util.LogHelper.logPersistenceUnitInformation:line31] - HHH000204: Processing PersistenceUnitInfo [name: default]
""[02:30:26.177][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line110] - HikariPool-27 - Starting...
""[02:30:26.189][INFO ][com.zaxxer.hikari.HikariDataSource.getConnection:line123] - HikariPool-27 - Start completed.
""[02:30:26.190][INFO ][org.hibernate.dialect.Dialect.<init>:line175] - HHH000400: Using dialect: org.hibernate.dialect.MySQL8Dialect
""[02:30:26.221][INFO ][org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator.initiateService:line52] - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
""[02:30:26.221][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.buildNativeEntityManagerFactory:line437] - Initialized JPA EntityManagerFactory for persistence unit 'default'
""[02:30:26.391][INFO ][org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer.startServer:line59] - LiveReload server is running on port 35729
""[02:30:26.401][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig.logAll:line376] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-25
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

""[02:30:26.405][WARN ][org.apache.kafka.clients.consumer.ConsumerConfig.logUnused:line384] - The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
""[02:30:26.405][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line119] - Kafka version: 3.1.2
""[02:30:26.405][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line120] - Kafka commitId: f8c67dc3ae0a3265
""[02:30:26.406][INFO ][org.apache.kafka.common.utils.AppInfoParser.<init>:line121] - Kafka startTimeMs: 1692293426405
""[02:30:26.406][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.subscribe:line966] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Subscribed to topic(s): reservation-topic
""[02:30:26.410][INFO ][org.springframework.boot.web.embedded.tomcat.TomcatWebServer.start:line220] - Tomcat started on port(s): 8080 (http) with context path ''
""[02:30:26.412][INFO ][org.apache.kafka.clients.Metadata.updateLatestMetadata:line402] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Resetting the last seen epoch of partition reservation-topic-0 to 0 since the associated topicId changed from null to 8aoMqokpSXGOqjBL2y8aPw
""[02:30:26.412][INFO ][org.apache.kafka.clients.Metadata.update:line287] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Cluster ID: TgEACWKoRbSzp0Inn-GuTg
""[02:30:26.412][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onSuccess:line853] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Discovered group coordinator 127.0.0.1:9092 (id: 2147482646 rack: null)
""[02:30:26.413][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] (Re-)joining group
""[02:30:26.414][INFO ][com.jinseong.demo.Application.logStarted:line61] - Started Application in 0.947 seconds (JVM running for 2838.431)
""[02:30:26.415][INFO ][org.springframework.boot.devtools.autoconfigure.ConditionEvaluationDeltaLoggingListener.onApplicationEvent:line63] - Condition evaluation unchanged
""[02:30:26.416][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Request joining group due to: need to re-join with the given member-id
""[02:30:26.417][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendJoinGroupRequest:line535] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] (Re-)joining group
""[02:30:26.422][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line595] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Successfully joined group with generation Generation{generationId=106, memberId='consumer-my-consumer-group-25-09bcc46d-bf15-450a-91da-98e30225c988', protocol='range'}
""[02:30:26.422][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment:line659] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Finished assignment for group at generation 106: {consumer-my-consumer-group-25-09bcc46d-bf15-450a-91da-98e30225c988=Assignment(partitions=[reservation-topic-0])}
""[02:30:26.426][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle:line761] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Successfully synced group in generation Generation{generationId=106, memberId='consumer-my-consumer-group-25-09bcc46d-bf15-450a-91da-98e30225c988', protocol='range'}
""[02:30:26.427][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokeOnAssignment:line280] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Notifying assignor about the new Assignment(partitions=[reservation-topic-0])
""[02:30:26.427][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsAssigned:line292] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Adding newly assigned partitions: reservation-topic-0
""[02:30:26.431][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded:line851] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Setting offset for partition reservation-topic-0 to the committed offset FetchPosition{offset=103, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 1001 rack: null)], epoch=0}}
""[02:30:26.431][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions assigned: [reservation-topic-0]
""[02:30:41.073][INFO ][org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin.shutdown:line159] - Application shutdown requested.
""[02:30:41.089][INFO ][org.apache.catalina.core.StandardService.log:line173] - Stopping service [Tomcat]
""[02:30:41.095][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked:line311] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Revoke previously assigned partitions reservation-topic-0
""[02:30:41.095][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: partitions revoked: [reservation-topic-0]
""[02:30:41.095][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeLeaveGroup:line1060] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Member consumer-my-consumer-group-25-09bcc46d-bf15-450a-91da-98e30225c988 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147482646 rack: null) due to the consumer unsubscribed from all topics
""[02:30:41.095][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:30:41.095][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:30:41.095][INFO ][org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe:line1075] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Unsubscribed all topics or patterns and assigned partitions
""[02:30:41.095][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.resetStateAndGeneration:line972] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Resetting generation due to: consumer pro-actively leaving the group
""[02:30:41.096][INFO ][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.requestRejoin:line1000] - [Consumer clientId=consumer-my-consumer-group-25, groupId=my-consumer-group] Request joining group due to: consumer pro-actively leaving the group
""[02:30:41.102][INFO ][org.apache.kafka.common.metrics.Metrics.close:line659] - Metrics scheduler closed
""[02:30:41.102][INFO ][org.apache.kafka.common.metrics.Metrics.close:line663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
""[02:30:41.102][INFO ][org.apache.kafka.common.metrics.Metrics.close:line669] - Metrics reporters closed
""[02:30:41.104][INFO ][org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo:line83] - App info kafka.consumer for consumer-my-consumer-group-25 unregistered
""[02:30:41.104][INFO ][org.springframework.kafka.listener.KafkaMessageListenerContainer.info:line292] - my-consumer-group: Consumer stopped
""[02:30:41.105][INFO ][org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.destroy:line651] - Closing JPA EntityManagerFactory for persistence unit 'default'
""[02:30:41.106][INFO ][com.zaxxer.hikari.HikariDataSource.close:line350] - HikariPool-27 - Shutdown initiated...
""[02:30:41.109][INFO ][com.zaxxer.hikari.HikariDataSource.close:line352] - HikariPool-27 - Shutdown completed.
"